{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOS:<br>\n",
    "\n",
    "- Übersicht über alle Verfahren geben in kapitel 3 (Tabelle?!)\n",
    "- überprüfen Formulierung\n",
    "- untertitel der grafik bei LSA in pdf überprüfen\n",
    "\n",
    "\n",
    "für generierung:\n",
    "- toc entfernen?\n",
    "-  tabelle anpassen in 3.1\n",
    "- alle %%time entfernen!\n",
    "- imports entfernen\n",
    "- alle code zeilen gut angezeigt?\n",
    "- Fußnoten fixen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inhaltsverzeichnis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Einführung\" data-toc-modified-id=\"Einführung-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Einführung</a></span><ul class=\"toc-item\"><li><span><a href=\"#Das-Bag-of-Words-Modell\" data-toc-modified-id=\"Das-Bag-of-Words-Modell-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Das Bag-of-Words Modell</a></span></li><li><span><a href=\"#Grenzen-des-Bag-of-Words-Modells\" data-toc-modified-id=\"Grenzen-des-Bag-of-Words-Modells-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Grenzen des Bag-of-Words Modells</a></span></li></ul></li><li><span><a href=\"#LSA\" data-toc-modified-id=\"LSA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSA</a></span></li><li><span><a href=\"#Word-Embeddings\" data-toc-modified-id=\"Word-Embeddings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word Embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"#Allgemeines\" data-toc-modified-id=\"Allgemeines-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Allgemeines</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Word2Vec</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vortrainierte-Embeddings-verwenden\" data-toc-modified-id=\"Vortrainierte-Embeddings-verwenden-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Vortrainierte Embeddings verwenden</a></span></li><li><span><a href=\"#Eigene-Embeddings-trainieren\" data-toc-modified-id=\"Eigene-Embeddings-trainieren-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Eigene Embeddings trainieren</a></span></li></ul></li><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>GloVe</a></span></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>FastText</a></span></li><li><span><a href=\"#ELMo\" data-toc-modified-id=\"ELMo-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>ELMo</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>BERT</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as gensim_downloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import urllib.request\n",
    "\n",
    "from utils import preprocess_text, plot_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: weg\n",
    "\"\"\"\n",
    "text_w2v = [\"das kind sagt, dass es feuerwehrmann sein möchte\",\n",
    "            \"der erwachsene sagt, dass er lieber kein feuerwehrmann sein möchte\",\n",
    "            \"das kind fragt, was der erwachsene denn lieber sein möchte\",\n",
    "            \"der erwachsene sagt, dass er lieber polizist sein möchte\"]\n",
    "#text_w2v = [word_tokenize(sen) for sen in text_w2v]\n",
    "df = pd.DataFrame(text_w2v, columns = [\"text\"])\n",
    "\n",
    "url = 'http://cloud.devmount.de/d2bc5672c523b086/german.model'\n",
    "urllib.request.urlretrieve(url, \"german_model.bin\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 1.14 s, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = pd.read_csv(\"../corpora/small_amazon_reviews_electronic.csv\")\n",
    "corpus[\"review\"] = corpus.review.apply(lambda x: preprocess_text(x))\n",
    "texts = [word_tokenize(row[\"review\"]) for idx, row in corpus.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das **Natural Language Processing** (kurz: NLP) befasst sich mit Methoden und Verfahren zur maschinellen Verarbeitung von natürlicher Sprache in Form von Worten, Texten oder ganzen Korpora. Bevor jedoch NLP Verfahren wie die Textklassifikation oder das Topic Modelling auf die Textdaten angewendet werden können, müssen diese in eine Darstellungsweise umgewandelt werden, mit der die Verfahren arbeiten können. Die rohen Textdaten werden daher in **Vektoren**, die aus Zahlen bestehen, umgewandelt. Dieser Vorgang nennt sich **Vektorisierung**. Ein Wort wie \"Baum\" kann dadurch als Vektor aufgefasst werden. Natürlich können auch andere Features aus den Texten als Vektoren dargestellt werden; so ist es auch möglich, einzelne Buchstaben, Phrasen, Sätze, Segmente oder ganze Texte als Features aus den Textdaten zu extrahieren und diese zu vektorisieren. In der folgenden Übersicht werden jedoch vorwiegend Wörter als Features verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Bag-of-Words Modell\n",
    "\n",
    "Das wohl einfachste Verfahren zur Darstellung von Wörtern als Vektoren ist das **Bag-of-Words** Modell. Wörter werden hier als eindimensionale Vektoren (= einfache Zahlen) dargestellt, wobei jedes individuelle Wort einen individuellen eindimensionalen Vektor (auch: **Index**) zugeordnet bekommt. Die Zuordnungen jedes einzigartigen Wortes zu seinem Vektor werden in einem *Vokabular* gespeichert. Nun können mithilfe dieses Vokabulars auch ganze Sätze oder sogar Texte dargestellt werden. Dafür wird für jeden Satz/Text ein Vektor gebildet, der die gleiche Länge wie das Vokabular hat. Jedem Eintrag des Vektors wird anhand des Vokabulars ein Wort zugeordnet. Der Satz/Text wird dann als Vektor aus **absoluten Termhäufigkeiten** dargestellt, wo an jeder Stelle, an dem ein Wort aus dem Vokabular in dem Text vorkommt, die Häufigkeit des Wortes in dem jeweiligen Satz/Text steht und an jeder anderen Stelle eine $0$, da es kein einziges Mal vorkommt.[<sup>1</sup>](#fn1) Dies soll im Folgenden anhand eines Code-Beispiels erläutert werden. Zuerst wird das Vokabular aller Texte dargestellt, bei dem die Wörter einem Index zugeordnet werden (es wird ab $0$ gezählt). Danach werden die vektorisierten Sätze/Texte angezeigt.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn1\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">1</sup> &nbsp;Dies ist nur eine Möglichkeit, die Häufigkeit eines Wortes beim Bag-of-Words Modell darzustellen. Eine weitere Möglichkeit wären <b>binäre Häufigkeiten</b>, bei denen das Vorkommen eines Wortes mit einer $1$ und die Abwesenheit eines Wortes mit einer $0$ gekennzeichnet werden. Um häufigen Wörtern in den Dokumenten weniger Gewicht zu geben, da diese meist einen geringeren Informationsgehalt besitzen, ist es auch möglich, das Bag-of-Words Modell in der Kombination mit dem <b>TF-IDF Maß</b> aus dem Bereich des Information Retrievals zu verwenden, bei dem die Häufigkeit von Worten skaliert wird.</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"ich gehe nachher zur bank, um etwas geld zu holen\",\n",
    "        \"ich möchte mich kurz auf die bank setzen\",\n",
    "        \"um mir etwas zu essen zu holen, stand ich von der bank auf\", \n",
    "        \"auf der hölzernen bank neben der bank liegt noch geld\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vector = vectorizer.fit_transform(text)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grenzen des Bag-of-Words Modells\n",
    "\n",
    "Aufgrund seiner Einfachheit ist das Bag-of-Words Modell leicht verständlich und sehr schnell umsetzbar. Es hat jedoch eine Reihe an Nachteilen, von deinen einige im Folgenden kurz erläutert werden:\n",
    "\n",
    "- **Keine Informationen über Reihenfolge der Wörter.** Beim Bag-of-Words Modell wird jegliche Information über die Reihenfolge der Wörter verworfen, der Kontext eines Wortes bleibt unberücksichtigt. Dies wird auch durch den Namen dieses Modells deutlich: Die Bezeichnung \"bag\" (deutsch: Sack) soll darauf hinweisen, dass alle Informationen über die Struktur oder Reihenfolge der Wörter im Dokument verworfen werden, da sie metaphorisch in einen \"Sack\" geworfen werden. Die Reihenfolge lässt sich auch nicht im Nachhinein rekonstruieren. Insgesamt gehen somit sehr viele semantische Informationen verloren. Eine Lösung, bei der die Reihenfolge der Worte berücksichtigt werden kann, ist die Verwendung von **N-Grammen** oder **LSA** (Kapitel 2 TODO). \n",
    "- **Spärlichkeit von Wortvektoren.** Umso mehr verschiedene Worte in den verwendeten Texten vorkommen, umso größer wird das Vokabular. Dies kann oft zu sehr spärlichen (engl. *sparse*) Wortvektoren führen. Besteht das Vokabular aus 500000 Worten, ein Text aber nur aus 50 verschiedenen Worten, sind nur 0.01% der Stellen des 500000 langen Wortvektors mit Einsen besetzt, der Rest nur mit Nullen. Dies führt dazu, dass eine große Menge an Rechenspeicher für die Verarbeitung der riesigen Matrizen benötigt wird. Weiterhin werden wenige Informationen in sehr großen Repräsentationsräumen benutzt, wodurch es für einige NLP Verfahren und Modelle problematisch ist, diese wenigen Informationen effizient zu nutzen. Eine Lösung bieten dichtbesetzte **Word Embeddings**, die in den nächsten Kapiteln behandelt werden.\n",
    "- **Abbildung der Mehrdeutigkeit von Worten**. Wörter können trotz gleicher Schreibweise mehrere Bedeutungen haben, welche sich durch den Kontext des Wortes zeigen können. Dies wird durch das Bag-of-Words Modell nicht abgebildet. Eine mögliche Lösung wäre die Verwendung von **kontextabhängigen Word Embeddings** wie die **BERT-Embeddings** in Kapitel 3.6 (TODO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA\n",
    "\n",
    "**Latent Semantic Analysis** (kurz: LSA, auch: *Latent Semantic Indexing*) ist ein Verfahren aus dem Bereich des Information Retrievals aus dem Jahre 1990. Bei diesem Verfahren werden Dokumente und Terme (repräsentiert durch eine **Term-Dokument Matrix**) in einem latenten Raum abgebildet, der aus **Konzepten** (oder **Hauptkomponenten**) besteht. Dokumente, die ähnlich zueinander sind, d.h. aus ähnlichen Konzepten bestehen, werden in diesem Raum näher beieinander platziert. Dies wird durch die folgende Grafik deutlich.\n",
    "\n",
    "\n",
    "![lsa](img/lsa.png)\n",
    "\n",
    "Grafik von Susan Dumais, siehe <a href=\"http://www.ifis.uni-luebeck.de/~moeller/tuhh-lectures/mmieir-sose-12/05-Latent-Semantic-Analysis.pdf\">Präsentation</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel der LSA ist es, die Konzepte innerhalb der Dokumente zu finden. Dabei greift das Verfahren auf eine Technik der linearen Algebra zurück, der **Singulärwertzerlegung** (englisch: Singular Value Decomposition). Die Idee dabei ist, dass die Term-Dokument Matrix aus **Hauptdimensionen**, welche die wichtigen Konzepte der Dokumente beinhalten, und aus weniger aussagekräftigen Dimensionen mit unwichtigen Termen besteht. Mithilfe der Singulärwertzerlegung wird die originale Term-Dokument Matrix in drei Matrizen aufgeteilt, wobei die beiden äußeren Matrizen aus den linken bzw. rechten orthonormalen Eigenvektoren bestehen und die mittlere Matrix eine Diagonalmatrix ist, die die singulären Werte der Originalmatrix enthält. Mit Hilfe dieser Zerlegung kann eine **Approximation** der Originalmatrix mit einer kleiner dimensionierten Matrix erreicht werden. Die singulären Werte in der Diagonalmatrix sind nach ihrer Größe absteigend geordnet. Singulärwerte, die unter einem bestimmten Schwellenwert liegen, werden entfernt. Auch in den anderen Matrizen werden entsprechende Zeilen oder Spalten entfernt. Mit Hilfe der reduzierten Matrizen erhält man durch Matrixmultiplikation die optimale Approximation der Originalmatrix, die kleiner als die originale Term-Dokument Matrix ist, da Informationen aus den weniger aussagekräftigen Dimensionen verworfen wurden. Weiterhin werden bei der Dimensionsreduktion auch ähnliche Konzepte zusammengefasst, so werden z.B. Worte wie \"Tür\" und \"Tor\" in einem Konzept zusammengefasst.\n",
    "\n",
    "Der Vorteil der LSA ist, dass anders als beim Bag-of-Words Modell die **Semantik** der Dokumente wiedergegeben werden kann. Zudem werden **Synonyme** zusammengefasst. Probleme hat LSA jedoch mit der **Polysemie**. Zudem ist der Algorithmus sehr rechenaufwendig.\n",
    "\n",
    "TODO: mehr?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "## Allgemeines\n",
    "\n",
    "**Word Embeddings** (deutsch: Worteinbettungen) sind die Sammelbezeichnung für eine Reihe von Sprachmodellierungstechniken. Anders als beim Bag-of-Words Modell werden Wörter mit ähnlichen Bedeutungen ähnlich dargestellt, wobei der Kontext der Wörter berücksichtigt wird. Word Embeddings repräsentieren Wörter als Vektoren in einem multidimensionalen semantischen Raum. In diesem Raum werden Wörter, die ähnlich zueinander sind, näher beieinander platziert. Diesen Raum kann man sich etwa folgendermaßen vorstellen:<br>\n",
    "\n",
    "\n",
    "![wordembeddings](img/we_space.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die grundsätzliche Idee von Word Embeddings basiert auf der **Distributionellen Hypothese** von  John Rupert Firth, die besagt, dass die Bedeutung eines Wortes durch sein Umfeld geprägt ist. Wörter, die einen ähnlichen Kontext besitzen, haben eine ähnliche Bedeutung. Anders als vorherige Vektorisierungsmethoden basieren Word Embeddings auf **Vorhersagemodellen** (englisch: **prediction models**)[<sup>2</sup>](#fn2), indem Wörter durch Wahrscheinlichkeiten anstatt durch Häufigkeiten wie beim Bag-of-Words Modell oder bei der Latent Semantic Analysis dargestellt werden. Weiterhin sind die Wortvektoren von Word Embeddings anders als beim Bag-of-Words Modell **dichtbesetzt** (englisch: **dense**) und haben weitaus weniger Dimensionen (100-800 Dimensionen anstatt 100000-1000000, je nach der Größe des Vokabulars). Dadurch haben die Wortvektoren eine viel geringere Größe, bieten trotzdem eine effizientere und komplexere Darstellung der Wörter.\n",
    "\n",
    "Eine weitere Besonderheit von Word Embeddings ist, dass es mit diesen möglich ist, eine Arithmetik mit Wörtern umzusetzen. So kann mit Wortvektoren \"gerechnet\" werden. Folgende Gleichungen sind mit Word Embeddings möglich:\n",
    "\n",
    "`König - Mann + Frau = Königin`<br>\n",
    "\n",
    "`London - Großbritannien + Deutschland = Berlin`\n",
    "\n",
    "\n",
    "Word Embeddings wurden ab 2013 durch die Einführung des Algorithmus **Word2Vec** populär, in den Jahren darauf folgten weitere Word Embedding Algorithmen wie **GloVe**, **FastText**, **ELMo** und **BERT**. In der folgenden Tabelle sind die wichtigsten Unterschiede der verschiedenen Embeddings zusammengefasst, genauere Erläuterungen der Embeddings befinden sich in den folgenden Kapiteln.\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn2\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">2</sup> &nbsp;Obwohl GloVe eigentlich kein Vorhersagemodell verwendet, unterscheidet sich GloVe trotzdem stark von vorhergehenden, Häufigkeits-basierenden Modellen, weshalb es oft als Vohersagemodell angesehen wird, siehe LEVY et. al. (2015), Improving Distributional Similarity with Lessons Learned from Word Embeddings, https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf (abgerufen am 31.07.2020).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ausfüllen & mehr, gucken wie anders dargestellt werden kann\n",
    "\n",
    "<table>\n",
    "    <th></th>\n",
    "    <th>Word2Vec</th>\n",
    "    <th>GloVe</th>\n",
    "    <th>FastText</th>\n",
    "    <th>ELMo</th>\n",
    "    <th>BERT</th>\n",
    "    <tr>\n",
    "        <td>Entstehungsjahr</td>\n",
    "        <td>2013</td>\n",
    "        <td>2014</td>\n",
    "        <td>2016</td>\n",
    "        <td>2018</td>\n",
    "        <td>2018</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>Out of vocabulary Fehler</td>\n",
    "        <td>ja</td>\n",
    "        <td>ja</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>Kontextsensitiv</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>ja</td>\n",
    "        <td>ja</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Die Popularität von Word Embeddings ist vor allem **Word2Vec** geschuldet, welches 2013 von Tomas Mikolov und weiteren Mitgliedern von Google publiziert wurde. Word2Vec basiert auf einer simplen und effektiven Feedforward Neuronalen Netzstruktur. Word2Vec implementiert zwei verschiedene Ansätze zur Berechnung der Wortwahrscheinlichkeiten: **Continous Bag of Words** (**CBOW**) und das **Skip-gram Modell**. \n",
    "\n",
    "**Continous Bag of Words** versucht die Wahrscheinlichkeit eines Wortes oder einer Gruppe von Wörtern anhand eines gegebenen Kontext vorauszusagen:\n",
    "\n",
    "![cbow](img/cbow.png)\n",
    "\n",
    "\n",
    "Das **Skip-gram Model** funktioniert wie CBOW, nur anders herum. Das Modell versucht, anhand eines gegebenen Wortes den Kontext vorauszusagen:\n",
    "\n",
    "![skip-gram](img/skipgram.png)\n",
    "\n",
    "<br>Word2Vec nutzt wahlweise eine dieser Techniken, um aus rohen Textdaten mithilfe eines Neuronales Netzes Wortvektoren zu erstellen. Dabei kann Word2Vec bei vielen Implementierungen (z.b. bei Gensim) auf zwei Arten verwendet werden: Entweder werden bereits vortrainierte Embeddings geladen oder es werden eigene Embeddings auf eigenen Textdaten trainiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vortrainierte Embeddings verwenden\n",
    "\n",
    "Für die Demonstration der Nutzung von vortrainierten Word Embeddings wird ein deutsches Modell verwendet, welches auf Wikipedia- und Zeitungsartikeln trainiert wurde ([Quelle](https://devmount.github.io/GermanWordEmbeddings/)). Als Framework wird **Gensim** verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_w2v = gensim.models.KeyedVectors.load_word2vec_format('german_model.bin', \n",
    "                                                          binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code werden die 10 ähnlichsten Wörter zu \"König\" ausgegeben. Alle diese Wörter passen auch thematisch zu \"König\", sie verbindet alle das Thema \"royal\" bzw. \"Königshaus\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prinz: 0.786\n",
      "Koenigs: 0.736\n",
      "Koenigin: 0.726\n",
      "Jungkoenig: 0.705\n",
      "Kaiser: 0.705\n"
     ]
    }
   ],
   "source": [
    "for t in pre_w2v.most_similar('Koenig', topn=5): \n",
    "    print(f\"{t[0]}: {np.around(t[1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch das Rechenbeispiel aus Kapitel 3.1 TODO kann mit Word2Vec umgesetzt werden. Addiert man \"König\" mit \"Frau\" und subtrahiert \"Mann\", erhält man Begriffe zum Thema \"Königin\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koenigin: 0.752\n",
      "Prinzessin: 0.715\n",
      "Prinz: 0.688\n",
      "Jungschuetzenkoenigin: 0.674\n",
      "Majestaet: 0.659\n"
     ]
    }
   ],
   "source": [
    "for t in pre_w2v.most_similar(positive=['Koenig', 'Frau'],\n",
    "                              negative=['Mann'], topn=5):\n",
    "    print(f\"{t[0]}: {np.around(t[1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiterhin kann man auch ein Wort mit einer Liste von anderen Wörtern vergleichen und abfragen, welchem Wort aus der Liste das Wort am ähnlichsten ist oder man überprüft bei einer Liste von Wörtern, welches Wort nicht passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welches Wort ist am ähnlichsten zu 'Banane'? -> Apfel\n",
      "Welches Wort nicht zu den anderen Wörtern? -> Berg\n"
     ]
    }
   ],
   "source": [
    "most_similar = pre_w2v.most_similar_to_given('Banane', ['Koenig', 'Berg', \n",
    "                                                        'Haus', 'Apfel'])\n",
    "doesnt_match = pre_w2v.doesnt_match(['Koenig', 'Thron', 'Berg', 'Prinzessin'])\n",
    "print(f\"Welches Wort ist am ähnlichsten zu 'Banane'? -> {most_similar}\")\n",
    "print(f\"Welches Wort nicht zu den anderen Wörtern? -> {doesnt_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wortvektoren können mit verwandeten Wörtern (hier die 5 ähnlichsten Wörter) auch geplottet werden, wodurch die einzelnen Themen sehr gut sichtbar sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordlist = ['Haus', 'Berg', 'Koenig', 'gehen']\n",
    "plot_word_embeddings(pre_w2v, wordlist, figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigene Embeddings trainieren\n",
    "\n",
    "Es ist auch möglich, eigene Embeddings zu trainieren. Dabei muss sich zuvor für die Technik **CBOW** oder **Skip-gram** entschieden werden (wird durch den Parameter `sg`gesteuert). Es wurde der englische Datensatz **Amazon Reviews** verwendet ([Quelle](https://nijianmo.github.io/amazon/index.html)). Dieser wurde für Demonstrationszwecke auf Reviews zu elektronischen Geräten aus dem Jahr 2018 gekürzt. Auch hier passen die ähnlichsten 5 Wörter sehr gut zum ausgewählten Wort *smartphone*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 1s, sys: 4.19 s, total: 6min 5s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2vec_cbow = Word2Vec(texts, min_count=1, size=100, window=5, sg=0)\n",
    "word2vec_skipgram = Word2Vec(texts, min_count=1, size=100, window=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iphone', 0.7408102750778198),\n",
       " ('phones', 0.657496452331543),\n",
       " ('ph', 0.635297954082489),\n",
       " ('car', 0.626123309135437),\n",
       " ('cell', 0.6212888956069946)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv.most_similar('phone', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe\n",
    "\n",
    "**GloVe** (= Global Vectors) wurde 2014 von Pennigton et. al. veröffentlicht. Vor der Veröffentlichung von Globe ließen sich die Wortvektorisierungsmethoden in zwei Hauptströmungen unterteilen: das Statistik-basierende **LDA**[<sup>3</sup>](#fn3) und das lernbasierte **Word2Vec**. Während LDA Wörter mithilfe von Häufigkeiten in einer Kookkurrenz-Matrix darstellt, verwendet Word2Vec zur Darstellung der Wörter Wortwahrscheinlichkeiten, die mithilfe eines Voraussage-Modells erstellt wurden. **GloVe** verwendet wie LDA für die Darstellung der Häufigkeiten eine Kookkurrenz-Matrix, wobei GloVe die Häufigkeiten vorher normalisiert und mithilfe des Logarithmus *\"glättet\"* (englisch: *smoothing*). Anders als Word2Vec benutzt es für die Erstellung der Embeddings also keine neuronalen Netze, die erst durch ein Training die Wortbeziehungen erlernen, sondern die Beziehungen werden **global** (daher auch der Name) mithilfe einer Mischung aus maschinellem Lernen und statischen Verfahren aus den Texten gewonnen.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn3\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">3</sup> &nbsp;<b>LDA</b> steht für \"Latent Dirichlet allocation\" und ist ein Algorithmus, der Wörter ähnlichen Gruppen anhand der Wahrscheinlichkeit, dass sie zusammen in einem Dokument vorkommen, zuordnet.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Demonstatration der Glove-Embeddings wurde die Bibliothek **Flair** verwendet. Jeder Vektor für jedes Token-Embedding hat eine Länge von 100, es wurden jedoch nur die ersten drei Zahlen ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'smartphones': tensor([-0.2138, -0.3245,  0.2806]) (Vektorlänge: 100)\n",
      "'have': tensor([0.1571, 0.6561, 0.0021]) (Vektorlänge: 100)\n",
      "'a': tensor([-0.2709,  0.0440, -0.0203]) (Vektorlänge: 100)\n",
      "'touchscreen': tensor([-0.7974,  0.1240,  0.7148]) (Vektorlänge: 100)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('smartphones have a touchscreen', use_tokenizer=True)\n",
    "WordEmbeddings('glove').embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(f\"'{token.text}': {token.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token.embedding)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "\n",
    "BERT steht für \"Bidirectional Encoder Representations from Transformers\" und brach bei seiner Veröffentlichung 2018 eine ganze Reihe von Rekorden für Aufgaben des Natural Language Processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Inhalte",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
