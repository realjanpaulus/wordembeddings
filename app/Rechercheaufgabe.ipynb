{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.embeddings import BertEmbeddings, ELMoEmbeddings, FastTextEmbeddings, TransformerWordEmbeddings, WordEmbeddings\n",
    "\n",
    "import gensim\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import gensim.downloader as gensim_downloader\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import urllib.request\n",
    "from utils import preprocess_text, plot_word_embeddings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 1.74 s, total: 1min 20s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = pd.read_csv(\"../corpora/small_amazon_reviews_electronic.csv\")\n",
    "corpus[\"review\"] = corpus.review.apply(lambda x: preprocess_text(x))\n",
    "texts = [word_tokenize(row[\"review\"]) for idx, row in corpus.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inhaltsverzeichnis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Einführung\" data-toc-modified-id=\"Einführung-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Einführung</a></span><ul class=\"toc-item\"><li><span><a href=\"#Das-Bag-of-Words-Modell\" data-toc-modified-id=\"Das-Bag-of-Words-Modell-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Das Bag-of-Words Modell</a></span></li><li><span><a href=\"#Grenzen-des-Bag-of-Words-Modells\" data-toc-modified-id=\"Grenzen-des-Bag-of-Words-Modells-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Grenzen des Bag-of-Words Modells</a></span></li></ul></li><li><span><a href=\"#LSA\" data-toc-modified-id=\"LSA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSA</a></span></li><li><span><a href=\"#Word-Embeddings\" data-toc-modified-id=\"Word-Embeddings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word Embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"#Allgemeines\" data-toc-modified-id=\"Allgemeines-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Allgemeines</a></span></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Word2Vec</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vortrainierte-Embeddings-verwenden\" data-toc-modified-id=\"Vortrainierte-Embeddings-verwenden-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Vortrainierte Embeddings verwenden</a></span></li><li><span><a href=\"#Eigene-Embeddings-trainieren\" data-toc-modified-id=\"Eigene-Embeddings-trainieren-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Eigene Embeddings trainieren</a></span></li></ul></li><li><span><a href=\"#GloVe\" data-toc-modified-id=\"GloVe-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>GloVe</a></span></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>FastText</a></span></li></ul></li><li><span><a href=\"#Contextualised-word-embeddings\" data-toc-modified-id=\"Contextualised-word-embeddings-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Contextualised word embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"#Allgemeines\" data-toc-modified-id=\"Allgemeines-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Allgemeines</a></span></li><li><span><a href=\"#ELMo\" data-toc-modified-id=\"ELMo-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>ELMo</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>BERT</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das **Natural Language Processing** (kurz: NLP) befasst sich mit Methoden und Verfahren zur maschinellen Verarbeitung von natürlicher Sprache in Form von Worten, Texten oder ganzen Korpora. Bevor jedoch NLP Verfahren wie die Textklassifikation oder das Topic Modelling auf die Textdaten angewendet werden können, müssen diese in eine Darstellungsweise umgewandelt werden, mit der die Verfahren arbeiten können. Die rohen Textdaten werden daher in **Vektoren**, die aus Zahlen bestehen, umgewandelt. Dieser Vorgang nennt sich **Vektorisierung**. Ein Wort wie \"Baum\" kann dadurch als Vektor aufgefasst werden. Natürlich können auch andere Features aus den Texten als Vektoren dargestellt werden; so ist es auch möglich, einzelne Buchstaben, Phrasen, Sätze, Segmente oder ganze Texte als Features aus den Textdaten zu extrahieren und diese zu vektorisieren. In der folgenden Übersicht werden jedoch vorwiegend Wörter als Features verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Bag-of-Words Modell\n",
    "\n",
    "Das wohl einfachste Verfahren zur Darstellung von Wörtern als Vektoren ist das **Bag-of-Words** Modell. Wörter werden hier als eindimensionale Vektoren (= einfache Zahlen) dargestellt, wobei jedes individuelle Wort einen individuellen eindimensionalen Vektor (auch: **Index**) zugeordnet bekommt. Die Zuordnungen jedes einzigartigen Wortes zu seinem Vektor werden in einem *Vokabular* gespeichert. Nun können mithilfe dieses Vokabulars auch ganze Sätze oder sogar Texte dargestellt werden. Dafür wird für jeden Satz/Text ein Vektor gebildet, der die gleiche Länge wie das Vokabular hat. Jedem Eintrag des Vektors wird anhand des Vokabulars ein Wort zugeordnet. Der Satz/Text wird dann als Vektor aus **absoluten Termhäufigkeiten** dargestellt, wo an jeder Stelle, an dem ein Wort aus dem Vokabular in dem Text vorkommt, die Häufigkeit des Wortes in dem jeweiligen Satz/Text steht und an jeder anderen Stelle eine $0$, da es kein einziges Mal vorkommt.[<sup>1</sup>](#fn1) Dies soll im Folgenden anhand eines Code-Beispiels erläutert werden. Zuerst wird das Vokabular aller Texte dargestellt, bei dem die Wörter einem Index zugeordnet werden (es wird ab $0$ gezählt). Danach werden die vektorisierten Sätze/Texte angezeigt.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn1\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">1</sup> &nbsp;Dies ist nur eine Möglichkeit, die Häufigkeit eines Wortes beim Bag-of-Words Modell darzustellen. Eine weitere Möglichkeit wären <b>binäre Häufigkeiten</b>, bei denen das Vorkommen eines Wortes mit einer $1$ und die Abwesenheit eines Wortes mit einer $0$ gekennzeichnet werden. Um häufigen Wörtern in den Dokumenten weniger Gewicht zu geben, da diese meist einen geringeren Informationsgehalt besitzen, ist es auch möglich, das Bag-of-Words Modell in der Kombination mit dem <b>TF-IDF Maß</b> aus dem Bereich des Information Retrievals zu verwenden, bei dem die Häufigkeit von Worten skaliert wird.</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ich': 10, 'gehe': 6, 'nachher': 16, 'zur': 24, 'bank': 1, 'um': 21, 'etwas': 5, 'geld': 7, 'zu': 23, 'holen': 8, 'möchte': 15, 'mich': 13, 'kurz': 11, 'auf': 0, 'die': 3, 'setzen': 19, 'mir': 14, 'essen': 4, 'stand': 20, 'von': 22, 'der': 2, 'hölzernen': 9, 'neben': 17, 'liegt': 12, 'noch': 18}\n"
     ]
    }
   ],
   "source": [
    "text = [\"ich gehe nachher zur bank, um etwas geld zu holen\",\n",
    "        \"ich möchte mich kurz auf die bank setzen\",\n",
    "        \"um mir etwas zu essen zu holen, stand ich von der bank auf\", \n",
    "        \"auf der hölzernen bank neben der bank liegt noch geld\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vector = vectorizer.fit_transform(text)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1]\n",
      " [1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0]\n",
      " [1 1 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 1 2 0]\n",
      " [1 2 2 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grenzen des Bag-of-Words Modells\n",
    "\n",
    "Aufgrund seiner Einfachheit ist das Bag-of-Words Modell leicht verständlich und sehr schnell umsetzbar. Es hat jedoch eine Reihe an Nachteilen, von denen einige im Folgenden kurz erläutert werden:\n",
    "\n",
    "- **Keine Informationen über Reihenfolge der Wörter.** Beim Bag-of-Words Modell wird jegliche Information über die Reihenfolge der Wörter verworfen, der Kontext eines Wortes bleibt unberücksichtigt. Dies wird auch durch den Namen dieses Modells deutlich: Die Bezeichnung \"bag\" (deutsch: Sack) soll darauf hinweisen, dass alle Informationen über die Struktur oder Reihenfolge der Wörter im Dokument verworfen werden, da sie metaphorisch in einen \"Sack\" geworfen werden. Die Reihenfolge lässt sich auch nicht im Nachhinein rekonstruieren. Insgesamt gehen somit sehr viele semantische Informationen verloren. Eine Lösung, bei der die Reihenfolge der Worte berücksichtigt werden kann, ist die Verwendung von **N-Grammen**, **LSA** (Kapitel 2) oder **contextualised word embeddings** (Kapitel 4). \n",
    "- **Spärlichkeit von Wortvektoren.** Umso mehr verschiedene Worte in den verwendeten Texten vorkommen, umso größer wird das Vokabular. Dies kann oft zu sehr spärlichen (engl. *sparse*) Wortvektoren führen. Besteht das Vokabular aus 500000 Worten, ein Text aber nur aus 50 verschiedenen Worten, sind nur 0.01% der Stellen des 500000 langen Wortvektors mit Einsen besetzt, der Rest nur mit Nullen. Dies führt dazu, dass eine große Menge an Rechenspeicher für die Verarbeitung der riesigen Matrizen benötigt wird. Weiterhin werden wenige Informationen in sehr großen Repräsentationsräumen benutzt, wodurch es für einige NLP Verfahren und Modelle problematisch ist, diese wenigen Informationen effizient zu nutzen. Eine Lösung bieten dichtbesetzte **Word Embeddings**, die in Kapitel 3 und 4 behandelt werden.\n",
    "- **Abbildung der Mehrdeutigkeit von Worten**. Wörter können trotz gleicher Schreibweise mehrere Bedeutungen haben, welche sich durch den Kontext des Wortes zeigen können. Dies wird durch das Bag-of-Words Modell nicht abgebildet. Eine mögliche Lösung wäre die Verwendung von **kontextabhängigen Word Embeddings** wie die **ELMo**- oder **BERT-Embeddings** in Kapitel 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA\n",
    "\n",
    "**Latent Semantic Analysis** (kurz: LSA, auch: *Latent Semantic Indexing*) ist ein Verfahren aus dem Bereich des Information Retrievals aus dem Jahre 1990. Bei diesem Verfahren werden Dokumente und Terme (repräsentiert durch eine **Term-Dokument Matrix**) in einem latenten Raum abgebildet, der aus **Konzepten** (oder **Hauptkomponenten**) besteht. Dokumente, die ähnlich zueinander sind, d.h. aus ähnlichen Konzepten bestehen, werden in diesem Raum näher beieinander platziert. Dies wird durch die folgende Grafik deutlich.\n",
    "\n",
    "\n",
    "![lsa](img/lsa.png)\n",
    "\n",
    "Grafik von Susan Dumais ([Quelle](http://www.ifis.uni-luebeck.de/~moeller/tuhh-lectures/mmieir-sose-12/05-Latent-Semantic-Analysis.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel der LSA ist es, die Konzepte innerhalb der Dokumente zu finden. Dabei greift das Verfahren auf eine Technik der linearen Algebra zurück, der **Singulärwertzerlegung** (englisch: Singular Value Decomposition). Die Idee dabei ist, dass die Term-Dokument Matrix aus **Hauptdimensionen**, welche die wichtigen Konzepte der Dokumente beinhalten, und aus weniger aussagekräftigen Dimensionen mit unwichtigen Termen besteht. Mithilfe der Singulärwertzerlegung wird die originale Term-Dokument Matrix in drei Matrizen aufgeteilt, wobei die beiden äußeren Matrizen aus den linken bzw. rechten orthonormalen Eigenvektoren bestehen und die mittlere Matrix eine Diagonalmatrix ist, die die singulären Werte der Originalmatrix enthält. Mit Hilfe dieser Zerlegung kann eine **Approximation** der Originalmatrix mit einer kleiner dimensionierten Matrix erreicht werden. Die singulären Werte in der Diagonalmatrix sind nach ihrer Größe absteigend geordnet. Singulärwerte, die unter einem bestimmten Schwellenwert liegen, werden entfernt. Auch in den anderen Matrizen werden entsprechende Zeilen oder Spalten entfernt. Mit Hilfe der reduzierten Matrizen erhält man durch Matrixmultiplikation die optimale Approximation der Originalmatrix, die kleiner als die originale Term-Dokument Matrix ist, da Informationen aus den weniger aussagekräftigen Dimensionen verworfen wurden. Weiterhin werden bei der Dimensionsreduktion auch ähnliche Konzepte zusammengefasst, so werden z.B. Worte wie \"Tür\" und \"Tor\" in einem Konzept zusammengefasst.\n",
    "\n",
    "Der Vorteil der LSA ist, dass anders als beim Bag-of-Words Modell die **Semantik** der Dokumente wiedergegeben werden kann. Zudem werden **Synonyme** zusammengefasst. Probleme hat LSA jedoch mit der **Polysemie**. Zudem ist der Algorithmus sehr rechenaufwendig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "## Allgemeines\n",
    "\n",
    "**Word Embeddings** (deutsch: Worteinbettungen) sind die Sammelbezeichnung für eine Reihe von Sprachmodellierungstechniken. Anders als beim Bag-of-Words Modell werden Wörter mit ähnlichen Bedeutungen ähnlich dargestellt, wobei der Kontext der Wörter berücksichtigt wird. Word Embeddings repräsentieren Wörter als Vektoren in einem multidimensionalen semantischen Raum. In diesem Raum werden Wörter, die ähnlich zueinander sind, näher beieinander platziert. Die grundsätzliche Idee von Word Embeddings basiert auf der **Distributionellen Hypothese** von  John Rupert Firth, die besagt, dass die Bedeutung eines Wortes durch sein Umfeld geprägt ist. Wörter, die einen ähnlichen Kontext besitzen, haben eine ähnliche Bedeutung. Anders als vorherige Vektorisierungsmethoden basieren Word Embeddings auf **Vorhersagemodellen** (englisch: **prediction models**)[<sup>2</sup>](#fn2), indem Wörter durch Wahrscheinlichkeiten anstatt durch Häufigkeiten wie beim Bag-of-Words Modell oder bei der Latent Semantic Analysis dargestellt werden. Weiterhin sind die Wortvektoren von Word Embeddings anders als beim Bag-of-Words Modell **dichtbesetzt** (englisch: **dense**) und haben weitaus weniger Dimensionen (100-800 Dimensionen anstatt 100000-1000000, je nach der Größe des Vokabulars). Dadurch haben die Wortvektoren eine viel geringere Größe, bieten trotzdem eine effizientere und komplexere Darstellung der Wörter.\n",
    "\n",
    "Eine weitere Besonderheit von Word Embeddings ist, dass es mit diesen möglich ist, eine Arithmetik mit Wörtern umzusetzen. So kann mit Wortvektoren \"gerechnet\" werden. Folgende Gleichungen sind mit Word Embeddings möglich:\n",
    "\n",
    "`König - Mann + Frau = Königin`<br>\n",
    "\n",
    "`London - Großbritannien + Deutschland = Berlin`\n",
    "\n",
    "\n",
    "Word Embeddings wurden ab 2013 durch die Einführung des Algorithmus **Word2Vec** populär, in den Jahren darauf folgten weitere Word Embedding Algorithmen wie **GloVe**, **FastText**, **ELMo** und **BERT**. In der folgenden Tabelle sind die wichtigsten Unterschiede der hier erläuterten Embeddings zusammengefasst, genauere Erläuterungen dieser Embeddings finden sich in den folgenden Kapiteln. Die darauffolgende Abbildung liefert eine Art Stammbaum der verschiedenen Embedding-Arten.\n",
    "\n",
    "\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn2\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">2</sup> &nbsp;Obwohl GloVe eigentlich kein Vorhersagemodell verwendet, unterscheidet sich GloVe trotzdem stark von vorhergehenden, Häufigkeits-basierenden Modellen, weshalb es oft als Vohersagemodell angesehen wird, siehe LEVY et. al. (2015), Improving Distributional Similarity with Lessons Learned from Word Embeddings, https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf (abgerufen am 31.07.2020).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ausfüllen & mehr, gucken wie anders dargestellt werden kann\n",
    "\n",
    "<table>\n",
    "    <th></th>\n",
    "    <th>Word2Vec</th>\n",
    "    <th>GloVe</th>\n",
    "    <th>FastText</th>\n",
    "    <th>ELMo</th>\n",
    "    <th>BERT</th>\n",
    "    <tr>\n",
    "        <td>Entstehungsjahr</td>\n",
    "        <td>2013</td>\n",
    "        <td>2014</td>\n",
    "        <td>2016</td>\n",
    "        <td>2018</td>\n",
    "        <td>2018</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>Out of vocabulary Fehler</td>\n",
    "        <td>ja</td>\n",
    "        <td>ja</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>Kontextsensitiv</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>nein</td>\n",
    "        <td>ja</td>\n",
    "        <td>ja</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>gelernte Repräsentationen</td>\n",
    "        <td>Wörter</td>\n",
    "        <td>Wörter</td>\n",
    "        <td>Teilwörter</td>\n",
    "        <td>Wörter</td>\n",
    "        <td>Teilwörter</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/all_embeddings.png)\n",
    "\n",
    "Die Grafik wurde von dieser [Webseite](https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598) entnommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Die Popularität von Word Embeddings ist vor allem **Word2Vec** geschuldet, welches 2013 von Tomas Mikolov und weiteren Mitgliedern von Google publiziert wurde ([Paper](https://arxiv.org/abs/1301.3781)). Word2Vec basiert auf einem simplen, aber doch effektiven Feedforward Neuronalen Netz. Word2Vec implementiert zwei verschiedene Ansätze zur Berechnung der Wortwahrscheinlichkeiten: **Continous Bag of Words** (**CBOW**) und das **Skip-gram Modell**. \n",
    "\n",
    "**Continous Bag of Words** versucht die Wahrscheinlichkeit eines Wortes oder einer Gruppe von Wörtern anhand eines gegebenen Kontext vorauszusagen:\n",
    "\n",
    "![cbow](img/cbow.png)\n",
    "\n",
    "\n",
    "Das **Skip-gram Model** funktioniert wie CBOW, nur anders herum. Das Modell versucht, anhand eines gegebenen Wortes den Kontext vorauszusagen:\n",
    "\n",
    "![skip-gram](img/skipgram.png)\n",
    "\n",
    "<br>Word2Vec nutzt wahlweise eine dieser Techniken, um aus rohen Textdaten mithilfe eines Neuronalen Netzes Wortvektoren zu erstellen. Dabei kann Word2Vec bei vielen Implementierungen (z.b. bei Gensim) auf zwei Arten verwendet werden: Entweder werden bereits vortrainierte Embeddings geladen oder es werden eigene Embeddings auf eigenen Textdaten trainiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vortrainierte Embeddings verwenden\n",
    "\n",
    "Für die Demonstration der Nutzung von vortrainierten Word Embeddings wird ein deutsches Modell verwendet, welches auf Wikipedia- und Zeitungsartikeln trainiert wurde ([Quelle](https://devmount.github.io/GermanWordEmbeddings/)). Als Framework wird **Gensim** verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_w2v = gensim.models.KeyedVectors.load_word2vec_format('german_model.bin', \n",
    "                                                          binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code werden die 5 ähnlichsten Wörter zu \"König\" ausgegeben. Alle diese Wörter passen auch thematisch zu \"König\", sie verbindet alle das Thema \"royal\" bzw. \"Königshaus\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prinz: 0.786\n",
      "Koenigs: 0.736\n",
      "Koenigin: 0.726\n",
      "Jungkoenig: 0.705\n",
      "Kaiser: 0.705\n"
     ]
    }
   ],
   "source": [
    "for t in pre_w2v.most_similar('Koenig', topn=5): \n",
    "    print(f\"{t[0]}: {np.around(t[1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch das Rechenbeispiel aus Kapitel 3.1 kann mit Word2Vec umgesetzt werden. Addiert man \"König\" mit \"Frau\" und subtrahiert \"Mann\", erhält man Begriffe zum Thema \"Königin\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koenigin: 0.752\n",
      "Prinzessin: 0.715\n",
      "Prinz: 0.688\n",
      "Jungschuetzenkoenigin: 0.674\n",
      "Majestaet: 0.659\n"
     ]
    }
   ],
   "source": [
    "for t in pre_w2v.most_similar(positive=['Koenig', 'Frau'],\n",
    "                              negative=['Mann'], topn=5):\n",
    "    print(f\"{t[0]}: {np.around(t[1], decimals=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiterhin kann man auch ein Wort mit einer Liste von anderen Wörtern vergleichen und abfragen, welchem Wort aus der Liste das Wort am ähnlichsten ist oder aber man überprüft bei einer Liste von Wörtern, welches Wort nicht passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welches Wort ist am ähnlichsten zu 'Banane'? -> Apfel\n",
      "Welches Wort passt nicht zu den anderen Wörtern? -> Berg\n"
     ]
    }
   ],
   "source": [
    "most_similar = pre_w2v.most_similar_to_given('Banane', ['Koenig', 'Berg', \n",
    "                                                        'Haus', 'Apfel'])\n",
    "doesnt_match = pre_w2v.doesnt_match(['Koenig', 'Thron', 'Berg', 'Prinzessin'])\n",
    "print(f\"Welches Wort ist am ähnlichsten zu 'Banane'? -> {most_similar}\")\n",
    "print(f\"Welches Wort passt nicht zu den anderen Wörtern? -> {doesnt_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plottet man die Wortvektoren der verwandten Wörter (hier die 5 ähnlichsten Wörter), werden die einzelnen Themen sehr gut sichtbar, da sie Cluster bilden und sich von anderen Themen abgrenzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordlist = ['Haus', 'Berg', 'Koenig', 'gehen']\n",
    "plot_word_embeddings(pre_w2v, wordlist, figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigene Embeddings trainieren\n",
    "\n",
    "Es ist auch möglich, eigene Embeddings zu trainieren. Dabei muss sich zuvor für die Technik **CBOW** oder **Skip-gram** entschieden werden (wird durch den Parameter `sg`gesteuert). Es wurde der englische Datensatz **Amazon Reviews** verwendet ([Quelle](https://nijianmo.github.io/amazon/index.html)). Dieser wurde für Demonstrationszwecke auf Reviews zu elektronischen Geräten aus dem Jahr 2018 gekürzt. Auch hier passen die ähnlichsten 5 Wörter sehr gut zum ausgewählten Wort *smartphone*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 16s, sys: 5.09 s, total: 6min 21s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2vec_cbow = Word2Vec(texts, min_count=1, size=100, window=5, sg=0)\n",
    "word2vec_skipgram = Word2Vec(texts, min_count=1, size=100, window=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iphone', 0.7328867316246033),\n",
       " ('cell', 0.6630538702011108),\n",
       " ('phones', 0.6511064767837524),\n",
       " ('smartphone', 0.6296558976173401),\n",
       " ('computer', 0.6081698536872864)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cbow.wv.most_similar('phone', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe\n",
    "\n",
    "**GloVe** (= Global Vectors) wurde 2014 von Pennigton et. al. veröffentlicht ([Paper](https://nlp.stanford.edu/pubs/glove.pdf)). Vor der Veröffentlichung von GloVe ließen sich die Wortvektorisierungsmethoden in zwei Hauptströmungen unterteilen: das Statistik-basierende **LDA**[<sup>3</sup>](#fn3) und das lernbasierte **Word2Vec**. Während LDA Wörter mithilfe von Häufigkeiten in einer Kookkurrenz-Matrix darstellt, verwendet Word2Vec zur Darstellung der Wörter Wortwahrscheinlichkeiten, die mithilfe eines Voraussage-Modells erstellt wurden. **GloVe** verwendet für die Darstellung der Häufigkeiten wie LDA eine Kookkurrenz-Matrix, wobei GloVe die Häufigkeiten vorher normalisiert und mithilfe des Logarithmus \"*glättet*\" (englisch: *smoothing*). Anders als Word2Vec benutzt es für die Erstellung der Embeddings also keine neuronalen Netze, die erst durch ein Training die Wortbeziehungen erlernen, sondern die Beziehungen werden **global** (daher auch der Name) mithilfe einer Mischung aus maschinellem Lernen und statischen Verfahren aus den Texten gewonnen.\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn3\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">3</sup> &nbsp;<b>LDA</b> steht für \"Latent Dirichlet allocation\" und ist ein Algorithmus, der Wörter ähnlichen Gruppen anhand der Wahrscheinlichkeit, dass sie zusammen in einem Dokument vorkommen, zuordnet.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Demonstration der Glove-Embeddings wurde die Bibliothek **Flair** verwendet. Jeder Vektor für jedes Token-Embedding hat eine Länge von 100, es wurden jedoch nur die ersten drei Zahlen ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'smartphones': tensor([-0.2138, -0.3245,  0.2806]) (Vektorlänge: 100)\n",
      "'have': tensor([0.1571, 0.6561, 0.0021]) (Vektorlänge: 100)\n",
      "'a': tensor([-0.2709,  0.0440, -0.0203]) (Vektorlänge: 100)\n",
      "'touchscreen': tensor([-0.7974,  0.1240,  0.7148]) (Vektorlänge: 100)\n"
     ]
    }
   ],
   "source": [
    "string = \"smartphones have a touchscreen\"\n",
    "sentence = Sentence(string, use_tokenizer=True)\n",
    "glove_embeddings = WordEmbeddings('glove').embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(f\"'{token.text}': {token.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token.embedding)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText\n",
    "\n",
    "**Word2Vec** und **GloVe** haben Probleme damit, unbekannte Wörter zu verarbeiten. Dieser Fehler nennt sich **out of vocabulary** (**OOV**), da das Wort nicht im bekannten Vokabular der Embeddings vorkommt. Es ist zwar möglich, unbekannten Wörtern ein zufälliges Embedding zuzuweisen, jedoch ist dies vor allem problematisch, wenn das unbekannte Wort ein Schlüsselwort im untersuchten Text ist. Eine Embedding Verfahren, welches das OOV Problem löst, ist **FastText**, welches 2016 von Bojanowski et. al. veröffentlicht wurde ([Paper](https://arxiv.org/abs/1607.04606)). FastText löst das OOV-Problem, indem es Wörter mithilfe von Buchstaben N-Grammen in einzelne Teilwörter aufteilt. Während des Trainings lernt FastText die Buchstaben N-Gramme der Teilwörter. Bei einem unbekannten Wort wird ein Embedding dieses Wortes erzeugt, indem der Mittelwert der Vektorrepräsentationen der verschiedenen Buchstaben N-Gramm-Embeddings gebildet wird. Zwar kann FastText so mit unbekannten Wörtern umgehen, eine optimale Lösung für das Problem ist dies jedoch nicht, da Wörter zwar aus ähnlichen Buchstaben N-Gramm-Bestandteilen bestehen, sich aber semantisch trotzdem stark voneinander unterscheiden können.\n",
    "\n",
    "Im Folgenden wird die Funktionsweise von FastText-Embeddings anhand eines Beispielsatzes demonstriert. Wie bei den GloVe-Embeddings auch wird hier die Bibliothek **Flair** verwendet. Der folgende Code erzeugt sowohl für das FastText-Embedding als auch für das GloVe-Embedding einen OOV-Fehler für das Wort \"tensorflow\", dargestellt durch einen Wortvektor, der nur aus Nullen besteht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GloVe] 'tensorflow': tensor([0., 0., 0.]) (Vektorlänge: 100)\n",
      "[FastText] 'tensorflow': tensor([0., 0., 0.]) (Vektorlänge: 300)\n"
     ]
    }
   ],
   "source": [
    "string2 = \"tensorflow is a library\"\n",
    "sentence2 = Sentence(string2, use_tokenizer=True)\n",
    "sentence3 = Sentence(string2, use_tokenizer=True)\n",
    "glove_embedding2 = WordEmbeddings('glove').embed(sentence2)\n",
    "fasttext_embedding2 = WordEmbeddings('en').embed(sentence3)\n",
    "\n",
    "for token1, token2 in zip(sentence2, sentence3):\n",
    "    print(f\"[GloVe] '{token1.text}': {token1.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token1.embedding)})\")\n",
    "    print(f\"[FastText] '{token2.text}': {token2.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token2.embedding)})\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um keinen OOV-Fehler zu erzeugen, muss anstatt der Klasse `WordEmbeddings` die Klasse `FastTextEmbeddings` in Kombination mit einem selbst heruntergeladen englischen Model verwendet werden ([Link zum Modell](https://fasttext.cc/docs/en/pretrained-vectors.html)). Nun kann das Wort \"tensorflow\" dargestellt werden.[<sup>4</sup>](#fn4)\n",
    "\n",
    "<hr style=\"border: 0.1px solid black;\"/>\n",
    "<div id=\"fn4\" style=\"font-size:8pt; line-height:1; padding-left: 1em; text-indent: -1em\"><sup style=\"font-size:5pt\">4</sup> &nbsp;Da die FastText-Embeddings sehr groß sind, wurden die Wortvektoren extern berechnet, hier werden nur die Ergebnisse angezeigt.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tensorflow': tensor([-0.0790, -0.0390,  0.0030]) \n",
      "'is': tensor([-0.0980, -0.2080, -0.1040]) \n",
      "'a': tensor([ 0.0880, -0.4960, -0.0500]) \n",
      "'library': tensor([ 0.0000,  0.0320, -0.0270]) \n"
     ]
    }
   ],
   "source": [
    "# sentence4 = Sentence(string2, use_tokenizer=True)\n",
    "# fasttext_embedding = FastTextEmbeddings('cc.en.300.bin').embed(sentence4)\n",
    "with open(\"fasttext.json\", \"r\") as f:\n",
    "    sentence4_worddict = json.load(f)\n",
    "    for k, v in sentence4_worddict.items():\n",
    "         print(f\"'{k}': {np.around(torch.tensor(v), decimals=3)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualised word embeddings\n",
    "\n",
    "## Allgemeines\n",
    "\n",
    "Seit ihrer Einführung wurden vortrainierte Word Embeddings als bevorzugte Vektorisierungsmethode für Neuronale Netze verwendet. Word Embeddings wie Word2Vec, GloVe oder FastText haben jedoch das Problem, dass sie **statische** Wortrepräsentationen liefern. Das Embedding eines Wortes ist immer gleich, egal in welchem Kontext es auftaucht. \n",
    "\n",
    "`Ich sitze auf der Bank.`<br>\n",
    "\n",
    "`Ich hole Geld von der Bank.`\n",
    "\n",
    "Betrachtet man die beiden Beispielsätze, hat das Wort \"Bank\" eine unterschiedliche Bedeutung (Sitzgelegenheit/Möbelstück und Kreditinstitut), wird von den statischen Word Embeddings aber als gleicher Wortvektor aufgefasst. Statische Word Embeddings haben zwei Limitierungen:\n",
    "\n",
    "1. Die Bedeutung eines Wortes, die sich durch den Kontext ergibt, wird ignoriert.\n",
    "2. Semantische Phänomene wie langfristige Abhängigkeiten oder die Kompositionalität eines Satzes bleiben unberücksichtigt.\n",
    "\n",
    "\n",
    "Eine Lösung bieten die in den letzten Jahren veröffentlichten **contextualised word embeddings** wie **ELMo** oder **BERT**. Diese Word Embeddings bieten eine **dynamische** Wortrepräsentation, sodass Worte, die die gleiche Schreibweise besitzen, durch unterschiedliche Vektoren dargestellt werden können, je nachdem in welchem Kontext sie sich befinden oder in welcher Reihenfolge sie vorkommen.\n",
    "\n",
    "**Contextualised word embeddings** unterscheiden sich von den statischen Word Embeddings ebenfalls in der Hinsicht, dass das Modell, mit denen die Embeddings trainiert wurden, für weitere Anwendungen der Embeddings verwendet werden muss. Möchte man beispielsweise ein  Neuronales Netz trainieren, reicht es bei statischen Word Embeddings, lediglich die Wortvektoren in einem Embedding Layer zu verwenden. Bei den kontextualisierten Word Embeddings wird zusätzlich das Modell benötigt, da diese den Wortvektor anhand der umliegenden Wörter erstellen. Dies wird durch die folgende Grafik deutlich:\n",
    "\n",
    "\n",
    "![](img/difference_embeddings.png)\n",
    "\n",
    "Die Grafik wurde von dieser [Webseite](https://www.quora.com/What-were-the-most-significant-Natural-Language-Processing-advances-in-2018/answer/Ajit-Rajasekharan) entnommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo\n",
    "\n",
    "**ELMo** (= Embeddings from Language Models) wurde Anfang 2018 von Peters et. al. veröffentlicht ([Paper](https://arxiv.org/abs/1802.05365)). Für das Training von Embeddings verwendet ELMo ein **tiefes bidirektionales LSTM Language Model**. Language Models werden dazu verwendet, anhand von vorangegangen Wörtern das nächste Wort in einem Satz vorauszusagen. Dazu müssen Language Models sowohl die semantischen als auch die syntaktischen Eigenschaften von Wörtern kodieren, welches sie zu geeignten Modellen für die Darstellung von Wörtern macht. Die Bidirektionalität erlaubt es ELMo, nicht nur vorhergehende Wörter, sondern auch nachfolgende Wörter für die Vorausage eines Wortes zu verwenden. ELMo agiert beim Training nicht auf der Wortebene, sondern verwendet ähnlich wie FastText Buchstabenvektoren, womit Wörter unter Benutzung eines Lernmodells oder der Mittelwertsbildung der Wortvektoren gebaut und das OOV-Problem umgangen werden kann. Trotzdem sind die ausgegeben Vektoren letztendlich Wortvektoren und keine Buchstaben- oder Teilwortvektoren.\n",
    "\n",
    "Im Folgenden wird anhand eines Beispielsatzes die Funktionsweise der ELMo-Embedding mithilfe der Bibliothek **Flair** demonstriert. Beim Beispielsatz hat das Wort \"apple\" mehrere Bedeutungen, einmal ist das Unternehmen gemeint und einmal die Frucht. Vergleicht man die beiden Vektoren, erkennt man, dass diese durch unterschiedliche Vektoren dargestellt werden. Anders als bei vorherigen Embedding-Verfahren wird die Mehrdeutigkeit also dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'apple': tensor([0.1444, 0.0678, 0.3774]) (Vektorlänge: 3072)\n",
      "'is': tensor([ 0.1915,  0.2300, -0.2894]) (Vektorlänge: 3072)\n",
      "'a': tensor([ 0.1040,  0.1229, -0.0706]) (Vektorlänge: 3072)\n",
      "'company': tensor([ 0.6496,  0.0804, -0.5390]) (Vektorlänge: 3072)\n",
      "'but': tensor([-0.2404, -0.2742, -0.2190]) (Vektorlänge: 3072)\n",
      "'an': tensor([ 0.0797,  0.1992, -0.0695]) (Vektorlänge: 3072)\n",
      "'apple': tensor([0.1444, 0.0678, 0.3774]) (Vektorlänge: 3072)\n",
      "'is': tensor([ 0.1915,  0.2300, -0.2894]) (Vektorlänge: 3072)\n",
      "'also': tensor([ 0.8475, -0.2688,  0.2739]) (Vektorlänge: 3072)\n",
      "'a': tensor([ 0.1040,  0.1229, -0.0706]) (Vektorlänge: 3072)\n",
      "'fruit': tensor([-0.5279,  0.3975,  0.8766]) (Vektorlänge: 3072)\n"
     ]
    }
   ],
   "source": [
    "sentence5 = Sentence('apple is a company but an apple is also a fruit')\n",
    "ELMoEmbeddings(\"original\").embed(sentence5)\n",
    "\n",
    "elmo_tensors = []\n",
    "\n",
    "for token in sentence5:\n",
    "    if token.text == \"apple\":\n",
    "        elmo_tensors.append(token.embedding)\n",
    "    print(f\"'{token.text}': {token.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token.embedding)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Vektoren der beiden unterschiedlichen Bedeutungen von 'apple' unterscheiden sich bei ELMo in 2045 von 3072 Stellen.\n"
     ]
    }
   ],
   "source": [
    "diff = elmo_tensors[1] - elmo_tensors[0]\n",
    "print(\"Die Vektoren der beiden unterschiedlichen Bedeutungen \" +\n",
    "      \"von 'apple' unterscheiden sich bei ELMo in \" +\n",
    "      f\"{len([i for i in diff.tolist() if i != 0])} von 3072 Stellen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "**BERT** (= Bidirectional Encoder Representations from Transformers) gehört wie **ELMo** zu den **contextualised word embeddings** und wurde Ende 2018 von Devlin et. al. veröffentlicht ([Paper](https://arxiv.org/abs/1810.04805)). BERT baut auf der bidirektionalen Idee von ELMo auf, verwendet anstatt einem LSTM-Modell jedoch ein **Transformers**-Modell um die Embeddings zu berechnen. Beim Training verwendete BERT den sogenannten **Attention**-Mechanismus des **Transformers**-Modell, der es erlaubt, relevanten Worten in einer Sequenz mehr Bedeutung als anderen Worten zuzuschreiben. Anders als vorhergehende Implementierungen des Attention-Mechanismus verwendete BERT anstatt eines unidirektionalen einen **bidirektionalen** Ansatz, bei dem nicht nur nachfolgende, sondern auch vorhergehende Wörter betrachtet wurden. Der bidirektionale Ansatz ist jedoch in dem Sinne problematisch, dass er Wörtern erlaubt, sich indirekt \"selbst zu sehen\", wodurch das Modell in der Lage wäre, das Zielwort relativ einfach vorauszusagen.\n",
    "    \n",
    "Zur Lösung dieses Problems benutzte BERT die Konzepte **Next Sentence Prediction** und **Masked Language Modeling**. Bei der **Next Sentence Prediction** (NSP) prüft BERT, ob ein nachfolgender Satz kontextuell zum vorherigen Satz passt. Das **Masked Language Modeling** (MLM) ist eine spezielle Form des Language Modelings. Dabei werden zufällig 15% der Wörter in jedem Satz der Trainingsdaten ausgewählt, von denen wiederum 80% durch ein spezielles Maskierungstoken ausgetauscht, 10% durch ein zufälliges Wort aus dem Vokabular des Korpus ersetzt und 10% der Wörter nicht verändert werden. BERT versuchte dann im Training, die ausgewählten Tokens vorauszusagen, wozu es die umliegenden, nicht maskierten Wörter verwendete. Dadurch berücksichtigen die gelernten Gewichte anders als Word2Vec oder GloVe den Kontext eines Wortes, was es BERT erlaubt, zwischen mehrdeutigen Wörtern zu unterscheiden. Um das OOV-Problem zu umgehen, verwendete BERT ähnlich wie FastText keine ganzen Wörter, sondern Teilwörter, mithilfe derer verschiedene Wörter zusammengebaut werden können.\n",
    "   \n",
    "Im Folgenden wird anhand eines Beispielsatzes die Funktionsweise der BERT-Embedding mithilfe der Bibliothek **Flair** demonstriert. Beim Beispielsatz hat das Wort \"apple\" mehrere Bedeutungen, einmal ist das Unternehmen gemeint und einmal die Frucht. Vergleicht man die beiden Vektoren, erkennt man, dass diese durch unterschiedliche Vektoren dargestellt werden. Anders als noch bei ELMo unterscheiden sich diese Vektoren vollends voneinander, sie haben keine gemeinsamen Stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'apple': tensor([ 0.3007,  0.4433, -0.2990]) (Vektorlänge: 3072)\n",
      "'is': tensor([-0.1345, -0.1533, -0.1418]) (Vektorlänge: 3072)\n",
      "'a': tensor([-0.0250, -0.0645,  0.1348]) (Vektorlänge: 3072)\n",
      "'company': tensor([ 0.2446, -0.1140,  0.0695]) (Vektorlänge: 3072)\n",
      "'but': tensor([-0.2657, -0.2901,  0.1341]) (Vektorlänge: 3072)\n",
      "'an': tensor([-0.1693,  1.0000, -0.0986]) (Vektorlänge: 3072)\n",
      "'apple': tensor([ 0.0220,  0.8081, -0.1181]) (Vektorlänge: 3072)\n",
      "'is': tensor([-0.3891,  0.3975,  0.1520]) (Vektorlänge: 3072)\n",
      "'also': tensor([-0.7347, -0.0557, -0.2733]) (Vektorlänge: 3072)\n",
      "'a': tensor([-0.1067,  0.3567,  0.2085]) (Vektorlänge: 3072)\n",
      "'fruit': tensor([-0.1865,  0.4674, -0.2058]) (Vektorlänge: 3072)\n"
     ]
    }
   ],
   "source": [
    "sentence6 = Sentence('apple is a company but an apple is also a fruit')\n",
    "BertEmbeddings().embed(sentence6)\n",
    "\n",
    "bert_tensors = []\n",
    "\n",
    "for token in sentence6:\n",
    "    if token.text == \"apple\":\n",
    "        bert_tensors.append(token.embedding)\n",
    "    print(f\"'{token.text}': {token.embedding[:3]} \" +\n",
    "          f\"(Vektorlänge: {len(token.embedding)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Vektoren der beiden unterschiedlichen Bedeutungen von 'apple' unterscheiden sich bei BERT in 3072 von 3072 Stellen.\n"
     ]
    }
   ],
   "source": [
    "diff = bert_tensors[1] - bert_tensors[0]\n",
    "print(\"Die Vektoren der beiden unterschiedlichen Bedeutungen \" +\n",
    "      \"von 'apple' unterscheiden sich bei BERT in \" +\n",
    "      f\"{len([i for i in diff.tolist() if i != 0])} von 3072 Stellen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Inhalte",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.43478393554688px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
