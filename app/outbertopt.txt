INFO: Starting optimization.
INFO: Argument combination 1/9.
INFO: Learning rate: 2e-05.
INFO: Split number: 1.
2020-08-27 16:29:43.637876: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 16:29:43.637909: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:25.
Batch   100  of  4,500.    Elapsed: 0:00:41.
Batch   150  of  4,500.    Elapsed: 0:00:57.
Batch   200  of  4,500.    Elapsed: 0:01:13.
Batch   250  of  4,500.    Elapsed: 0:01:29.
Batch   300  of  4,500.    Elapsed: 0:01:46.
Batch   350  of  4,500.    Elapsed: 0:02:02.
Batch   400  of  4,500.    Elapsed: 0:02:18.
Batch   450  of  4,500.    Elapsed: 0:02:35.
Batch   500  of  4,500.    Elapsed: 0:02:51.
Batch   550  of  4,500.    Elapsed: 0:03:07.
Batch   600  of  4,500.    Elapsed: 0:03:24.
Batch   650  of  4,500.    Elapsed: 0:03:40.
Batch   700  of  4,500.    Elapsed: 0:03:57.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:30.
Batch   850  of  4,500.    Elapsed: 0:04:46.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:35.
Batch 1,050  of  4,500.    Elapsed: 0:05:52.
Batch 1,100  of  4,500.    Elapsed: 0:06:08.
Batch 1,150  of  4,500.    Elapsed: 0:06:25.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:14.
Batch 1,350  of  4,500.    Elapsed: 0:07:31.
Batch 1,400  of  4,500.    Elapsed: 0:07:47.
Batch 1,450  of  4,500.    Elapsed: 0:08:04.
Batch 1,500  of  4,500.    Elapsed: 0:08:20.
Batch 1,550  of  4,500.    Elapsed: 0:08:36.
Batch 1,600  of  4,500.    Elapsed: 0:08:53.
Batch 1,650  of  4,500.    Elapsed: 0:09:09.
Batch 1,700  of  4,500.    Elapsed: 0:09:26.
Batch 1,750  of  4,500.    Elapsed: 0:09:42.
Batch 1,800  of  4,500.    Elapsed: 0:09:59.
Batch 1,850  of  4,500.    Elapsed: 0:10:15.
Batch 1,900  of  4,500.    Elapsed: 0:10:32.
Batch 1,950  of  4,500.    Elapsed: 0:10:48.
Batch 2,000  of  4,500.    Elapsed: 0:11:05.
Batch 2,050  of  4,500.    Elapsed: 0:11:21.
Batch 2,100  of  4,500.    Elapsed: 0:11:38.
Batch 2,150  of  4,500.    Elapsed: 0:11:54.
Batch 2,200  of  4,500.    Elapsed: 0:12:11.
Batch 2,250  of  4,500.    Elapsed: 0:12:27.
Batch 2,300  of  4,500.    Elapsed: 0:12:43.
Batch 2,350  of  4,500.    Elapsed: 0:13:00.
Batch 2,400  of  4,500.    Elapsed: 0:13:16.
Batch 2,450  of  4,500.    Elapsed: 0:13:33.
Batch 2,500  of  4,500.    Elapsed: 0:13:49.
Batch 2,550  of  4,500.    Elapsed: 0:14:06.
Batch 2,600  of  4,500.    Elapsed: 0:14:22.
Batch 2,650  of  4,500.    Elapsed: 0:14:39.
Batch 2,700  of  4,500.    Elapsed: 0:14:55.
Batch 2,750  of  4,500.    Elapsed: 0:15:11.
Batch 2,800  of  4,500.    Elapsed: 0:15:28.
Batch 2,850  of  4,500.    Elapsed: 0:15:44.
Batch 2,900  of  4,500.    Elapsed: 0:16:01.
Batch 2,950  of  4,500.    Elapsed: 0:16:17.
Batch 3,000  of  4,500.    Elapsed: 0:16:34.
Batch 3,050  of  4,500.    Elapsed: 0:16:50.
Batch 3,100  of  4,500.    Elapsed: 0:17:07.
Batch 3,150  of  4,500.    Elapsed: 0:17:24.
Batch 3,200  of  4,500.    Elapsed: 0:17:40.
Batch 3,250  of  4,500.    Elapsed: 0:17:57.
Batch 3,300  of  4,500.    Elapsed: 0:18:14.
Batch 3,350  of  4,500.    Elapsed: 0:18:31.
Batch 3,400  of  4,500.    Elapsed: 0:18:47.
Batch 3,450  of  4,500.    Elapsed: 0:19:04.
Batch 3,500  of  4,500.    Elapsed: 0:19:21.
Batch 3,550  of  4,500.    Elapsed: 0:19:38.
Batch 3,600  of  4,500.    Elapsed: 0:19:55.
Batch 3,650  of  4,500.    Elapsed: 0:20:11.
Batch 3,700  of  4,500.    Elapsed: 0:20:28.
Batch 3,750  of  4,500.    Elapsed: 0:20:45.
Batch 3,800  of  4,500.    Elapsed: 0:21:02.
Batch 3,850  of  4,500.    Elapsed: 0:21:19.
Batch 3,900  of  4,500.    Elapsed: 0:21:36.
Batch 3,950  of  4,500.    Elapsed: 0:21:52.
Batch 4,000  of  4,500.    Elapsed: 0:22:09.
Batch 4,050  of  4,500.    Elapsed: 0:22:26.
Batch 4,100  of  4,500.    Elapsed: 0:22:43.
Batch 4,150  of  4,500.    Elapsed: 0:23:00.
Batch 4,200  of  4,500.    Elapsed: 0:23:17.
Batch 4,250  of  4,500.    Elapsed: 0:23:33.
Batch 4,300  of  4,500.    Elapsed: 0:23:50.
Batch 4,350  of  4,500.    Elapsed: 0:24:07.
Batch 4,400  of  4,500.    Elapsed: 0:24:24.
Batch 4,450  of  4,500.    Elapsed: 0:24:41.

  Average training loss: 0.62
  Training epoch took: 0:24:58

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.57
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:08.
Batch   250  of  4,500.    Elapsed: 0:01:25.
Batch   300  of  4,500.    Elapsed: 0:01:42.
Batch   350  of  4,500.    Elapsed: 0:01:58.
Batch   400  of  4,500.    Elapsed: 0:02:15.
Batch   450  of  4,500.    Elapsed: 0:02:32.
Batch   500  of  4,500.    Elapsed: 0:02:49.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:30.
Batch   850  of  4,500.    Elapsed: 0:04:47.
Batch   900  of  4,500.    Elapsed: 0:05:04.
Batch   950  of  4,500.    Elapsed: 0:05:21.
Batch 1,000  of  4,500.    Elapsed: 0:05:37.
Batch 1,050  of  4,500.    Elapsed: 0:05:54.
Batch 1,100  of  4,500.    Elapsed: 0:06:11.
Batch 1,150  of  4,500.    Elapsed: 0:06:28.
Batch 1,200  of  4,500.    Elapsed: 0:06:45.
Batch 1,250  of  4,500.    Elapsed: 0:07:01.
Batch 1,300  of  4,500.    Elapsed: 0:07:18.
Batch 1,350  of  4,500.    Elapsed: 0:07:34.
Batch 1,400  of  4,500.    Elapsed: 0:07:51.
Batch 1,450  of  4,500.    Elapsed: 0:08:07.
Batch 1,500  of  4,500.    Elapsed: 0:08:23.
Batch 1,550  of  4,500.    Elapsed: 0:08:40.
Batch 1,600  of  4,500.    Elapsed: 0:08:56.
Batch 1,650  of  4,500.    Elapsed: 0:09:13.
Batch 1,700  of  4,500.    Elapsed: 0:09:29.
Batch 1,750  of  4,500.    Elapsed: 0:09:45.
Batch 1,800  of  4,500.    Elapsed: 0:10:02.
Batch 1,850  of  4,500.    Elapsed: 0:10:18.
Batch 1,900  of  4,500.    Elapsed: 0:10:35.
Batch 1,950  of  4,500.    Elapsed: 0:10:51.
Batch 2,000  of  4,500.    Elapsed: 0:11:07.
Batch 2,050  of  4,500.    Elapsed: 0:11:24.
Batch 2,100  of  4,500.    Elapsed: 0:11:40.
Batch 2,150  of  4,500.    Elapsed: 0:11:57.
Batch 2,200  of  4,500.    Elapsed: 0:12:13.
Batch 2,250  of  4,500.    Elapsed: 0:12:30.
Batch 2,300  of  4,500.    Elapsed: 0:12:46.
Batch 2,350  of  4,500.    Elapsed: 0:13:03.
Batch 2,400  of  4,500.    Elapsed: 0:13:19.
Batch 2,450  of  4,500.    Elapsed: 0:13:35.
Batch 2,500  of  4,500.    Elapsed: 0:13:52.
Batch 2,550  of  4,500.    Elapsed: 0:14:08.
Batch 2,600  of  4,500.    Elapsed: 0:14:24.
Batch 2,650  of  4,500.    Elapsed: 0:14:41.
Batch 2,700  of  4,500.    Elapsed: 0:14:57.
Batch 2,750  of  4,500.    Elapsed: 0:15:14.
Batch 2,800  of  4,500.    Elapsed: 0:15:30.
Batch 2,850  of  4,500.    Elapsed: 0:15:47.
Batch 2,900  of  4,500.    Elapsed: 0:16:03.
Batch 2,950  of  4,500.    Elapsed: 0:16:19.
Batch 3,000  of  4,500.    Elapsed: 0:16:34.
Batch 3,050  of  4,500.    Elapsed: 0:16:50.
Batch 3,100  of  4,500.    Elapsed: 0:17:06.
Batch 3,150  of  4,500.    Elapsed: 0:17:22.
Batch 3,200  of  4,500.    Elapsed: 0:17:37.
Batch 3,250  of  4,500.    Elapsed: 0:17:53.
Batch 3,300  of  4,500.    Elapsed: 0:18:09.
Batch 3,350  of  4,500.    Elapsed: 0:18:24.
Batch 3,400  of  4,500.    Elapsed: 0:18:40.
Batch 3,450  of  4,500.    Elapsed: 0:18:56.
Batch 3,500  of  4,500.    Elapsed: 0:19:12.
Batch 3,550  of  4,500.    Elapsed: 0:19:27.
Batch 3,600  of  4,500.    Elapsed: 0:19:43.
Batch 3,650  of  4,500.    Elapsed: 0:19:59.
Batch 3,700  of  4,500.    Elapsed: 0:20:15.
Batch 3,750  of  4,500.    Elapsed: 0:20:30.
Batch 3,800  of  4,500.    Elapsed: 0:20:46.
Batch 3,850  of  4,500.    Elapsed: 0:21:02.
Batch 3,900  of  4,500.    Elapsed: 0:21:18.
Batch 3,950  of  4,500.    Elapsed: 0:21:33.
Batch 4,000  of  4,500.    Elapsed: 0:21:49.
Batch 4,050  of  4,500.    Elapsed: 0:22:05.
Batch 4,100  of  4,500.    Elapsed: 0:22:21.
Batch 4,150  of  4,500.    Elapsed: 0:22:36.
Batch 4,200  of  4,500.    Elapsed: 0:22:52.
Batch 4,250  of  4,500.    Elapsed: 0:23:08.
Batch 4,300  of  4,500.    Elapsed: 0:23:24.
Batch 4,350  of  4,500.    Elapsed: 0:23:39.
Batch 4,400  of  4,500.    Elapsed: 0:23:55.
Batch 4,450  of  4,500.    Elapsed: 0:24:11.

  Average training loss: 0.47
  Training epoch took: 0:24:26

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.60
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:16.
Batch   100  of  4,500.    Elapsed: 0:00:32.
Batch   150  of  4,500.    Elapsed: 0:00:47.
Batch   200  of  4,500.    Elapsed: 0:01:03.
Batch   250  of  4,500.    Elapsed: 0:01:19.
Batch   300  of  4,500.    Elapsed: 0:01:35.
Batch   350  of  4,500.    Elapsed: 0:01:51.
Batch   400  of  4,500.    Elapsed: 0:02:07.
Batch   450  of  4,500.    Elapsed: 0:02:23.
Batch   500  of  4,500.    Elapsed: 0:02:40.
Batch   550  of  4,500.    Elapsed: 0:02:56.
Batch   600  of  4,500.    Elapsed: 0:03:13.
Batch   650  of  4,500.    Elapsed: 0:03:29.
Batch   700  of  4,500.    Elapsed: 0:03:45.
Batch   750  of  4,500.    Elapsed: 0:04:02.
Batch   800  of  4,500.    Elapsed: 0:04:18.
Batch   850  of  4,500.    Elapsed: 0:04:35.
Batch   900  of  4,500.    Elapsed: 0:04:51.
Batch   950  of  4,500.    Elapsed: 0:05:08.
Batch 1,000  of  4,500.    Elapsed: 0:05:24.
Batch 1,050  of  4,500.    Elapsed: 0:05:40.
Batch 1,100  of  4,500.    Elapsed: 0:05:56.
Batch 1,150  of  4,500.    Elapsed: 0:06:12.
Batch 1,200  of  4,500.    Elapsed: 0:06:28.
Batch 1,250  of  4,500.    Elapsed: 0:06:43.
Batch 1,300  of  4,500.    Elapsed: 0:06:59.
Batch 1,350  of  4,500.    Elapsed: 0:07:15.
Batch 1,400  of  4,500.    Elapsed: 0:07:30.
Batch 1,450  of  4,500.    Elapsed: 0:07:46.
Batch 1,500  of  4,500.    Elapsed: 0:08:02.
Batch 1,550  of  4,500.    Elapsed: 0:08:18.
Batch 1,600  of  4,500.    Elapsed: 0:08:33.
Batch 1,650  of  4,500.    Elapsed: 0:08:49.
Batch 1,700  of  4,500.    Elapsed: 0:09:05.
Batch 1,750  of  4,500.    Elapsed: 0:09:21.
Batch 1,800  of  4,500.    Elapsed: 0:09:36.
Batch 1,850  of  4,500.    Elapsed: 0:09:52.
Batch 1,900  of  4,500.    Elapsed: 0:10:08.
Batch 1,950  of  4,500.    Elapsed: 0:10:23.
Batch 2,000  of  4,500.    Elapsed: 0:10:40.
Batch 2,050  of  4,500.    Elapsed: 0:10:57.
Batch 2,100  of  4,500.    Elapsed: 0:11:14.
Batch 2,150  of  4,500.    Elapsed: 0:11:30.
Batch 2,200  of  4,500.    Elapsed: 0:11:47.
Batch 2,250  of  4,500.    Elapsed: 0:12:04.
Batch 2,300  of  4,500.    Elapsed: 0:12:21.
Batch 2,350  of  4,500.    Elapsed: 0:12:38.
Batch 2,400  of  4,500.    Elapsed: 0:12:55.
Batch 2,450  of  4,500.    Elapsed: 0:13:12.
Batch 2,500  of  4,500.    Elapsed: 0:13:28.
Batch 2,550  of  4,500.    Elapsed: 0:13:45.
Batch 2,600  of  4,500.    Elapsed: 0:14:02.
Batch 2,650  of  4,500.    Elapsed: 0:14:19.
Batch 2,700  of  4,500.    Elapsed: 0:14:36.
Batch 2,750  of  4,500.    Elapsed: 0:14:53.
Batch 2,800  of  4,500.    Elapsed: 0:15:10.
Batch 2,850  of  4,500.    Elapsed: 0:15:26.
Batch 2,900  of  4,500.    Elapsed: 0:15:43.
Batch 2,950  of  4,500.    Elapsed: 0:16:00.
Batch 3,000  of  4,500.    Elapsed: 0:16:17.
Batch 3,050  of  4,500.    Elapsed: 0:16:33.
Batch 3,100  of  4,500.    Elapsed: 0:16:50.
Batch 3,150  of  4,500.    Elapsed: 0:17:06.
Batch 3,200  of  4,500.    Elapsed: 0:17:23.
Batch 3,250  of  4,500.    Elapsed: 0:17:39.
Batch 3,300  of  4,500.    Elapsed: 0:17:56.
Batch 3,350  of  4,500.    Elapsed: 0:18:12.
Batch 3,400  of  4,500.    Elapsed: 0:18:29.
Batch 3,450  of  4,500.    Elapsed: 0:18:45.
Batch 3,500  of  4,500.    Elapsed: 0:19:02.
Batch 3,550  of  4,500.    Elapsed: 0:19:18.
Batch 3,600  of  4,500.    Elapsed: 0:19:34.
Batch 3,650  of  4,500.    Elapsed: 0:19:51.
Batch 3,700  of  4,500.    Elapsed: 0:20:07.
Batch 3,750  of  4,500.    Elapsed: 0:20:23.
Batch 3,800  of  4,500.    Elapsed: 0:20:40.
Batch 3,850  of  4,500.    Elapsed: 0:20:56.
Batch 3,900  of  4,500.    Elapsed: 0:21:13.
Batch 3,950  of  4,500.    Elapsed: 0:21:29.
Batch 4,000  of  4,500.    Elapsed: 0:21:45.
Batch 4,050  of  4,500.    Elapsed: 0:22:02.
Batch 4,100  of  4,500.    Elapsed: 0:22:18.
Batch 4,150  of  4,500.    Elapsed: 0:22:35.
Batch 4,200  of  4,500.    Elapsed: 0:22:51.
Batch 4,250  of  4,500.    Elapsed: 0:23:08.
Batch 4,300  of  4,500.    Elapsed: 0:23:24.
Batch 4,350  of  4,500.    Elapsed: 0:23:41.
Batch 4,400  of  4,500.    Elapsed: 0:23:57.
Batch 4,450  of  4,500.    Elapsed: 0:24:13.

  Average training loss: 0.37
  Training epoch took: 0:24:30

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.81
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:17.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:50.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:12.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:45.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:18.
Batch 1,200  of  4,500.    Elapsed: 0:06:35.
Batch 1,250  of  4,500.    Elapsed: 0:06:51.
Batch 1,300  of  4,500.    Elapsed: 0:07:08.
Batch 1,350  of  4,500.    Elapsed: 0:07:24.
Batch 1,400  of  4,500.    Elapsed: 0:07:40.
Batch 1,450  of  4,500.    Elapsed: 0:07:57.
Batch 1,500  of  4,500.    Elapsed: 0:08:13.
Batch 1,550  of  4,500.    Elapsed: 0:08:30.
Batch 1,600  of  4,500.    Elapsed: 0:08:46.
Batch 1,650  of  4,500.    Elapsed: 0:09:03.
Batch 1,700  of  4,500.    Elapsed: 0:09:19.
Batch 1,750  of  4,500.    Elapsed: 0:09:35.
Batch 1,800  of  4,500.    Elapsed: 0:09:52.
Batch 1,850  of  4,500.    Elapsed: 0:10:08.
Batch 1,900  of  4,500.    Elapsed: 0:10:25.
Batch 1,950  of  4,500.    Elapsed: 0:10:41.
Batch 2,000  of  4,500.    Elapsed: 0:10:58.
Batch 2,050  of  4,500.    Elapsed: 0:11:14.
Batch 2,100  of  4,500.    Elapsed: 0:11:30.
Batch 2,150  of  4,500.    Elapsed: 0:11:47.
Batch 2,200  of  4,500.    Elapsed: 0:12:03.
Batch 2,250  of  4,500.    Elapsed: 0:12:20.
Batch 2,300  of  4,500.    Elapsed: 0:12:36.
Batch 2,350  of  4,500.    Elapsed: 0:12:52.
Batch 2,400  of  4,500.    Elapsed: 0:13:09.
Batch 2,450  of  4,500.    Elapsed: 0:13:25.
Batch 2,500  of  4,500.    Elapsed: 0:13:41.
Batch 2,550  of  4,500.    Elapsed: 0:13:58.
Batch 2,600  of  4,500.    Elapsed: 0:14:14.
Batch 2,650  of  4,500.    Elapsed: 0:14:31.
Batch 2,700  of  4,500.    Elapsed: 0:14:47.
Batch 2,750  of  4,500.    Elapsed: 0:15:03.
Batch 2,800  of  4,500.    Elapsed: 0:15:20.
Batch 2,850  of  4,500.    Elapsed: 0:15:36.
Batch 2,900  of  4,500.    Elapsed: 0:15:53.
Batch 2,950  of  4,500.    Elapsed: 0:16:09.
Batch 3,000  of  4,500.    Elapsed: 0:16:26.
Batch 3,050  of  4,500.    Elapsed: 0:16:42.
Batch 3,100  of  4,500.    Elapsed: 0:16:59.
Batch 3,150  of  4,500.    Elapsed: 0:17:15.
Batch 3,200  of  4,500.    Elapsed: 0:17:31.
Batch 3,250  of  4,500.    Elapsed: 0:17:48.
Batch 3,300  of  4,500.    Elapsed: 0:18:04.
Batch 3,350  of  4,500.    Elapsed: 0:18:21.
Batch 3,400  of  4,500.    Elapsed: 0:18:37.
Batch 3,450  of  4,500.    Elapsed: 0:18:53.
Batch 3,500  of  4,500.    Elapsed: 0:19:10.
Batch 3,550  of  4,500.    Elapsed: 0:19:26.
Batch 3,600  of  4,500.    Elapsed: 0:19:43.
Batch 3,650  of  4,500.    Elapsed: 0:19:59.
Batch 3,700  of  4,500.    Elapsed: 0:20:15.
Batch 3,750  of  4,500.    Elapsed: 0:20:32.
Batch 3,800  of  4,500.    Elapsed: 0:20:48.
Batch 3,850  of  4,500.    Elapsed: 0:21:05.
Batch 3,900  of  4,500.    Elapsed: 0:21:21.
Batch 3,950  of  4,500.    Elapsed: 0:21:38.
Batch 4,000  of  4,500.    Elapsed: 0:21:54.
Batch 4,050  of  4,500.    Elapsed: 0:22:11.
Batch 4,100  of  4,500.    Elapsed: 0:22:27.
Batch 4,150  of  4,500.    Elapsed: 0:22:43.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:42:24 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7662
INFO: Training took 1:43:26 (h:mm:ss)
INFO: Total duration: 105.65 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:00.
Batch 4,250  of  4,500.    Elapsed: 0:23:16.
Batch 4,300  of  4,500.    Elapsed: 0:23:33.
Batch 4,350  of  4,500.    Elapsed: 0:23:49.
Batch 4,400  of  4,500.    Elapsed: 0:24:05.
Batch 4,450  of  4,500.    Elapsed: 0:24:22.

  Average training loss: 0.29
  Training epoch took: 0:24:38

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 1.11
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 2/9.
INFO: Learning rate: 2e-05.
INFO: Split number: 2.
2020-08-27 18:15:30.015954: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 18:15:30.015988: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:39.
Batch   150  of  4,500.    Elapsed: 0:00:55.
Batch   200  of  4,500.    Elapsed: 0:01:11.
Batch   250  of  4,500.    Elapsed: 0:01:28.
Batch   300  of  4,500.    Elapsed: 0:01:45.
Batch   350  of  4,500.    Elapsed: 0:02:02.
Batch   400  of  4,500.    Elapsed: 0:02:19.
Batch   450  of  4,500.    Elapsed: 0:02:36.
Batch   500  of  4,500.    Elapsed: 0:02:53.
Batch   550  of  4,500.    Elapsed: 0:03:09.
Batch   600  of  4,500.    Elapsed: 0:03:26.
Batch   650  of  4,500.    Elapsed: 0:03:43.
Batch   700  of  4,500.    Elapsed: 0:04:00.
Batch   750  of  4,500.    Elapsed: 0:04:17.
Batch   800  of  4,500.    Elapsed: 0:04:34.
Batch   850  of  4,500.    Elapsed: 0:04:51.
Batch   900  of  4,500.    Elapsed: 0:05:08.
Batch   950  of  4,500.    Elapsed: 0:05:25.
Batch 1,000  of  4,500.    Elapsed: 0:05:42.
Batch 1,050  of  4,500.    Elapsed: 0:05:59.
Batch 1,100  of  4,500.    Elapsed: 0:06:15.
Batch 1,150  of  4,500.    Elapsed: 0:06:32.
Batch 1,200  of  4,500.    Elapsed: 0:06:48.
Batch 1,250  of  4,500.    Elapsed: 0:07:05.
Batch 1,300  of  4,500.    Elapsed: 0:07:21.
Batch 1,350  of  4,500.    Elapsed: 0:07:38.
Batch 1,400  of  4,500.    Elapsed: 0:07:54.
Batch 1,450  of  4,500.    Elapsed: 0:08:11.
Batch 1,500  of  4,500.    Elapsed: 0:08:27.
Batch 1,550  of  4,500.    Elapsed: 0:08:44.
Batch 1,600  of  4,500.    Elapsed: 0:09:00.
Batch 1,650  of  4,500.    Elapsed: 0:09:17.
Batch 1,700  of  4,500.    Elapsed: 0:09:33.
Batch 1,750  of  4,500.    Elapsed: 0:09:49.
Batch 1,800  of  4,500.    Elapsed: 0:10:06.
Batch 1,850  of  4,500.    Elapsed: 0:10:22.
Batch 1,900  of  4,500.    Elapsed: 0:10:39.
Batch 1,950  of  4,500.    Elapsed: 0:10:55.
Batch 2,000  of  4,500.    Elapsed: 0:11:12.
Batch 2,050  of  4,500.    Elapsed: 0:11:28.
Batch 2,100  of  4,500.    Elapsed: 0:11:45.
Batch 2,150  of  4,500.    Elapsed: 0:12:01.
Batch 2,200  of  4,500.    Elapsed: 0:12:18.
Batch 2,250  of  4,500.    Elapsed: 0:12:34.
Batch 2,300  of  4,500.    Elapsed: 0:12:51.
Batch 2,350  of  4,500.    Elapsed: 0:13:07.
Batch 2,400  of  4,500.    Elapsed: 0:13:24.
Batch 2,450  of  4,500.    Elapsed: 0:13:40.
Batch 2,500  of  4,500.    Elapsed: 0:13:57.
Batch 2,550  of  4,500.    Elapsed: 0:14:13.
Batch 2,600  of  4,500.    Elapsed: 0:14:29.
Batch 2,650  of  4,500.    Elapsed: 0:14:46.
Batch 2,700  of  4,500.    Elapsed: 0:15:02.
Batch 2,750  of  4,500.    Elapsed: 0:15:19.
Batch 2,800  of  4,500.    Elapsed: 0:15:35.
Batch 2,850  of  4,500.    Elapsed: 0:15:52.
Batch 2,900  of  4,500.    Elapsed: 0:16:08.
Batch 2,950  of  4,500.    Elapsed: 0:16:25.
Batch 3,000  of  4,500.    Elapsed: 0:16:41.
Batch 3,050  of  4,500.    Elapsed: 0:16:58.
Batch 3,100  of  4,500.    Elapsed: 0:17:14.
Batch 3,150  of  4,500.    Elapsed: 0:17:31.
Batch 3,200  of  4,500.    Elapsed: 0:17:47.
Batch 3,250  of  4,500.    Elapsed: 0:18:04.
Batch 3,300  of  4,500.    Elapsed: 0:18:20.
Batch 3,350  of  4,500.    Elapsed: 0:18:37.
Batch 3,400  of  4,500.    Elapsed: 0:18:54.
Batch 3,450  of  4,500.    Elapsed: 0:19:11.
Batch 3,500  of  4,500.    Elapsed: 0:19:28.
Batch 3,550  of  4,500.    Elapsed: 0:19:45.
Batch 3,600  of  4,500.    Elapsed: 0:20:01.
Batch 3,650  of  4,500.    Elapsed: 0:20:18.
Batch 3,700  of  4,500.    Elapsed: 0:20:35.
Batch 3,750  of  4,500.    Elapsed: 0:20:52.
Batch 3,800  of  4,500.    Elapsed: 0:21:09.
Batch 3,850  of  4,500.    Elapsed: 0:21:26.
Batch 3,900  of  4,500.    Elapsed: 0:21:42.
Batch 3,950  of  4,500.    Elapsed: 0:21:59.
Batch 4,000  of  4,500.    Elapsed: 0:22:15.
Batch 4,050  of  4,500.    Elapsed: 0:22:32.
Batch 4,100  of  4,500.    Elapsed: 0:22:48.
Batch 4,150  of  4,500.    Elapsed: 0:23:05.
Batch 4,200  of  4,500.    Elapsed: 0:23:21.
Batch 4,250  of  4,500.    Elapsed: 0:23:38.
Batch 4,300  of  4,500.    Elapsed: 0:23:54.
Batch 4,350  of  4,500.    Elapsed: 0:24:11.
Batch 4,400  of  4,500.    Elapsed: 0:24:28.
Batch 4,450  of  4,500.    Elapsed: 0:24:44.

  Average training loss: 0.62
  Training epoch took: 0:25:01

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.54
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:25.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:58.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:31.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:04.
Batch 1,150  of  4,500.    Elapsed: 0:06:20.
Batch 1,200  of  4,500.    Elapsed: 0:06:37.
Batch 1,250  of  4,500.    Elapsed: 0:06:53.
Batch 1,300  of  4,500.    Elapsed: 0:07:10.
Batch 1,350  of  4,500.    Elapsed: 0:07:26.
Batch 1,400  of  4,500.    Elapsed: 0:07:43.
Batch 1,450  of  4,500.    Elapsed: 0:07:59.
Batch 1,500  of  4,500.    Elapsed: 0:08:16.
Batch 1,550  of  4,500.    Elapsed: 0:08:32.
Batch 1,600  of  4,500.    Elapsed: 0:08:49.
Batch 1,650  of  4,500.    Elapsed: 0:09:05.
Batch 1,700  of  4,500.    Elapsed: 0:09:22.
Batch 1,750  of  4,500.    Elapsed: 0:09:38.
Batch 1,800  of  4,500.    Elapsed: 0:09:55.
Batch 1,850  of  4,500.    Elapsed: 0:10:12.
Batch 1,900  of  4,500.    Elapsed: 0:10:28.
Batch 1,950  of  4,500.    Elapsed: 0:10:45.
Batch 2,000  of  4,500.    Elapsed: 0:11:01.
Batch 2,050  of  4,500.    Elapsed: 0:11:18.
Batch 2,100  of  4,500.    Elapsed: 0:11:34.
Batch 2,150  of  4,500.    Elapsed: 0:11:51.
Batch 2,200  of  4,500.    Elapsed: 0:12:07.
Batch 2,250  of  4,500.    Elapsed: 0:12:24.
Batch 2,300  of  4,500.    Elapsed: 0:12:40.
Batch 2,350  of  4,500.    Elapsed: 0:12:57.
Batch 2,400  of  4,500.    Elapsed: 0:13:13.
Batch 2,450  of  4,500.    Elapsed: 0:13:30.
Batch 2,500  of  4,500.    Elapsed: 0:13:46.
Batch 2,550  of  4,500.    Elapsed: 0:14:03.
Batch 2,600  of  4,500.    Elapsed: 0:14:19.
Batch 2,650  of  4,500.    Elapsed: 0:14:36.
Batch 2,700  of  4,500.    Elapsed: 0:14:53.
Batch 2,750  of  4,500.    Elapsed: 0:15:09.
Batch 2,800  of  4,500.    Elapsed: 0:15:26.
Batch 2,850  of  4,500.    Elapsed: 0:15:42.
Batch 2,900  of  4,500.    Elapsed: 0:15:59.
Batch 2,950  of  4,500.    Elapsed: 0:16:15.
Batch 3,000  of  4,500.    Elapsed: 0:16:32.
Batch 3,050  of  4,500.    Elapsed: 0:16:48.
Batch 3,100  of  4,500.    Elapsed: 0:17:05.
Batch 3,150  of  4,500.    Elapsed: 0:17:21.
Batch 3,200  of  4,500.    Elapsed: 0:17:38.
Batch 3,250  of  4,500.    Elapsed: 0:17:54.
Batch 3,300  of  4,500.    Elapsed: 0:18:11.
Batch 3,350  of  4,500.    Elapsed: 0:18:27.
Batch 3,400  of  4,500.    Elapsed: 0:18:44.
Batch 3,450  of  4,500.    Elapsed: 0:19:01.
Batch 3,500  of  4,500.    Elapsed: 0:19:17.
Batch 3,550  of  4,500.    Elapsed: 0:19:34.
Batch 3,600  of  4,500.    Elapsed: 0:19:50.
Batch 3,650  of  4,500.    Elapsed: 0:20:07.
Batch 3,700  of  4,500.    Elapsed: 0:20:23.
Batch 3,750  of  4,500.    Elapsed: 0:20:40.
Batch 3,800  of  4,500.    Elapsed: 0:20:56.
Batch 3,850  of  4,500.    Elapsed: 0:21:13.
Batch 3,900  of  4,500.    Elapsed: 0:21:29.
Batch 3,950  of  4,500.    Elapsed: 0:21:46.
Batch 4,000  of  4,500.    Elapsed: 0:22:02.
Batch 4,050  of  4,500.    Elapsed: 0:22:19.
Batch 4,100  of  4,500.    Elapsed: 0:22:35.
Batch 4,150  of  4,500.    Elapsed: 0:22:52.
Batch 4,200  of  4,500.    Elapsed: 0:23:08.
Batch 4,250  of  4,500.    Elapsed: 0:23:25.
Batch 4,300  of  4,500.    Elapsed: 0:23:42.
Batch 4,350  of  4,500.    Elapsed: 0:23:58.
Batch 4,400  of  4,500.    Elapsed: 0:24:15.
Batch 4,450  of  4,500.    Elapsed: 0:24:31.

  Average training loss: 0.47
  Training epoch took: 0:24:48

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.60
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:39.
Batch   900  of  4,500.    Elapsed: 0:04:55.
Batch   950  of  4,500.    Elapsed: 0:05:11.
Batch 1,000  of  4,500.    Elapsed: 0:05:27.
Batch 1,050  of  4,500.    Elapsed: 0:05:43.
Batch 1,100  of  4,500.    Elapsed: 0:05:58.
Batch 1,150  of  4,500.    Elapsed: 0:06:14.
Batch 1,200  of  4,500.    Elapsed: 0:06:30.
Batch 1,250  of  4,500.    Elapsed: 0:06:46.
Batch 1,300  of  4,500.    Elapsed: 0:07:02.
Batch 1,350  of  4,500.    Elapsed: 0:07:17.
Batch 1,400  of  4,500.    Elapsed: 0:07:33.
Batch 1,450  of  4,500.    Elapsed: 0:07:49.
Batch 1,500  of  4,500.    Elapsed: 0:08:05.
Batch 1,550  of  4,500.    Elapsed: 0:08:20.
Batch 1,600  of  4,500.    Elapsed: 0:08:36.
Batch 1,650  of  4,500.    Elapsed: 0:08:52.
Batch 1,700  of  4,500.    Elapsed: 0:09:08.
Batch 1,750  of  4,500.    Elapsed: 0:09:24.
Batch 1,800  of  4,500.    Elapsed: 0:09:39.
Batch 1,850  of  4,500.    Elapsed: 0:09:55.
Batch 1,900  of  4,500.    Elapsed: 0:10:11.
Batch 1,950  of  4,500.    Elapsed: 0:10:27.
Batch 2,000  of  4,500.    Elapsed: 0:10:43.
Batch 2,050  of  4,500.    Elapsed: 0:10:58.
Batch 2,100  of  4,500.    Elapsed: 0:11:14.
Batch 2,150  of  4,500.    Elapsed: 0:11:30.
Batch 2,200  of  4,500.    Elapsed: 0:11:46.
Batch 2,250  of  4,500.    Elapsed: 0:12:02.
Batch 2,300  of  4,500.    Elapsed: 0:12:19.
Batch 2,350  of  4,500.    Elapsed: 0:12:35.
Batch 2,400  of  4,500.    Elapsed: 0:12:52.
Batch 2,450  of  4,500.    Elapsed: 0:13:08.
Batch 2,500  of  4,500.    Elapsed: 0:13:25.
Batch 2,550  of  4,500.    Elapsed: 0:13:41.
Batch 2,600  of  4,500.    Elapsed: 0:13:57.
Batch 2,650  of  4,500.    Elapsed: 0:14:14.
Batch 2,700  of  4,500.    Elapsed: 0:14:30.
Batch 2,750  of  4,500.    Elapsed: 0:14:47.
Batch 2,800  of  4,500.    Elapsed: 0:15:04.
Batch 2,850  of  4,500.    Elapsed: 0:15:20.
Batch 2,900  of  4,500.    Elapsed: 0:15:37.
Batch 2,950  of  4,500.    Elapsed: 0:15:53.
Batch 3,000  of  4,500.    Elapsed: 0:16:10.
Batch 3,050  of  4,500.    Elapsed: 0:16:26.
Batch 3,100  of  4,500.    Elapsed: 0:16:43.
Batch 3,150  of  4,500.    Elapsed: 0:16:59.
Batch 3,200  of  4,500.    Elapsed: 0:17:15.
Batch 3,250  of  4,500.    Elapsed: 0:17:32.
Batch 3,300  of  4,500.    Elapsed: 0:17:48.
Batch 3,350  of  4,500.    Elapsed: 0:18:05.
Batch 3,400  of  4,500.    Elapsed: 0:18:21.
Batch 3,450  of  4,500.    Elapsed: 0:18:38.
Batch 3,500  of  4,500.    Elapsed: 0:18:54.
Batch 3,550  of  4,500.    Elapsed: 0:19:11.
Batch 3,600  of  4,500.    Elapsed: 0:19:26.
Batch 3,650  of  4,500.    Elapsed: 0:19:42.
Batch 3,700  of  4,500.    Elapsed: 0:19:58.
Batch 3,750  of  4,500.    Elapsed: 0:20:14.
Batch 3,800  of  4,500.    Elapsed: 0:20:30.
Batch 3,850  of  4,500.    Elapsed: 0:20:46.
Batch 3,900  of  4,500.    Elapsed: 0:21:03.
Batch 3,950  of  4,500.    Elapsed: 0:21:19.
Batch 4,000  of  4,500.    Elapsed: 0:21:36.
Batch 4,050  of  4,500.    Elapsed: 0:21:52.
Batch 4,100  of  4,500.    Elapsed: 0:22:09.
Batch 4,150  of  4,500.    Elapsed: 0:22:26.
Batch 4,200  of  4,500.    Elapsed: 0:22:42.
Batch 4,250  of  4,500.    Elapsed: 0:22:59.
Batch 4,300  of  4,500.    Elapsed: 0:23:15.
Batch 4,350  of  4,500.    Elapsed: 0:23:32.
Batch 4,400  of  4,500.    Elapsed: 0:23:48.
Batch 4,450  of  4,500.    Elapsed: 0:24:05.

  Average training loss: 0.36
  Training epoch took: 0:24:21

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.82
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:08.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:41.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:14.
Batch 1,550  of  4,500.    Elapsed: 0:08:30.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:03.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:36.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:09.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:41.
Batch 2,000  of  4,500.    Elapsed: 0:10:57.
Batch 2,050  of  4,500.    Elapsed: 0:11:13.
Batch 2,100  of  4,500.    Elapsed: 0:11:29.
Batch 2,150  of  4,500.    Elapsed: 0:11:44.
Batch 2,200  of  4,500.    Elapsed: 0:12:00.
Batch 2,250  of  4,500.    Elapsed: 0:12:16.
Batch 2,300  of  4,500.    Elapsed: 0:12:32.
Batch 2,350  of  4,500.    Elapsed: 0:12:48.
Batch 2,400  of  4,500.    Elapsed: 0:13:03.
Batch 2,450  of  4,500.    Elapsed: 0:13:19.
Batch 2,500  of  4,500.    Elapsed: 0:13:35.
Batch 2,550  of  4,500.    Elapsed: 0:13:51.
Batch 2,600  of  4,500.    Elapsed: 0:14:07.
Batch 2,650  of  4,500.    Elapsed: 0:14:24.
Batch 2,700  of  4,500.    Elapsed: 0:14:40.
Batch 2,750  of  4,500.    Elapsed: 0:14:57.
Batch 2,800  of  4,500.    Elapsed: 0:15:13.
Batch 2,850  of  4,500.    Elapsed: 0:15:30.
Batch 2,900  of  4,500.    Elapsed: 0:15:46.
Batch 2,950  of  4,500.    Elapsed: 0:16:02.
Batch 3,000  of  4,500.    Elapsed: 0:16:18.
Batch 3,050  of  4,500.    Elapsed: 0:16:34.
Batch 3,100  of  4,500.    Elapsed: 0:16:51.
Batch 3,150  of  4,500.    Elapsed: 0:17:07.
Batch 3,200  of  4,500.    Elapsed: 0:17:24.
Batch 3,250  of  4,500.    Elapsed: 0:17:40.
Batch 3,300  of  4,500.    Elapsed: 0:17:57.
Batch 3,350  of  4,500.    Elapsed: 0:18:13.
Batch 3,400  of  4,500.    Elapsed: 0:18:30.
Batch 3,450  of  4,500.    Elapsed: 0:18:46.
Batch 3,500  of  4,500.    Elapsed: 0:19:02.
Batch 3,550  of  4,500.    Elapsed: 0:19:17.
Batch 3,600  of  4,500.    Elapsed: 0:19:33.
Batch 3,650  of  4,500.    Elapsed: 0:19:49.
Batch 3,700  of  4,500.    Elapsed: 0:20:05.
Batch 3,750  of  4,500.    Elapsed: 0:20:20.
Batch 3,800  of  4,500.    Elapsed: 0:20:36.
Batch 3,850  of  4,500.    Elapsed: 0:20:52.
Batch 3,900  of  4,500.    Elapsed: 0:21:08.
Batch 3,950  of  4,500.    Elapsed: 0:21:25.
Batch 4,000  of  4,500.    Elapsed: 0:21:41.
Batch 4,050  of  4,500.    Elapsed: 0:21:58.
Batch 4,100  of  4,500.    Elapsed: 0:22:14.
Batch 4,150  of  4,500.    Elapsed: 0:22:31.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:42:27 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7622
INFO: Training took 1:43:29 (h:mm:ss)
INFO: Total duration: 105.66666666666667 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:22:47.
Batch 4,250  of  4,500.    Elapsed: 0:23:04.
Batch 4,300  of  4,500.    Elapsed: 0:23:20.
Batch 4,350  of  4,500.    Elapsed: 0:23:37.
Batch 4,400  of  4,500.    Elapsed: 0:23:53.
Batch 4,450  of  4,500.    Elapsed: 0:24:09.

  Average training loss: 0.29
  Training epoch took: 0:24:26

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 1.01
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 3/9.
INFO: Learning rate: 2e-05.
INFO: Split number: 3.
2020-08-27 20:01:16.487855: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 20:01:16.487890: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:39.
Batch   150  of  4,500.    Elapsed: 0:00:55.
Batch   200  of  4,500.    Elapsed: 0:01:12.
Batch   250  of  4,500.    Elapsed: 0:01:28.
Batch   300  of  4,500.    Elapsed: 0:01:44.
Batch   350  of  4,500.    Elapsed: 0:02:01.
Batch   400  of  4,500.    Elapsed: 0:02:17.
Batch   450  of  4,500.    Elapsed: 0:02:33.
Batch   500  of  4,500.    Elapsed: 0:02:50.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:12.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:45.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:18.
Batch 1,000  of  4,500.    Elapsed: 0:05:35.
Batch 1,050  of  4,500.    Elapsed: 0:05:51.
Batch 1,100  of  4,500.    Elapsed: 0:06:08.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:14.
Batch 1,350  of  4,500.    Elapsed: 0:07:31.
Batch 1,400  of  4,500.    Elapsed: 0:07:47.
Batch 1,450  of  4,500.    Elapsed: 0:08:04.
Batch 1,500  of  4,500.    Elapsed: 0:08:20.
Batch 1,550  of  4,500.    Elapsed: 0:08:37.
Batch 1,600  of  4,500.    Elapsed: 0:08:53.
Batch 1,650  of  4,500.    Elapsed: 0:09:10.
Batch 1,700  of  4,500.    Elapsed: 0:09:26.
Batch 1,750  of  4,500.    Elapsed: 0:09:43.
Batch 1,800  of  4,500.    Elapsed: 0:10:00.
Batch 1,850  of  4,500.    Elapsed: 0:10:16.
Batch 1,900  of  4,500.    Elapsed: 0:10:33.
Batch 1,950  of  4,500.    Elapsed: 0:10:50.
Batch 2,000  of  4,500.    Elapsed: 0:11:06.
Batch 2,050  of  4,500.    Elapsed: 0:11:23.
Batch 2,100  of  4,500.    Elapsed: 0:11:40.
Batch 2,150  of  4,500.    Elapsed: 0:11:57.
Batch 2,200  of  4,500.    Elapsed: 0:12:14.
Batch 2,250  of  4,500.    Elapsed: 0:12:31.
Batch 2,300  of  4,500.    Elapsed: 0:12:48.
Batch 2,350  of  4,500.    Elapsed: 0:13:04.
Batch 2,400  of  4,500.    Elapsed: 0:13:21.
Batch 2,450  of  4,500.    Elapsed: 0:13:38.
Batch 2,500  of  4,500.    Elapsed: 0:13:55.
Batch 2,550  of  4,500.    Elapsed: 0:14:12.
Batch 2,600  of  4,500.    Elapsed: 0:14:29.
Batch 2,650  of  4,500.    Elapsed: 0:14:46.
Batch 2,700  of  4,500.    Elapsed: 0:15:02.
Batch 2,750  of  4,500.    Elapsed: 0:15:19.
Batch 2,800  of  4,500.    Elapsed: 0:15:36.
Batch 2,850  of  4,500.    Elapsed: 0:15:53.
Batch 2,900  of  4,500.    Elapsed: 0:16:10.
Batch 2,950  of  4,500.    Elapsed: 0:16:27.
Batch 3,000  of  4,500.    Elapsed: 0:16:43.
Batch 3,050  of  4,500.    Elapsed: 0:17:00.
Batch 3,100  of  4,500.    Elapsed: 0:17:17.
Batch 3,150  of  4,500.    Elapsed: 0:17:34.
Batch 3,200  of  4,500.    Elapsed: 0:17:51.
Batch 3,250  of  4,500.    Elapsed: 0:18:08.
Batch 3,300  of  4,500.    Elapsed: 0:18:25.
Batch 3,350  of  4,500.    Elapsed: 0:18:42.
Batch 3,400  of  4,500.    Elapsed: 0:18:59.
Batch 3,450  of  4,500.    Elapsed: 0:19:15.
Batch 3,500  of  4,500.    Elapsed: 0:19:32.
Batch 3,550  of  4,500.    Elapsed: 0:19:49.
Batch 3,600  of  4,500.    Elapsed: 0:20:06.
Batch 3,650  of  4,500.    Elapsed: 0:20:23.
Batch 3,700  of  4,500.    Elapsed: 0:20:40.
Batch 3,750  of  4,500.    Elapsed: 0:20:56.
Batch 3,800  of  4,500.    Elapsed: 0:21:13.
Batch 3,850  of  4,500.    Elapsed: 0:21:29.
Batch 3,900  of  4,500.    Elapsed: 0:21:46.
Batch 3,950  of  4,500.    Elapsed: 0:22:02.
Batch 4,000  of  4,500.    Elapsed: 0:22:19.
Batch 4,050  of  4,500.    Elapsed: 0:22:35.
Batch 4,100  of  4,500.    Elapsed: 0:22:52.
Batch 4,150  of  4,500.    Elapsed: 0:23:08.
Batch 4,200  of  4,500.    Elapsed: 0:23:25.
Batch 4,250  of  4,500.    Elapsed: 0:23:41.
Batch 4,300  of  4,500.    Elapsed: 0:23:58.
Batch 4,350  of  4,500.    Elapsed: 0:24:14.
Batch 4,400  of  4,500.    Elapsed: 0:24:30.
Batch 4,450  of  4,500.    Elapsed: 0:24:47.

  Average training loss: 0.62
  Training epoch took: 0:25:03

Now Validating.
  Validation Accuracy: 0.78
  Validation Loss: 0.53
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:19.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:52.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:25.
Batch   850  of  4,500.    Elapsed: 0:04:42.
Batch   900  of  4,500.    Elapsed: 0:04:59.
Batch   950  of  4,500.    Elapsed: 0:05:16.
Batch 1,000  of  4,500.    Elapsed: 0:05:33.
Batch 1,050  of  4,500.    Elapsed: 0:05:50.
Batch 1,100  of  4,500.    Elapsed: 0:06:07.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:15.
Batch 1,350  of  4,500.    Elapsed: 0:07:32.
Batch 1,400  of  4,500.    Elapsed: 0:07:49.
Batch 1,450  of  4,500.    Elapsed: 0:08:06.
Batch 1,500  of  4,500.    Elapsed: 0:08:23.
Batch 1,550  of  4,500.    Elapsed: 0:08:40.
Batch 1,600  of  4,500.    Elapsed: 0:08:57.
Batch 1,650  of  4,500.    Elapsed: 0:09:14.
Batch 1,700  of  4,500.    Elapsed: 0:09:31.
Batch 1,750  of  4,500.    Elapsed: 0:09:48.
Batch 1,800  of  4,500.    Elapsed: 0:10:05.
Batch 1,850  of  4,500.    Elapsed: 0:10:22.
Batch 1,900  of  4,500.    Elapsed: 0:10:39.
Batch 1,950  of  4,500.    Elapsed: 0:10:56.
Batch 2,000  of  4,500.    Elapsed: 0:11:13.
Batch 2,050  of  4,500.    Elapsed: 0:11:29.
Batch 2,100  of  4,500.    Elapsed: 0:11:46.
Batch 2,150  of  4,500.    Elapsed: 0:12:03.
Batch 2,200  of  4,500.    Elapsed: 0:12:20.
Batch 2,250  of  4,500.    Elapsed: 0:12:37.
Batch 2,300  of  4,500.    Elapsed: 0:12:54.
Batch 2,350  of  4,500.    Elapsed: 0:13:11.
Batch 2,400  of  4,500.    Elapsed: 0:13:28.
Batch 2,450  of  4,500.    Elapsed: 0:13:45.
Batch 2,500  of  4,500.    Elapsed: 0:14:02.
Batch 2,550  of  4,500.    Elapsed: 0:14:19.
Batch 2,600  of  4,500.    Elapsed: 0:14:36.
Batch 2,650  of  4,500.    Elapsed: 0:14:53.
Batch 2,700  of  4,500.    Elapsed: 0:15:10.
Batch 2,750  of  4,500.    Elapsed: 0:15:27.
Batch 2,800  of  4,500.    Elapsed: 0:15:44.
Batch 2,850  of  4,500.    Elapsed: 0:16:01.
Batch 2,900  of  4,500.    Elapsed: 0:16:18.
Batch 2,950  of  4,500.    Elapsed: 0:16:35.
Batch 3,000  of  4,500.    Elapsed: 0:16:52.
Batch 3,050  of  4,500.    Elapsed: 0:17:09.
Batch 3,100  of  4,500.    Elapsed: 0:17:26.
Batch 3,150  of  4,500.    Elapsed: 0:17:43.
Batch 3,200  of  4,500.    Elapsed: 0:18:00.
Batch 3,250  of  4,500.    Elapsed: 0:18:17.
Batch 3,300  of  4,500.    Elapsed: 0:18:34.
Batch 3,350  of  4,500.    Elapsed: 0:18:51.
Batch 3,400  of  4,500.    Elapsed: 0:19:08.
Batch 3,450  of  4,500.    Elapsed: 0:19:25.
Batch 3,500  of  4,500.    Elapsed: 0:19:42.
Batch 3,550  of  4,500.    Elapsed: 0:19:59.
Batch 3,600  of  4,500.    Elapsed: 0:20:16.
Batch 3,650  of  4,500.    Elapsed: 0:20:33.
Batch 3,700  of  4,500.    Elapsed: 0:20:50.
Batch 3,750  of  4,500.    Elapsed: 0:21:07.
Batch 3,800  of  4,500.    Elapsed: 0:21:24.
Batch 3,850  of  4,500.    Elapsed: 0:21:41.
Batch 3,900  of  4,500.    Elapsed: 0:21:58.
Batch 3,950  of  4,500.    Elapsed: 0:22:15.
Batch 4,000  of  4,500.    Elapsed: 0:22:32.
Batch 4,050  of  4,500.    Elapsed: 0:22:48.
Batch 4,100  of  4,500.    Elapsed: 0:23:05.
Batch 4,150  of  4,500.    Elapsed: 0:23:22.
Batch 4,200  of  4,500.    Elapsed: 0:23:39.
Batch 4,250  of  4,500.    Elapsed: 0:23:56.
Batch 4,300  of  4,500.    Elapsed: 0:24:13.
Batch 4,350  of  4,500.    Elapsed: 0:24:30.
Batch 4,400  of  4,500.    Elapsed: 0:24:47.
Batch 4,450  of  4,500.    Elapsed: 0:25:04.

  Average training loss: 0.47
  Training epoch took: 0:25:21

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.55
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:08.
Batch   250  of  4,500.    Elapsed: 0:01:25.
Batch   300  of  4,500.    Elapsed: 0:01:42.
Batch   350  of  4,500.    Elapsed: 0:01:59.
Batch   400  of  4,500.    Elapsed: 0:02:16.
Batch   450  of  4,500.    Elapsed: 0:02:33.
Batch   500  of  4,500.    Elapsed: 0:02:50.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:46.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:35.
Batch 1,050  of  4,500.    Elapsed: 0:05:52.
Batch 1,100  of  4,500.    Elapsed: 0:06:08.
Batch 1,150  of  4,500.    Elapsed: 0:06:25.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:14.
Batch 1,350  of  4,500.    Elapsed: 0:07:31.
Batch 1,400  of  4,500.    Elapsed: 0:07:48.
Batch 1,450  of  4,500.    Elapsed: 0:08:04.
Batch 1,500  of  4,500.    Elapsed: 0:08:21.
Batch 1,550  of  4,500.    Elapsed: 0:08:37.
Batch 1,600  of  4,500.    Elapsed: 0:08:54.
Batch 1,650  of  4,500.    Elapsed: 0:09:10.
Batch 1,700  of  4,500.    Elapsed: 0:09:27.
Batch 1,750  of  4,500.    Elapsed: 0:09:43.
Batch 1,800  of  4,500.    Elapsed: 0:10:00.
Batch 1,850  of  4,500.    Elapsed: 0:10:16.
Batch 1,900  of  4,500.    Elapsed: 0:10:33.
Batch 1,950  of  4,500.    Elapsed: 0:10:49.
Batch 2,000  of  4,500.    Elapsed: 0:11:06.
Batch 2,050  of  4,500.    Elapsed: 0:11:22.
Batch 2,100  of  4,500.    Elapsed: 0:11:39.
Batch 2,150  of  4,500.    Elapsed: 0:11:55.
Batch 2,200  of  4,500.    Elapsed: 0:12:12.
Batch 2,250  of  4,500.    Elapsed: 0:12:29.
Batch 2,300  of  4,500.    Elapsed: 0:12:45.
Batch 2,350  of  4,500.    Elapsed: 0:13:02.
Batch 2,400  of  4,500.    Elapsed: 0:13:19.
Batch 2,450  of  4,500.    Elapsed: 0:13:36.
Batch 2,500  of  4,500.    Elapsed: 0:13:53.
Batch 2,550  of  4,500.    Elapsed: 0:14:09.
Batch 2,600  of  4,500.    Elapsed: 0:14:26.
Batch 2,650  of  4,500.    Elapsed: 0:14:43.
Batch 2,700  of  4,500.    Elapsed: 0:15:00.
Batch 2,750  of  4,500.    Elapsed: 0:15:17.
Batch 2,800  of  4,500.    Elapsed: 0:15:34.
Batch 2,850  of  4,500.    Elapsed: 0:15:51.
Batch 2,900  of  4,500.    Elapsed: 0:16:08.
Batch 2,950  of  4,500.    Elapsed: 0:16:25.
Batch 3,000  of  4,500.    Elapsed: 0:16:42.
Batch 3,050  of  4,500.    Elapsed: 0:16:59.
Batch 3,100  of  4,500.    Elapsed: 0:17:16.
Batch 3,150  of  4,500.    Elapsed: 0:17:33.
Batch 3,200  of  4,500.    Elapsed: 0:17:50.
Batch 3,250  of  4,500.    Elapsed: 0:18:07.
Batch 3,300  of  4,500.    Elapsed: 0:18:24.
Batch 3,350  of  4,500.    Elapsed: 0:18:41.
Batch 3,400  of  4,500.    Elapsed: 0:18:58.
Batch 3,450  of  4,500.    Elapsed: 0:19:15.
Batch 3,500  of  4,500.    Elapsed: 0:19:32.
Batch 3,550  of  4,500.    Elapsed: 0:19:49.
Batch 3,600  of  4,500.    Elapsed: 0:20:06.
Batch 3,650  of  4,500.    Elapsed: 0:20:23.
Batch 3,700  of  4,500.    Elapsed: 0:20:40.
Batch 3,750  of  4,500.    Elapsed: 0:20:57.
Batch 3,800  of  4,500.    Elapsed: 0:21:14.
Batch 3,850  of  4,500.    Elapsed: 0:21:31.
Batch 3,900  of  4,500.    Elapsed: 0:21:48.
Batch 3,950  of  4,500.    Elapsed: 0:22:05.
Batch 4,000  of  4,500.    Elapsed: 0:22:22.
Batch 4,050  of  4,500.    Elapsed: 0:22:39.
Batch 4,100  of  4,500.    Elapsed: 0:22:56.
Batch 4,150  of  4,500.    Elapsed: 0:23:12.
Batch 4,200  of  4,500.    Elapsed: 0:23:29.
Batch 4,250  of  4,500.    Elapsed: 0:23:46.
Batch 4,300  of  4,500.    Elapsed: 0:24:03.
Batch 4,350  of  4,500.    Elapsed: 0:24:20.
Batch 4,400  of  4,500.    Elapsed: 0:24:37.
Batch 4,450  of  4,500.    Elapsed: 0:24:54.

  Average training loss: 0.37
  Training epoch took: 0:25:11

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.68
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:08.
Batch   250  of  4,500.    Elapsed: 0:01:25.
Batch   300  of  4,500.    Elapsed: 0:01:41.
Batch   350  of  4,500.    Elapsed: 0:01:58.
Batch   400  of  4,500.    Elapsed: 0:02:15.
Batch   450  of  4,500.    Elapsed: 0:02:32.
Batch   500  of  4,500.    Elapsed: 0:02:49.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:30.
Batch   850  of  4,500.    Elapsed: 0:04:47.
Batch   900  of  4,500.    Elapsed: 0:05:04.
Batch   950  of  4,500.    Elapsed: 0:05:21.
Batch 1,000  of  4,500.    Elapsed: 0:05:37.
Batch 1,050  of  4,500.    Elapsed: 0:05:54.
Batch 1,100  of  4,500.    Elapsed: 0:06:11.
Batch 1,150  of  4,500.    Elapsed: 0:06:28.
Batch 1,200  of  4,500.    Elapsed: 0:06:45.
Batch 1,250  of  4,500.    Elapsed: 0:07:01.
Batch 1,300  of  4,500.    Elapsed: 0:07:18.
Batch 1,350  of  4,500.    Elapsed: 0:07:34.
Batch 1,400  of  4,500.    Elapsed: 0:07:51.
Batch 1,450  of  4,500.    Elapsed: 0:08:07.
Batch 1,500  of  4,500.    Elapsed: 0:08:24.
Batch 1,550  of  4,500.    Elapsed: 0:08:40.
Batch 1,600  of  4,500.    Elapsed: 0:08:57.
Batch 1,650  of  4,500.    Elapsed: 0:09:13.
Batch 1,700  of  4,500.    Elapsed: 0:09:30.
Batch 1,750  of  4,500.    Elapsed: 0:09:46.
Batch 1,800  of  4,500.    Elapsed: 0:10:03.
Batch 1,850  of  4,500.    Elapsed: 0:10:19.
Batch 1,900  of  4,500.    Elapsed: 0:10:36.
Batch 1,950  of  4,500.    Elapsed: 0:10:52.
Batch 2,000  of  4,500.    Elapsed: 0:11:09.
Batch 2,050  of  4,500.    Elapsed: 0:11:25.
Batch 2,100  of  4,500.    Elapsed: 0:11:42.
Batch 2,150  of  4,500.    Elapsed: 0:11:58.
Batch 2,200  of  4,500.    Elapsed: 0:12:15.
Batch 2,250  of  4,500.    Elapsed: 0:12:31.
Batch 2,300  of  4,500.    Elapsed: 0:12:48.
Batch 2,350  of  4,500.    Elapsed: 0:13:04.
Batch 2,400  of  4,500.    Elapsed: 0:13:21.
Batch 2,450  of  4,500.    Elapsed: 0:13:37.
Batch 2,500  of  4,500.    Elapsed: 0:13:54.
Batch 2,550  of  4,500.    Elapsed: 0:14:10.
Batch 2,600  of  4,500.    Elapsed: 0:14:27.
Batch 2,650  of  4,500.    Elapsed: 0:14:43.
Batch 2,700  of  4,500.    Elapsed: 0:15:00.
Batch 2,750  of  4,500.    Elapsed: 0:15:16.
Batch 2,800  of  4,500.    Elapsed: 0:15:33.
Batch 2,850  of  4,500.    Elapsed: 0:15:49.
Batch 2,900  of  4,500.    Elapsed: 0:16:06.
Batch 2,950  of  4,500.    Elapsed: 0:16:22.
Batch 3,000  of  4,500.    Elapsed: 0:16:39.
Batch 3,050  of  4,500.    Elapsed: 0:16:55.
Batch 3,100  of  4,500.    Elapsed: 0:17:12.
Batch 3,150  of  4,500.    Elapsed: 0:17:28.
Batch 3,200  of  4,500.    Elapsed: 0:17:45.
Batch 3,250  of  4,500.    Elapsed: 0:18:01.
Batch 3,300  of  4,500.    Elapsed: 0:18:18.
Batch 3,350  of  4,500.    Elapsed: 0:18:34.
Batch 3,400  of  4,500.    Elapsed: 0:18:51.
Batch 3,450  of  4,500.    Elapsed: 0:19:07.
Batch 3,500  of  4,500.    Elapsed: 0:19:24.
Batch 3,550  of  4,500.    Elapsed: 0:19:40.
Batch 3,600  of  4,500.    Elapsed: 0:19:57.
Batch 3,650  of  4,500.    Elapsed: 0:20:13.
Batch 3,700  of  4,500.    Elapsed: 0:20:30.
Batch 3,750  of  4,500.    Elapsed: 0:20:46.
Batch 3,800  of  4,500.    Elapsed: 0:21:03.
Batch 3,850  of  4,500.    Elapsed: 0:21:19.
Batch 3,900  of  4,500.    Elapsed: 0:21:36.
Batch 3,950  of  4,500.    Elapsed: 0:21:52.
Batch 4,000  of  4,500.    Elapsed: 0:22:09.
Batch 4,050  of  4,500.    Elapsed: 0:22:26.
Batch 4,100  of  4,500.    Elapsed: 0:22:43.
Batch 4,150  of  4,500.    Elapsed: 0:23:00.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:44:24 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.764
INFO: Training took 1:45:26 (h:mm:ss)
INFO: Total duration: 107.61666666666666 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:17.
Batch 4,250  of  4,500.    Elapsed: 0:23:34.
Batch 4,300  of  4,500.    Elapsed: 0:23:50.
Batch 4,350  of  4,500.    Elapsed: 0:24:07.
Batch 4,400  of  4,500.    Elapsed: 0:24:23.
Batch 4,450  of  4,500.    Elapsed: 0:24:40.

  Average training loss: 0.29
  Training epoch took: 0:24:56

Now Validating.
  Validation Accuracy: 0.78
  Validation Loss: 1.00
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 4/9.
INFO: Learning rate: 3e-05.
INFO: Split number: 1.
2020-08-27 21:49:00.124478: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 21:49:00.124531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:25.
Batch   100  of  4,500.    Elapsed: 0:00:41.
Batch   150  of  4,500.    Elapsed: 0:00:57.
Batch   200  of  4,500.    Elapsed: 0:01:13.
Batch   250  of  4,500.    Elapsed: 0:01:30.
Batch   300  of  4,500.    Elapsed: 0:01:46.
Batch   350  of  4,500.    Elapsed: 0:02:02.
Batch   400  of  4,500.    Elapsed: 0:02:19.
Batch   450  of  4,500.    Elapsed: 0:02:35.
Batch   500  of  4,500.    Elapsed: 0:02:52.
Batch   550  of  4,500.    Elapsed: 0:03:08.
Batch   600  of  4,500.    Elapsed: 0:03:25.
Batch   650  of  4,500.    Elapsed: 0:03:41.
Batch   700  of  4,500.    Elapsed: 0:03:58.
Batch   750  of  4,500.    Elapsed: 0:04:14.
Batch   800  of  4,500.    Elapsed: 0:04:30.
Batch   850  of  4,500.    Elapsed: 0:04:47.
Batch   900  of  4,500.    Elapsed: 0:05:03.
Batch   950  of  4,500.    Elapsed: 0:05:20.
Batch 1,000  of  4,500.    Elapsed: 0:05:36.
Batch 1,050  of  4,500.    Elapsed: 0:05:53.
Batch 1,100  of  4,500.    Elapsed: 0:06:09.
Batch 1,150  of  4,500.    Elapsed: 0:06:26.
Batch 1,200  of  4,500.    Elapsed: 0:06:42.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:15.
Batch 1,350  of  4,500.    Elapsed: 0:07:31.
Batch 1,400  of  4,500.    Elapsed: 0:07:48.
Batch 1,450  of  4,500.    Elapsed: 0:08:05.
Batch 1,500  of  4,500.    Elapsed: 0:08:22.
Batch 1,550  of  4,500.    Elapsed: 0:08:39.
Batch 1,600  of  4,500.    Elapsed: 0:08:56.
Batch 1,650  of  4,500.    Elapsed: 0:09:12.
Batch 1,700  of  4,500.    Elapsed: 0:09:29.
Batch 1,750  of  4,500.    Elapsed: 0:09:46.
Batch 1,800  of  4,500.    Elapsed: 0:10:03.
Batch 1,850  of  4,500.    Elapsed: 0:10:20.
Batch 1,900  of  4,500.    Elapsed: 0:10:37.
Batch 1,950  of  4,500.    Elapsed: 0:10:53.
Batch 2,000  of  4,500.    Elapsed: 0:11:10.
Batch 2,050  of  4,500.    Elapsed: 0:11:27.
Batch 2,100  of  4,500.    Elapsed: 0:11:44.
Batch 2,150  of  4,500.    Elapsed: 0:12:01.
Batch 2,200  of  4,500.    Elapsed: 0:12:18.
Batch 2,250  of  4,500.    Elapsed: 0:12:35.
Batch 2,300  of  4,500.    Elapsed: 0:12:52.
Batch 2,350  of  4,500.    Elapsed: 0:13:09.
Batch 2,400  of  4,500.    Elapsed: 0:13:26.
Batch 2,450  of  4,500.    Elapsed: 0:13:43.
Batch 2,500  of  4,500.    Elapsed: 0:13:59.
Batch 2,550  of  4,500.    Elapsed: 0:14:16.
Batch 2,600  of  4,500.    Elapsed: 0:14:33.
Batch 2,650  of  4,500.    Elapsed: 0:14:50.
Batch 2,700  of  4,500.    Elapsed: 0:15:07.
Batch 2,750  of  4,500.    Elapsed: 0:15:24.
Batch 2,800  of  4,500.    Elapsed: 0:15:41.
Batch 2,850  of  4,500.    Elapsed: 0:15:58.
Batch 2,900  of  4,500.    Elapsed: 0:16:15.
Batch 2,950  of  4,500.    Elapsed: 0:16:32.
Batch 3,000  of  4,500.    Elapsed: 0:16:49.
Batch 3,050  of  4,500.    Elapsed: 0:17:06.
Batch 3,100  of  4,500.    Elapsed: 0:17:23.
Batch 3,150  of  4,500.    Elapsed: 0:17:40.
Batch 3,200  of  4,500.    Elapsed: 0:17:57.
Batch 3,250  of  4,500.    Elapsed: 0:18:14.
Batch 3,300  of  4,500.    Elapsed: 0:18:31.
Batch 3,350  of  4,500.    Elapsed: 0:18:47.
Batch 3,400  of  4,500.    Elapsed: 0:19:04.
Batch 3,450  of  4,500.    Elapsed: 0:19:20.
Batch 3,500  of  4,500.    Elapsed: 0:19:37.
Batch 3,550  of  4,500.    Elapsed: 0:19:53.
Batch 3,600  of  4,500.    Elapsed: 0:20:10.
Batch 3,650  of  4,500.    Elapsed: 0:20:27.
Batch 3,700  of  4,500.    Elapsed: 0:20:43.
Batch 3,750  of  4,500.    Elapsed: 0:20:59.
Batch 3,800  of  4,500.    Elapsed: 0:21:16.
Batch 3,850  of  4,500.    Elapsed: 0:21:33.
Batch 3,900  of  4,500.    Elapsed: 0:21:49.
Batch 3,950  of  4,500.    Elapsed: 0:22:06.
Batch 4,000  of  4,500.    Elapsed: 0:22:22.
Batch 4,050  of  4,500.    Elapsed: 0:22:39.
Batch 4,100  of  4,500.    Elapsed: 0:22:55.
Batch 4,150  of  4,500.    Elapsed: 0:23:12.
Batch 4,200  of  4,500.    Elapsed: 0:23:28.
Batch 4,250  of  4,500.    Elapsed: 0:23:44.
Batch 4,300  of  4,500.    Elapsed: 0:24:01.
Batch 4,350  of  4,500.    Elapsed: 0:24:17.
Batch 4,400  of  4,500.    Elapsed: 0:24:34.
Batch 4,450  of  4,500.    Elapsed: 0:24:50.

  Average training loss: 0.63
  Training epoch took: 0:25:06

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.57
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:31.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:04.
Batch 1,150  of  4,500.    Elapsed: 0:06:20.
Batch 1,200  of  4,500.    Elapsed: 0:06:37.
Batch 1,250  of  4,500.    Elapsed: 0:06:53.
Batch 1,300  of  4,500.    Elapsed: 0:07:10.
Batch 1,350  of  4,500.    Elapsed: 0:07:26.
Batch 1,400  of  4,500.    Elapsed: 0:07:43.
Batch 1,450  of  4,500.    Elapsed: 0:07:59.
Batch 1,500  of  4,500.    Elapsed: 0:08:16.
Batch 1,550  of  4,500.    Elapsed: 0:08:32.
Batch 1,600  of  4,500.    Elapsed: 0:08:49.
Batch 1,650  of  4,500.    Elapsed: 0:09:05.
Batch 1,700  of  4,500.    Elapsed: 0:09:22.
Batch 1,750  of  4,500.    Elapsed: 0:09:38.
Batch 1,800  of  4,500.    Elapsed: 0:09:55.
Batch 1,850  of  4,500.    Elapsed: 0:10:11.
Batch 1,900  of  4,500.    Elapsed: 0:10:28.
Batch 1,950  of  4,500.    Elapsed: 0:10:44.
Batch 2,000  of  4,500.    Elapsed: 0:11:01.
Batch 2,050  of  4,500.    Elapsed: 0:11:17.
Batch 2,100  of  4,500.    Elapsed: 0:11:34.
Batch 2,150  of  4,500.    Elapsed: 0:11:50.
Batch 2,200  of  4,500.    Elapsed: 0:12:07.
Batch 2,250  of  4,500.    Elapsed: 0:12:23.
Batch 2,300  of  4,500.    Elapsed: 0:12:40.
Batch 2,350  of  4,500.    Elapsed: 0:12:56.
Batch 2,400  of  4,500.    Elapsed: 0:13:13.
Batch 2,450  of  4,500.    Elapsed: 0:13:29.
Batch 2,500  of  4,500.    Elapsed: 0:13:46.
Batch 2,550  of  4,500.    Elapsed: 0:14:02.
Batch 2,600  of  4,500.    Elapsed: 0:14:19.
Batch 2,650  of  4,500.    Elapsed: 0:14:35.
Batch 2,700  of  4,500.    Elapsed: 0:14:52.
Batch 2,750  of  4,500.    Elapsed: 0:15:08.
Batch 2,800  of  4,500.    Elapsed: 0:15:25.
Batch 2,850  of  4,500.    Elapsed: 0:15:41.
Batch 2,900  of  4,500.    Elapsed: 0:15:58.
Batch 2,950  of  4,500.    Elapsed: 0:16:14.
Batch 3,000  of  4,500.    Elapsed: 0:16:31.
Batch 3,050  of  4,500.    Elapsed: 0:16:47.
Batch 3,100  of  4,500.    Elapsed: 0:17:04.
Batch 3,150  of  4,500.    Elapsed: 0:17:20.
Batch 3,200  of  4,500.    Elapsed: 0:17:37.
Batch 3,250  of  4,500.    Elapsed: 0:17:53.
Batch 3,300  of  4,500.    Elapsed: 0:18:10.
Batch 3,350  of  4,500.    Elapsed: 0:18:26.
Batch 3,400  of  4,500.    Elapsed: 0:18:43.
Batch 3,450  of  4,500.    Elapsed: 0:18:59.
Batch 3,500  of  4,500.    Elapsed: 0:19:16.
Batch 3,550  of  4,500.    Elapsed: 0:19:32.
Batch 3,600  of  4,500.    Elapsed: 0:19:49.
Batch 3,650  of  4,500.    Elapsed: 0:20:06.
Batch 3,700  of  4,500.    Elapsed: 0:20:22.
Batch 3,750  of  4,500.    Elapsed: 0:20:39.
Batch 3,800  of  4,500.    Elapsed: 0:20:55.
Batch 3,850  of  4,500.    Elapsed: 0:21:12.
Batch 3,900  of  4,500.    Elapsed: 0:21:28.
Batch 3,950  of  4,500.    Elapsed: 0:21:45.
Batch 4,000  of  4,500.    Elapsed: 0:22:01.
Batch 4,050  of  4,500.    Elapsed: 0:22:18.
Batch 4,100  of  4,500.    Elapsed: 0:22:34.
Batch 4,150  of  4,500.    Elapsed: 0:22:51.
Batch 4,200  of  4,500.    Elapsed: 0:23:07.
Batch 4,250  of  4,500.    Elapsed: 0:23:24.
Batch 4,300  of  4,500.    Elapsed: 0:23:40.
Batch 4,350  of  4,500.    Elapsed: 0:23:57.
Batch 4,400  of  4,500.    Elapsed: 0:24:13.
Batch 4,450  of  4,500.    Elapsed: 0:24:30.

  Average training loss: 0.48
  Training epoch took: 0:24:46

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.60
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:42.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:48.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:10:59.
Batch 2,050  of  4,500.    Elapsed: 0:11:16.
Batch 2,100  of  4,500.    Elapsed: 0:11:32.
Batch 2,150  of  4,500.    Elapsed: 0:11:49.
Batch 2,200  of  4,500.    Elapsed: 0:12:05.
Batch 2,250  of  4,500.    Elapsed: 0:12:22.
Batch 2,300  of  4,500.    Elapsed: 0:12:38.
Batch 2,350  of  4,500.    Elapsed: 0:12:55.
Batch 2,400  of  4,500.    Elapsed: 0:13:11.
Batch 2,450  of  4,500.    Elapsed: 0:13:27.
Batch 2,500  of  4,500.    Elapsed: 0:13:44.
Batch 2,550  of  4,500.    Elapsed: 0:14:00.
Batch 2,600  of  4,500.    Elapsed: 0:14:17.
Batch 2,650  of  4,500.    Elapsed: 0:14:33.
Batch 2,700  of  4,500.    Elapsed: 0:14:50.
Batch 2,750  of  4,500.    Elapsed: 0:15:06.
Batch 2,800  of  4,500.    Elapsed: 0:15:23.
Batch 2,850  of  4,500.    Elapsed: 0:15:39.
Batch 2,900  of  4,500.    Elapsed: 0:15:56.
Batch 2,950  of  4,500.    Elapsed: 0:16:12.
Batch 3,000  of  4,500.    Elapsed: 0:16:29.
Batch 3,050  of  4,500.    Elapsed: 0:16:45.
Batch 3,100  of  4,500.    Elapsed: 0:17:02.
Batch 3,150  of  4,500.    Elapsed: 0:17:18.
Batch 3,200  of  4,500.    Elapsed: 0:17:34.
Batch 3,250  of  4,500.    Elapsed: 0:17:51.
Batch 3,300  of  4,500.    Elapsed: 0:18:07.
Batch 3,350  of  4,500.    Elapsed: 0:18:24.
Batch 3,400  of  4,500.    Elapsed: 0:18:40.
Batch 3,450  of  4,500.    Elapsed: 0:18:57.
Batch 3,500  of  4,500.    Elapsed: 0:19:13.
Batch 3,550  of  4,500.    Elapsed: 0:19:29.
Batch 3,600  of  4,500.    Elapsed: 0:19:46.
Batch 3,650  of  4,500.    Elapsed: 0:20:02.
Batch 3,700  of  4,500.    Elapsed: 0:20:19.
Batch 3,750  of  4,500.    Elapsed: 0:20:35.
Batch 3,800  of  4,500.    Elapsed: 0:20:51.
Batch 3,850  of  4,500.    Elapsed: 0:21:08.
Batch 3,900  of  4,500.    Elapsed: 0:21:24.
Batch 3,950  of  4,500.    Elapsed: 0:21:41.
Batch 4,000  of  4,500.    Elapsed: 0:21:57.
Batch 4,050  of  4,500.    Elapsed: 0:22:13.
Batch 4,100  of  4,500.    Elapsed: 0:22:30.
Batch 4,150  of  4,500.    Elapsed: 0:22:46.
Batch 4,200  of  4,500.    Elapsed: 0:23:03.
Batch 4,250  of  4,500.    Elapsed: 0:23:19.
Batch 4,300  of  4,500.    Elapsed: 0:23:35.
Batch 4,350  of  4,500.    Elapsed: 0:23:52.
Batch 4,400  of  4,500.    Elapsed: 0:24:08.
Batch 4,450  of  4,500.    Elapsed: 0:24:25.

  Average training loss: 0.38
  Training epoch took: 0:24:41

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.87
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:07.
Batch   250  of  4,500.    Elapsed: 0:01:24.
Batch   300  of  4,500.    Elapsed: 0:01:41.
Batch   350  of  4,500.    Elapsed: 0:01:58.
Batch   400  of  4,500.    Elapsed: 0:02:15.
Batch   450  of  4,500.    Elapsed: 0:02:32.
Batch   500  of  4,500.    Elapsed: 0:02:48.
Batch   550  of  4,500.    Elapsed: 0:03:05.
Batch   600  of  4,500.    Elapsed: 0:03:22.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:55.
Batch   750  of  4,500.    Elapsed: 0:04:12.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:46.
Batch   900  of  4,500.    Elapsed: 0:05:03.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:36.
Batch 1,050  of  4,500.    Elapsed: 0:05:53.
Batch 1,100  of  4,500.    Elapsed: 0:06:10.
Batch 1,150  of  4,500.    Elapsed: 0:06:27.
Batch 1,200  of  4,500.    Elapsed: 0:06:44.
Batch 1,250  of  4,500.    Elapsed: 0:07:01.
Batch 1,300  of  4,500.    Elapsed: 0:07:18.
Batch 1,350  of  4,500.    Elapsed: 0:07:35.
Batch 1,400  of  4,500.    Elapsed: 0:07:51.
Batch 1,450  of  4,500.    Elapsed: 0:08:08.
Batch 1,500  of  4,500.    Elapsed: 0:08:25.
Batch 1,550  of  4,500.    Elapsed: 0:08:42.
Batch 1,600  of  4,500.    Elapsed: 0:08:59.
Batch 1,650  of  4,500.    Elapsed: 0:09:16.
Batch 1,700  of  4,500.    Elapsed: 0:09:33.
Batch 1,750  of  4,500.    Elapsed: 0:09:50.
Batch 1,800  of  4,500.    Elapsed: 0:10:06.
Batch 1,850  of  4,500.    Elapsed: 0:10:23.
Batch 1,900  of  4,500.    Elapsed: 0:10:39.
Batch 1,950  of  4,500.    Elapsed: 0:10:56.
Batch 2,000  of  4,500.    Elapsed: 0:11:12.
Batch 2,050  of  4,500.    Elapsed: 0:11:28.
Batch 2,100  of  4,500.    Elapsed: 0:11:45.
Batch 2,150  of  4,500.    Elapsed: 0:12:01.
Batch 2,200  of  4,500.    Elapsed: 0:12:17.
Batch 2,250  of  4,500.    Elapsed: 0:12:34.
Batch 2,300  of  4,500.    Elapsed: 0:12:50.
Batch 2,350  of  4,500.    Elapsed: 0:13:07.
Batch 2,400  of  4,500.    Elapsed: 0:13:23.
Batch 2,450  of  4,500.    Elapsed: 0:13:40.
Batch 2,500  of  4,500.    Elapsed: 0:13:56.
Batch 2,550  of  4,500.    Elapsed: 0:14:12.
Batch 2,600  of  4,500.    Elapsed: 0:14:29.
Batch 2,650  of  4,500.    Elapsed: 0:14:45.
Batch 2,700  of  4,500.    Elapsed: 0:15:02.
Batch 2,750  of  4,500.    Elapsed: 0:15:18.
Batch 2,800  of  4,500.    Elapsed: 0:15:35.
Batch 2,850  of  4,500.    Elapsed: 0:15:51.
Batch 2,900  of  4,500.    Elapsed: 0:16:08.
Batch 2,950  of  4,500.    Elapsed: 0:16:24.
Batch 3,000  of  4,500.    Elapsed: 0:16:41.
Batch 3,050  of  4,500.    Elapsed: 0:16:57.
Batch 3,100  of  4,500.    Elapsed: 0:17:14.
Batch 3,150  of  4,500.    Elapsed: 0:17:30.
Batch 3,200  of  4,500.    Elapsed: 0:17:46.
Batch 3,250  of  4,500.    Elapsed: 0:18:03.
Batch 3,300  of  4,500.    Elapsed: 0:18:19.
Batch 3,350  of  4,500.    Elapsed: 0:18:36.
Batch 3,400  of  4,500.    Elapsed: 0:18:52.
Batch 3,450  of  4,500.    Elapsed: 0:19:09.
Batch 3,500  of  4,500.    Elapsed: 0:19:25.
Batch 3,550  of  4,500.    Elapsed: 0:19:41.
Batch 3,600  of  4,500.    Elapsed: 0:19:58.
Batch 3,650  of  4,500.    Elapsed: 0:20:14.
Batch 3,700  of  4,500.    Elapsed: 0:20:31.
Batch 3,750  of  4,500.    Elapsed: 0:20:47.
Batch 3,800  of  4,500.    Elapsed: 0:21:04.
Batch 3,850  of  4,500.    Elapsed: 0:21:20.
Batch 3,900  of  4,500.    Elapsed: 0:21:37.
Batch 3,950  of  4,500.    Elapsed: 0:21:53.
Batch 4,000  of  4,500.    Elapsed: 0:22:10.
Batch 4,050  of  4,500.    Elapsed: 0:22:26.
Batch 4,100  of  4,500.    Elapsed: 0:22:43.
Batch 4,150  of  4,500.    Elapsed: 0:22:59.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:43:21 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7547
INFO: Training took 1:44:23 (h:mm:ss)
INFO: Total duration: 106.6 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:16.
Batch 4,250  of  4,500.    Elapsed: 0:23:32.
Batch 4,300  of  4,500.    Elapsed: 0:23:49.
Batch 4,350  of  4,500.    Elapsed: 0:24:05.
Batch 4,400  of  4,500.    Elapsed: 0:24:22.
Batch 4,450  of  4,500.    Elapsed: 0:24:38.

  Average training loss: 0.30
  Training epoch took: 0:24:55

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 1.07
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 5/9.
INFO: Learning rate: 3e-05.
INFO: Split number: 2.
2020-08-27 23:35:43.921126: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-27 23:35:43.921171: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:39.
Batch   150  of  4,500.    Elapsed: 0:00:55.
Batch   200  of  4,500.    Elapsed: 0:01:11.
Batch   250  of  4,500.    Elapsed: 0:01:28.
Batch   300  of  4,500.    Elapsed: 0:01:44.
Batch   350  of  4,500.    Elapsed: 0:02:00.
Batch   400  of  4,500.    Elapsed: 0:02:17.
Batch   450  of  4,500.    Elapsed: 0:02:33.
Batch   500  of  4,500.    Elapsed: 0:02:50.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:22.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:55.
Batch   750  of  4,500.    Elapsed: 0:04:12.
Batch   800  of  4,500.    Elapsed: 0:04:28.
Batch   850  of  4,500.    Elapsed: 0:04:45.
Batch   900  of  4,500.    Elapsed: 0:05:01.
Batch   950  of  4,500.    Elapsed: 0:05:18.
Batch 1,000  of  4,500.    Elapsed: 0:05:34.
Batch 1,050  of  4,500.    Elapsed: 0:05:51.
Batch 1,100  of  4,500.    Elapsed: 0:06:07.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:40.
Batch 1,250  of  4,500.    Elapsed: 0:06:57.
Batch 1,300  of  4,500.    Elapsed: 0:07:13.
Batch 1,350  of  4,500.    Elapsed: 0:07:30.
Batch 1,400  of  4,500.    Elapsed: 0:07:46.
Batch 1,450  of  4,500.    Elapsed: 0:08:03.
Batch 1,500  of  4,500.    Elapsed: 0:08:20.
Batch 1,550  of  4,500.    Elapsed: 0:08:36.
Batch 1,600  of  4,500.    Elapsed: 0:08:52.
Batch 1,650  of  4,500.    Elapsed: 0:09:09.
Batch 1,700  of  4,500.    Elapsed: 0:09:25.
Batch 1,750  of  4,500.    Elapsed: 0:09:42.
Batch 1,800  of  4,500.    Elapsed: 0:09:59.
Batch 1,850  of  4,500.    Elapsed: 0:10:15.
Batch 1,900  of  4,500.    Elapsed: 0:10:32.
Batch 1,950  of  4,500.    Elapsed: 0:10:48.
Batch 2,000  of  4,500.    Elapsed: 0:11:05.
Batch 2,050  of  4,500.    Elapsed: 0:11:21.
Batch 2,100  of  4,500.    Elapsed: 0:11:38.
Batch 2,150  of  4,500.    Elapsed: 0:11:54.
Batch 2,200  of  4,500.    Elapsed: 0:12:11.
Batch 2,250  of  4,500.    Elapsed: 0:12:27.
Batch 2,300  of  4,500.    Elapsed: 0:12:44.
Batch 2,350  of  4,500.    Elapsed: 0:13:00.
Batch 2,400  of  4,500.    Elapsed: 0:13:17.
Batch 2,450  of  4,500.    Elapsed: 0:13:33.
Batch 2,500  of  4,500.    Elapsed: 0:13:50.
Batch 2,550  of  4,500.    Elapsed: 0:14:06.
Batch 2,600  of  4,500.    Elapsed: 0:14:23.
Batch 2,650  of  4,500.    Elapsed: 0:14:40.
Batch 2,700  of  4,500.    Elapsed: 0:14:56.
Batch 2,750  of  4,500.    Elapsed: 0:15:13.
Batch 2,800  of  4,500.    Elapsed: 0:15:29.
Batch 2,850  of  4,500.    Elapsed: 0:15:46.
Batch 2,900  of  4,500.    Elapsed: 0:16:02.
Batch 2,950  of  4,500.    Elapsed: 0:16:19.
Batch 3,000  of  4,500.    Elapsed: 0:16:35.
Batch 3,050  of  4,500.    Elapsed: 0:16:52.
Batch 3,100  of  4,500.    Elapsed: 0:17:08.
Batch 3,150  of  4,500.    Elapsed: 0:17:25.
Batch 3,200  of  4,500.    Elapsed: 0:17:41.
Batch 3,250  of  4,500.    Elapsed: 0:17:58.
Batch 3,300  of  4,500.    Elapsed: 0:18:14.
Batch 3,350  of  4,500.    Elapsed: 0:18:31.
Batch 3,400  of  4,500.    Elapsed: 0:18:47.
Batch 3,450  of  4,500.    Elapsed: 0:19:04.
Batch 3,500  of  4,500.    Elapsed: 0:19:20.
Batch 3,550  of  4,500.    Elapsed: 0:19:37.
Batch 3,600  of  4,500.    Elapsed: 0:19:53.
Batch 3,650  of  4,500.    Elapsed: 0:20:10.
Batch 3,700  of  4,500.    Elapsed: 0:20:26.
Batch 3,750  of  4,500.    Elapsed: 0:20:43.
Batch 3,800  of  4,500.    Elapsed: 0:20:59.
Batch 3,850  of  4,500.    Elapsed: 0:21:16.
Batch 3,900  of  4,500.    Elapsed: 0:21:32.
Batch 3,950  of  4,500.    Elapsed: 0:21:49.
Batch 4,000  of  4,500.    Elapsed: 0:22:05.
Batch 4,050  of  4,500.    Elapsed: 0:22:22.
Batch 4,100  of  4,500.    Elapsed: 0:22:38.
Batch 4,150  of  4,500.    Elapsed: 0:22:55.
Batch 4,200  of  4,500.    Elapsed: 0:23:11.
Batch 4,250  of  4,500.    Elapsed: 0:23:28.
Batch 4,300  of  4,500.    Elapsed: 0:23:44.
Batch 4,350  of  4,500.    Elapsed: 0:24:01.
Batch 4,400  of  4,500.    Elapsed: 0:24:17.
Batch 4,450  of  4,500.    Elapsed: 0:24:34.

  Average training loss: 0.62
  Training epoch took: 0:24:50

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.56
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:42.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:48.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:21.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:54.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:27.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:11:00.
Batch 2,050  of  4,500.    Elapsed: 0:11:17.
Batch 2,100  of  4,500.    Elapsed: 0:11:33.
Batch 2,150  of  4,500.    Elapsed: 0:11:50.
Batch 2,200  of  4,500.    Elapsed: 0:12:06.
Batch 2,250  of  4,500.    Elapsed: 0:12:23.
Batch 2,300  of  4,500.    Elapsed: 0:12:39.
Batch 2,350  of  4,500.    Elapsed: 0:12:56.
Batch 2,400  of  4,500.    Elapsed: 0:13:12.
Batch 2,450  of  4,500.    Elapsed: 0:13:29.
Batch 2,500  of  4,500.    Elapsed: 0:13:45.
Batch 2,550  of  4,500.    Elapsed: 0:14:02.
Batch 2,600  of  4,500.    Elapsed: 0:14:18.
Batch 2,650  of  4,500.    Elapsed: 0:14:35.
Batch 2,700  of  4,500.    Elapsed: 0:14:52.
Batch 2,750  of  4,500.    Elapsed: 0:15:08.
Batch 2,800  of  4,500.    Elapsed: 0:15:25.
Batch 2,850  of  4,500.    Elapsed: 0:15:41.
Batch 2,900  of  4,500.    Elapsed: 0:15:58.
Batch 2,950  of  4,500.    Elapsed: 0:16:14.
Batch 3,000  of  4,500.    Elapsed: 0:16:31.
Batch 3,050  of  4,500.    Elapsed: 0:16:47.
Batch 3,100  of  4,500.    Elapsed: 0:17:04.
Batch 3,150  of  4,500.    Elapsed: 0:17:20.
Batch 3,200  of  4,500.    Elapsed: 0:17:37.
Batch 3,250  of  4,500.    Elapsed: 0:17:54.
Batch 3,300  of  4,500.    Elapsed: 0:18:10.
Batch 3,350  of  4,500.    Elapsed: 0:18:27.
Batch 3,400  of  4,500.    Elapsed: 0:18:43.
Batch 3,450  of  4,500.    Elapsed: 0:19:00.
Batch 3,500  of  4,500.    Elapsed: 0:19:16.
Batch 3,550  of  4,500.    Elapsed: 0:19:33.
Batch 3,600  of  4,500.    Elapsed: 0:19:49.
Batch 3,650  of  4,500.    Elapsed: 0:20:06.
Batch 3,700  of  4,500.    Elapsed: 0:20:22.
Batch 3,750  of  4,500.    Elapsed: 0:20:39.
Batch 3,800  of  4,500.    Elapsed: 0:20:55.
Batch 3,850  of  4,500.    Elapsed: 0:21:12.
Batch 3,900  of  4,500.    Elapsed: 0:21:28.
Batch 3,950  of  4,500.    Elapsed: 0:21:45.
Batch 4,000  of  4,500.    Elapsed: 0:22:01.
Batch 4,050  of  4,500.    Elapsed: 0:22:18.
Batch 4,100  of  4,500.    Elapsed: 0:22:34.
Batch 4,150  of  4,500.    Elapsed: 0:22:50.
Batch 4,200  of  4,500.    Elapsed: 0:23:07.
Batch 4,250  of  4,500.    Elapsed: 0:23:23.
Batch 4,300  of  4,500.    Elapsed: 0:23:40.
Batch 4,350  of  4,500.    Elapsed: 0:23:56.
Batch 4,400  of  4,500.    Elapsed: 0:24:13.
Batch 4,450  of  4,500.    Elapsed: 0:24:29.

  Average training loss: 0.48
  Training epoch took: 0:24:46

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.62
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:20.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:53.
Batch 1,300  of  4,500.    Elapsed: 0:07:10.
Batch 1,350  of  4,500.    Elapsed: 0:07:26.
Batch 1,400  of  4,500.    Elapsed: 0:07:43.
Batch 1,450  of  4,500.    Elapsed: 0:07:59.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:32.
Batch 1,600  of  4,500.    Elapsed: 0:08:49.
Batch 1,650  of  4,500.    Elapsed: 0:09:05.
Batch 1,700  of  4,500.    Elapsed: 0:09:22.
Batch 1,750  of  4,500.    Elapsed: 0:09:38.
Batch 1,800  of  4,500.    Elapsed: 0:09:55.
Batch 1,850  of  4,500.    Elapsed: 0:10:11.
Batch 1,900  of  4,500.    Elapsed: 0:10:28.
Batch 1,950  of  4,500.    Elapsed: 0:10:44.
Batch 2,000  of  4,500.    Elapsed: 0:11:01.
Batch 2,050  of  4,500.    Elapsed: 0:11:17.
Batch 2,100  of  4,500.    Elapsed: 0:11:34.
Batch 2,150  of  4,500.    Elapsed: 0:11:50.
Batch 2,200  of  4,500.    Elapsed: 0:12:07.
Batch 2,250  of  4,500.    Elapsed: 0:12:23.
Batch 2,300  of  4,500.    Elapsed: 0:12:40.
Batch 2,350  of  4,500.    Elapsed: 0:12:57.
Batch 2,400  of  4,500.    Elapsed: 0:13:13.
Batch 2,450  of  4,500.    Elapsed: 0:13:30.
Batch 2,500  of  4,500.    Elapsed: 0:13:46.
Batch 2,550  of  4,500.    Elapsed: 0:14:03.
Batch 2,600  of  4,500.    Elapsed: 0:14:19.
Batch 2,650  of  4,500.    Elapsed: 0:14:36.
Batch 2,700  of  4,500.    Elapsed: 0:14:52.
Batch 2,750  of  4,500.    Elapsed: 0:15:09.
Batch 2,800  of  4,500.    Elapsed: 0:15:25.
Batch 2,850  of  4,500.    Elapsed: 0:15:42.
Batch 2,900  of  4,500.    Elapsed: 0:15:58.
Batch 2,950  of  4,500.    Elapsed: 0:16:15.
Batch 3,000  of  4,500.    Elapsed: 0:16:31.
Batch 3,050  of  4,500.    Elapsed: 0:16:48.
Batch 3,100  of  4,500.    Elapsed: 0:17:04.
Batch 3,150  of  4,500.    Elapsed: 0:17:21.
Batch 3,200  of  4,500.    Elapsed: 0:17:37.
Batch 3,250  of  4,500.    Elapsed: 0:17:54.
Batch 3,300  of  4,500.    Elapsed: 0:18:10.
Batch 3,350  of  4,500.    Elapsed: 0:18:27.
Batch 3,400  of  4,500.    Elapsed: 0:18:43.
Batch 3,450  of  4,500.    Elapsed: 0:19:00.
Batch 3,500  of  4,500.    Elapsed: 0:19:16.
Batch 3,550  of  4,500.    Elapsed: 0:19:33.
Batch 3,600  of  4,500.    Elapsed: 0:19:49.
Batch 3,650  of  4,500.    Elapsed: 0:20:06.
Batch 3,700  of  4,500.    Elapsed: 0:20:22.
Batch 3,750  of  4,500.    Elapsed: 0:20:39.
Batch 3,800  of  4,500.    Elapsed: 0:20:55.
Batch 3,850  of  4,500.    Elapsed: 0:21:12.
Batch 3,900  of  4,500.    Elapsed: 0:21:28.
Batch 3,950  of  4,500.    Elapsed: 0:21:45.
Batch 4,000  of  4,500.    Elapsed: 0:22:01.
Batch 4,050  of  4,500.    Elapsed: 0:22:18.
Batch 4,100  of  4,500.    Elapsed: 0:22:34.
Batch 4,150  of  4,500.    Elapsed: 0:22:51.
Batch 4,200  of  4,500.    Elapsed: 0:23:07.
Batch 4,250  of  4,500.    Elapsed: 0:23:24.
Batch 4,300  of  4,500.    Elapsed: 0:23:40.
Batch 4,350  of  4,500.    Elapsed: 0:23:56.
Batch 4,400  of  4,500.    Elapsed: 0:24:13.
Batch 4,450  of  4,500.    Elapsed: 0:24:29.

  Average training loss: 0.38
  Training epoch took: 0:24:46

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.82
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:42.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:48.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:10:59.
Batch 2,050  of  4,500.    Elapsed: 0:11:16.
Batch 2,100  of  4,500.    Elapsed: 0:11:32.
Batch 2,150  of  4,500.    Elapsed: 0:11:49.
Batch 2,200  of  4,500.    Elapsed: 0:12:05.
Batch 2,250  of  4,500.    Elapsed: 0:12:21.
Batch 2,300  of  4,500.    Elapsed: 0:12:38.
Batch 2,350  of  4,500.    Elapsed: 0:12:54.
Batch 2,400  of  4,500.    Elapsed: 0:13:11.
Batch 2,450  of  4,500.    Elapsed: 0:13:27.
Batch 2,500  of  4,500.    Elapsed: 0:13:44.
Batch 2,550  of  4,500.    Elapsed: 0:14:00.
Batch 2,600  of  4,500.    Elapsed: 0:14:17.
Batch 2,650  of  4,500.    Elapsed: 0:14:33.
Batch 2,700  of  4,500.    Elapsed: 0:14:50.
Batch 2,750  of  4,500.    Elapsed: 0:15:06.
Batch 2,800  of  4,500.    Elapsed: 0:15:23.
Batch 2,850  of  4,500.    Elapsed: 0:15:39.
Batch 2,900  of  4,500.    Elapsed: 0:15:55.
Batch 2,950  of  4,500.    Elapsed: 0:16:12.
Batch 3,000  of  4,500.    Elapsed: 0:16:28.
Batch 3,050  of  4,500.    Elapsed: 0:16:45.
Batch 3,100  of  4,500.    Elapsed: 0:17:01.
Batch 3,150  of  4,500.    Elapsed: 0:17:17.
Batch 3,200  of  4,500.    Elapsed: 0:17:34.
Batch 3,250  of  4,500.    Elapsed: 0:17:50.
Batch 3,300  of  4,500.    Elapsed: 0:18:07.
Batch 3,350  of  4,500.    Elapsed: 0:18:23.
Batch 3,400  of  4,500.    Elapsed: 0:18:39.
Batch 3,450  of  4,500.    Elapsed: 0:18:56.
Batch 3,500  of  4,500.    Elapsed: 0:19:12.
Batch 3,550  of  4,500.    Elapsed: 0:19:29.
Batch 3,600  of  4,500.    Elapsed: 0:19:45.
Batch 3,650  of  4,500.    Elapsed: 0:20:02.
Batch 3,700  of  4,500.    Elapsed: 0:20:18.
Batch 3,750  of  4,500.    Elapsed: 0:20:35.
Batch 3,800  of  4,500.    Elapsed: 0:20:51.
Batch 3,850  of  4,500.    Elapsed: 0:21:07.
Batch 3,900  of  4,500.    Elapsed: 0:21:24.
Batch 3,950  of  4,500.    Elapsed: 0:21:40.
Batch 4,000  of  4,500.    Elapsed: 0:21:57.
Batch 4,050  of  4,500.    Elapsed: 0:22:13.
Batch 4,100  of  4,500.    Elapsed: 0:22:29.
Batch 4,150  of  4,500.    Elapsed: 0:22:46.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:42:55 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7582
INFO: Training took 1:43:57 (h:mm:ss)
INFO: Total duration: 106.16666666666667 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:02.
Batch 4,250  of  4,500.    Elapsed: 0:23:19.
Batch 4,300  of  4,500.    Elapsed: 0:23:35.
Batch 4,350  of  4,500.    Elapsed: 0:23:52.
Batch 4,400  of  4,500.    Elapsed: 0:24:08.
Batch 4,450  of  4,500.    Elapsed: 0:24:25.

  Average training loss: 0.29
  Training epoch took: 0:24:41

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 1.10
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 6/9.
INFO: Learning rate: 3e-05.
INFO: Split number: 3.
2020-08-28 01:22:00.209635: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 01:22:00.209688: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:40.
Batch   150  of  4,500.    Elapsed: 0:00:56.
Batch   200  of  4,500.    Elapsed: 0:01:13.
Batch   250  of  4,500.    Elapsed: 0:01:29.
Batch   300  of  4,500.    Elapsed: 0:01:46.
Batch   350  of  4,500.    Elapsed: 0:02:02.
Batch   400  of  4,500.    Elapsed: 0:02:18.
Batch   450  of  4,500.    Elapsed: 0:02:35.
Batch   500  of  4,500.    Elapsed: 0:02:51.
Batch   550  of  4,500.    Elapsed: 0:03:08.
Batch   600  of  4,500.    Elapsed: 0:03:24.
Batch   650  of  4,500.    Elapsed: 0:03:40.
Batch   700  of  4,500.    Elapsed: 0:03:57.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:30.
Batch   850  of  4,500.    Elapsed: 0:04:46.
Batch   900  of  4,500.    Elapsed: 0:05:03.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:36.
Batch 1,050  of  4,500.    Elapsed: 0:05:52.
Batch 1,100  of  4,500.    Elapsed: 0:06:09.
Batch 1,150  of  4,500.    Elapsed: 0:06:25.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:14.
Batch 1,350  of  4,500.    Elapsed: 0:07:30.
Batch 1,400  of  4,500.    Elapsed: 0:07:47.
Batch 1,450  of  4,500.    Elapsed: 0:08:03.
Batch 1,500  of  4,500.    Elapsed: 0:08:19.
Batch 1,550  of  4,500.    Elapsed: 0:08:36.
Batch 1,600  of  4,500.    Elapsed: 0:08:52.
Batch 1,650  of  4,500.    Elapsed: 0:09:08.
Batch 1,700  of  4,500.    Elapsed: 0:09:25.
Batch 1,750  of  4,500.    Elapsed: 0:09:41.
Batch 1,800  of  4,500.    Elapsed: 0:09:58.
Batch 1,850  of  4,500.    Elapsed: 0:10:14.
Batch 1,900  of  4,500.    Elapsed: 0:10:30.
Batch 1,950  of  4,500.    Elapsed: 0:10:47.
Batch 2,000  of  4,500.    Elapsed: 0:11:03.
Batch 2,050  of  4,500.    Elapsed: 0:11:20.
Batch 2,100  of  4,500.    Elapsed: 0:11:36.
Batch 2,150  of  4,500.    Elapsed: 0:11:52.
Batch 2,200  of  4,500.    Elapsed: 0:12:09.
Batch 2,250  of  4,500.    Elapsed: 0:12:25.
Batch 2,300  of  4,500.    Elapsed: 0:12:42.
Batch 2,350  of  4,500.    Elapsed: 0:12:58.
Batch 2,400  of  4,500.    Elapsed: 0:13:15.
Batch 2,450  of  4,500.    Elapsed: 0:13:31.
Batch 2,500  of  4,500.    Elapsed: 0:13:47.
Batch 2,550  of  4,500.    Elapsed: 0:14:04.
Batch 2,600  of  4,500.    Elapsed: 0:14:20.
Batch 2,650  of  4,500.    Elapsed: 0:14:37.
Batch 2,700  of  4,500.    Elapsed: 0:14:53.
Batch 2,750  of  4,500.    Elapsed: 0:15:10.
Batch 2,800  of  4,500.    Elapsed: 0:15:26.
Batch 2,850  of  4,500.    Elapsed: 0:15:43.
Batch 2,900  of  4,500.    Elapsed: 0:15:59.
Batch 2,950  of  4,500.    Elapsed: 0:16:16.
Batch 3,000  of  4,500.    Elapsed: 0:16:32.
Batch 3,050  of  4,500.    Elapsed: 0:16:48.
Batch 3,100  of  4,500.    Elapsed: 0:17:05.
Batch 3,150  of  4,500.    Elapsed: 0:17:21.
Batch 3,200  of  4,500.    Elapsed: 0:17:38.
Batch 3,250  of  4,500.    Elapsed: 0:17:54.
Batch 3,300  of  4,500.    Elapsed: 0:18:10.
Batch 3,350  of  4,500.    Elapsed: 0:18:27.
Batch 3,400  of  4,500.    Elapsed: 0:18:43.
Batch 3,450  of  4,500.    Elapsed: 0:19:00.
Batch 3,500  of  4,500.    Elapsed: 0:19:16.
Batch 3,550  of  4,500.    Elapsed: 0:19:32.
Batch 3,600  of  4,500.    Elapsed: 0:19:49.
Batch 3,650  of  4,500.    Elapsed: 0:20:05.
Batch 3,700  of  4,500.    Elapsed: 0:20:20.
Batch 3,750  of  4,500.    Elapsed: 0:20:36.
Batch 3,800  of  4,500.    Elapsed: 0:20:52.
Batch 3,850  of  4,500.    Elapsed: 0:21:07.
Batch 3,900  of  4,500.    Elapsed: 0:21:23.
Batch 3,950  of  4,500.    Elapsed: 0:21:39.
Batch 4,000  of  4,500.    Elapsed: 0:21:54.
Batch 4,050  of  4,500.    Elapsed: 0:22:10.
Batch 4,100  of  4,500.    Elapsed: 0:22:26.
Batch 4,150  of  4,500.    Elapsed: 0:22:42.
Batch 4,200  of  4,500.    Elapsed: 0:22:57.
Batch 4,250  of  4,500.    Elapsed: 0:23:13.
Batch 4,300  of  4,500.    Elapsed: 0:23:29.
Batch 4,350  of  4,500.    Elapsed: 0:23:44.
Batch 4,400  of  4,500.    Elapsed: 0:24:00.
Batch 4,450  of  4,500.    Elapsed: 0:24:16.

  Average training loss: 0.63
  Training epoch took: 0:24:31

Now Validating.
  Validation Accuracy: 0.74
  Validation Loss: 0.67
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:16.
Batch   100  of  4,500.    Elapsed: 0:00:32.
Batch   150  of  4,500.    Elapsed: 0:00:47.
Batch   200  of  4,500.    Elapsed: 0:01:03.
Batch   250  of  4,500.    Elapsed: 0:01:19.
Batch   300  of  4,500.    Elapsed: 0:01:34.
Batch   350  of  4,500.    Elapsed: 0:01:50.
Batch   400  of  4,500.    Elapsed: 0:02:06.
Batch   450  of  4,500.    Elapsed: 0:02:22.
Batch   500  of  4,500.    Elapsed: 0:02:37.
Batch   550  of  4,500.    Elapsed: 0:02:53.
Batch   600  of  4,500.    Elapsed: 0:03:09.
Batch   650  of  4,500.    Elapsed: 0:03:25.
Batch   700  of  4,500.    Elapsed: 0:03:41.
Batch   750  of  4,500.    Elapsed: 0:03:58.
Batch   800  of  4,500.    Elapsed: 0:04:14.
Batch   850  of  4,500.    Elapsed: 0:04:31.
Batch   900  of  4,500.    Elapsed: 0:04:47.
Batch   950  of  4,500.    Elapsed: 0:05:03.
Batch 1,000  of  4,500.    Elapsed: 0:05:20.
Batch 1,050  of  4,500.    Elapsed: 0:05:36.
Batch 1,100  of  4,500.    Elapsed: 0:05:53.
Batch 1,150  of  4,500.    Elapsed: 0:06:09.
Batch 1,200  of  4,500.    Elapsed: 0:06:26.
Batch 1,250  of  4,500.    Elapsed: 0:06:42.
Batch 1,300  of  4,500.    Elapsed: 0:06:59.
Batch 1,350  of  4,500.    Elapsed: 0:07:15.
Batch 1,400  of  4,500.    Elapsed: 0:07:31.
Batch 1,450  of  4,500.    Elapsed: 0:07:48.
Batch 1,500  of  4,500.    Elapsed: 0:08:04.
Batch 1,550  of  4,500.    Elapsed: 0:08:21.
Batch 1,600  of  4,500.    Elapsed: 0:08:37.
Batch 1,650  of  4,500.    Elapsed: 0:08:54.
Batch 1,700  of  4,500.    Elapsed: 0:09:10.
Batch 1,750  of  4,500.    Elapsed: 0:09:26.
Batch 1,800  of  4,500.    Elapsed: 0:09:43.
Batch 1,850  of  4,500.    Elapsed: 0:09:59.
Batch 1,900  of  4,500.    Elapsed: 0:10:16.
Batch 1,950  of  4,500.    Elapsed: 0:10:32.
Batch 2,000  of  4,500.    Elapsed: 0:10:49.
Batch 2,050  of  4,500.    Elapsed: 0:11:05.
Batch 2,100  of  4,500.    Elapsed: 0:11:22.
Batch 2,150  of  4,500.    Elapsed: 0:11:38.
Batch 2,200  of  4,500.    Elapsed: 0:11:54.
Batch 2,250  of  4,500.    Elapsed: 0:12:11.
Batch 2,300  of  4,500.    Elapsed: 0:12:27.
Batch 2,350  of  4,500.    Elapsed: 0:12:44.
Batch 2,400  of  4,500.    Elapsed: 0:13:00.
Batch 2,450  of  4,500.    Elapsed: 0:13:17.
Batch 2,500  of  4,500.    Elapsed: 0:13:33.
Batch 2,550  of  4,500.    Elapsed: 0:13:50.
Batch 2,600  of  4,500.    Elapsed: 0:14:06.
Batch 2,650  of  4,500.    Elapsed: 0:14:22.
Batch 2,700  of  4,500.    Elapsed: 0:14:39.
Batch 2,750  of  4,500.    Elapsed: 0:14:55.
Batch 2,800  of  4,500.    Elapsed: 0:15:12.
Batch 2,850  of  4,500.    Elapsed: 0:15:28.
Batch 2,900  of  4,500.    Elapsed: 0:15:45.
Batch 2,950  of  4,500.    Elapsed: 0:16:01.
Batch 3,000  of  4,500.    Elapsed: 0:16:18.
Batch 3,050  of  4,500.    Elapsed: 0:16:35.
Batch 3,100  of  4,500.    Elapsed: 0:16:52.
Batch 3,150  of  4,500.    Elapsed: 0:17:08.
Batch 3,200  of  4,500.    Elapsed: 0:17:25.
Batch 3,250  of  4,500.    Elapsed: 0:17:42.
Batch 3,300  of  4,500.    Elapsed: 0:17:59.
Batch 3,350  of  4,500.    Elapsed: 0:18:16.
Batch 3,400  of  4,500.    Elapsed: 0:18:32.
Batch 3,450  of  4,500.    Elapsed: 0:18:49.
Batch 3,500  of  4,500.    Elapsed: 0:19:06.
Batch 3,550  of  4,500.    Elapsed: 0:19:23.
Batch 3,600  of  4,500.    Elapsed: 0:19:39.
Batch 3,650  of  4,500.    Elapsed: 0:19:56.
Batch 3,700  of  4,500.    Elapsed: 0:20:13.
Batch 3,750  of  4,500.    Elapsed: 0:20:30.
Batch 3,800  of  4,500.    Elapsed: 0:20:47.
Batch 3,850  of  4,500.    Elapsed: 0:21:04.
Batch 3,900  of  4,500.    Elapsed: 0:21:20.
Batch 3,950  of  4,500.    Elapsed: 0:21:37.
Batch 4,000  of  4,500.    Elapsed: 0:21:54.
Batch 4,050  of  4,500.    Elapsed: 0:22:11.
Batch 4,100  of  4,500.    Elapsed: 0:22:28.
Batch 4,150  of  4,500.    Elapsed: 0:22:45.
Batch 4,200  of  4,500.    Elapsed: 0:23:01.
Batch 4,250  of  4,500.    Elapsed: 0:23:18.
Batch 4,300  of  4,500.    Elapsed: 0:23:35.
Batch 4,350  of  4,500.    Elapsed: 0:23:52.
Batch 4,400  of  4,500.    Elapsed: 0:24:09.
Batch 4,450  of  4,500.    Elapsed: 0:24:26.

  Average training loss: 0.48
  Training epoch took: 0:24:42

Now Validating.
  Validation Accuracy: 0.78
  Validation Loss: 0.57
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:49.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:11.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:44.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:17.
Batch   650  of  4,500.    Elapsed: 0:03:33.
Batch   700  of  4,500.    Elapsed: 0:03:50.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:20.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:42.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:09.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:42.
Batch 2,000  of  4,500.    Elapsed: 0:10:59.
Batch 2,050  of  4,500.    Elapsed: 0:11:15.
Batch 2,100  of  4,500.    Elapsed: 0:11:31.
Batch 2,150  of  4,500.    Elapsed: 0:11:48.
Batch 2,200  of  4,500.    Elapsed: 0:12:04.
Batch 2,250  of  4,500.    Elapsed: 0:12:21.
Batch 2,300  of  4,500.    Elapsed: 0:12:37.
Batch 2,350  of  4,500.    Elapsed: 0:12:54.
Batch 2,400  of  4,500.    Elapsed: 0:13:10.
Batch 2,450  of  4,500.    Elapsed: 0:13:26.
Batch 2,500  of  4,500.    Elapsed: 0:13:43.
Batch 2,550  of  4,500.    Elapsed: 0:13:59.
Batch 2,600  of  4,500.    Elapsed: 0:14:16.
Batch 2,650  of  4,500.    Elapsed: 0:14:32.
Batch 2,700  of  4,500.    Elapsed: 0:14:48.
Batch 2,750  of  4,500.    Elapsed: 0:15:05.
Batch 2,800  of  4,500.    Elapsed: 0:15:21.
Batch 2,850  of  4,500.    Elapsed: 0:15:38.
Batch 2,900  of  4,500.    Elapsed: 0:15:54.
Batch 2,950  of  4,500.    Elapsed: 0:16:11.
Batch 3,000  of  4,500.    Elapsed: 0:16:27.
Batch 3,050  of  4,500.    Elapsed: 0:16:43.
Batch 3,100  of  4,500.    Elapsed: 0:17:00.
Batch 3,150  of  4,500.    Elapsed: 0:17:16.
Batch 3,200  of  4,500.    Elapsed: 0:17:33.
Batch 3,250  of  4,500.    Elapsed: 0:17:49.
Batch 3,300  of  4,500.    Elapsed: 0:18:06.
Batch 3,350  of  4,500.    Elapsed: 0:18:22.
Batch 3,400  of  4,500.    Elapsed: 0:18:38.
Batch 3,450  of  4,500.    Elapsed: 0:18:55.
Batch 3,500  of  4,500.    Elapsed: 0:19:12.
Batch 3,550  of  4,500.    Elapsed: 0:19:29.
Batch 3,600  of  4,500.    Elapsed: 0:19:46.
Batch 3,650  of  4,500.    Elapsed: 0:20:02.
Batch 3,700  of  4,500.    Elapsed: 0:20:19.
Batch 3,750  of  4,500.    Elapsed: 0:20:36.
Batch 3,800  of  4,500.    Elapsed: 0:20:53.
Batch 3,850  of  4,500.    Elapsed: 0:21:10.
Batch 3,900  of  4,500.    Elapsed: 0:21:26.
Batch 3,950  of  4,500.    Elapsed: 0:21:43.
Batch 4,000  of  4,500.    Elapsed: 0:22:00.
Batch 4,050  of  4,500.    Elapsed: 0:22:17.
Batch 4,100  of  4,500.    Elapsed: 0:22:34.
Batch 4,150  of  4,500.    Elapsed: 0:22:51.
Batch 4,200  of  4,500.    Elapsed: 0:23:08.
Batch 4,250  of  4,500.    Elapsed: 0:23:24.
Batch 4,300  of  4,500.    Elapsed: 0:23:41.
Batch 4,350  of  4,500.    Elapsed: 0:23:58.
Batch 4,400  of  4,500.    Elapsed: 0:24:15.
Batch 4,450  of  4,500.    Elapsed: 0:24:32.

  Average training loss: 0.38
  Training epoch took: 0:24:48

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 0.79
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:07.
Batch   250  of  4,500.    Elapsed: 0:01:24.
Batch   300  of  4,500.    Elapsed: 0:01:41.
Batch   350  of  4,500.    Elapsed: 0:01:58.
Batch   400  of  4,500.    Elapsed: 0:02:15.
Batch   450  of  4,500.    Elapsed: 0:02:31.
Batch   500  of  4,500.    Elapsed: 0:02:48.
Batch   550  of  4,500.    Elapsed: 0:03:05.
Batch   600  of  4,500.    Elapsed: 0:03:22.
Batch   650  of  4,500.    Elapsed: 0:03:38.
Batch   700  of  4,500.    Elapsed: 0:03:55.
Batch   750  of  4,500.    Elapsed: 0:04:12.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:45.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:36.
Batch 1,050  of  4,500.    Elapsed: 0:05:52.
Batch 1,100  of  4,500.    Elapsed: 0:06:09.
Batch 1,150  of  4,500.    Elapsed: 0:06:26.
Batch 1,200  of  4,500.    Elapsed: 0:06:43.
Batch 1,250  of  4,500.    Elapsed: 0:06:59.
Batch 1,300  of  4,500.    Elapsed: 0:07:16.
Batch 1,350  of  4,500.    Elapsed: 0:07:33.
Batch 1,400  of  4,500.    Elapsed: 0:07:49.
Batch 1,450  of  4,500.    Elapsed: 0:08:06.
Batch 1,500  of  4,500.    Elapsed: 0:08:23.
Batch 1,550  of  4,500.    Elapsed: 0:08:40.
Batch 1,600  of  4,500.    Elapsed: 0:08:56.
Batch 1,650  of  4,500.    Elapsed: 0:09:13.
Batch 1,700  of  4,500.    Elapsed: 0:09:29.
Batch 1,750  of  4,500.    Elapsed: 0:09:46.
Batch 1,800  of  4,500.    Elapsed: 0:10:02.
Batch 1,850  of  4,500.    Elapsed: 0:10:19.
Batch 1,900  of  4,500.    Elapsed: 0:10:35.
Batch 1,950  of  4,500.    Elapsed: 0:10:51.
Batch 2,000  of  4,500.    Elapsed: 0:11:08.
Batch 2,050  of  4,500.    Elapsed: 0:11:24.
Batch 2,100  of  4,500.    Elapsed: 0:11:40.
Batch 2,150  of  4,500.    Elapsed: 0:11:57.
Batch 2,200  of  4,500.    Elapsed: 0:12:13.
Batch 2,250  of  4,500.    Elapsed: 0:12:30.
Batch 2,300  of  4,500.    Elapsed: 0:12:46.
Batch 2,350  of  4,500.    Elapsed: 0:13:02.
Batch 2,400  of  4,500.    Elapsed: 0:13:19.
Batch 2,450  of  4,500.    Elapsed: 0:13:35.
Batch 2,500  of  4,500.    Elapsed: 0:13:52.
Batch 2,550  of  4,500.    Elapsed: 0:14:08.
Batch 2,600  of  4,500.    Elapsed: 0:14:24.
Batch 2,650  of  4,500.    Elapsed: 0:14:41.
Batch 2,700  of  4,500.    Elapsed: 0:14:57.
Batch 2,750  of  4,500.    Elapsed: 0:15:14.
Batch 2,800  of  4,500.    Elapsed: 0:15:30.
Batch 2,850  of  4,500.    Elapsed: 0:15:46.
Batch 2,900  of  4,500.    Elapsed: 0:16:03.
Batch 2,950  of  4,500.    Elapsed: 0:16:19.
Batch 3,000  of  4,500.    Elapsed: 0:16:36.
Batch 3,050  of  4,500.    Elapsed: 0:16:52.
Batch 3,100  of  4,500.    Elapsed: 0:17:08.
Batch 3,150  of  4,500.    Elapsed: 0:17:25.
Batch 3,200  of  4,500.    Elapsed: 0:17:41.
Batch 3,250  of  4,500.    Elapsed: 0:17:57.
Batch 3,300  of  4,500.    Elapsed: 0:18:14.
Batch 3,350  of  4,500.    Elapsed: 0:18:30.
Batch 3,400  of  4,500.    Elapsed: 0:18:46.
Batch 3,450  of  4,500.    Elapsed: 0:19:03.
Batch 3,500  of  4,500.    Elapsed: 0:19:19.
Batch 3,550  of  4,500.    Elapsed: 0:19:35.
Batch 3,600  of  4,500.    Elapsed: 0:19:52.
Batch 3,650  of  4,500.    Elapsed: 0:20:08.
Batch 3,700  of  4,500.    Elapsed: 0:20:24.
Batch 3,750  of  4,500.    Elapsed: 0:20:41.
Batch 3,800  of  4,500.    Elapsed: 0:20:57.
Batch 3,850  of  4,500.    Elapsed: 0:21:13.
Batch 3,900  of  4,500.    Elapsed: 0:21:30.
Batch 3,950  of  4,500.    Elapsed: 0:21:46.
Batch 4,000  of  4,500.    Elapsed: 0:22:02.
Batch 4,050  of  4,500.    Elapsed: 0:22:19.
Batch 4,100  of  4,500.    Elapsed: 0:22:35.
Batch 4,150  of  4,500.    Elapsed: 0:22:52.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:42:41 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7531
INFO: Training took 1:43:43 (h:mm:ss)
INFO: Total duration: 105.66666666666667 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:08.
Batch 4,250  of  4,500.    Elapsed: 0:23:24.
Batch 4,300  of  4,500.    Elapsed: 0:23:41.
Batch 4,350  of  4,500.    Elapsed: 0:23:57.
Batch 4,400  of  4,500.    Elapsed: 0:24:14.
Batch 4,450  of  4,500.    Elapsed: 0:24:30.

  Average training loss: 0.30
  Training epoch took: 0:24:47

Now Validating.
  Validation Accuracy: 0.77
  Validation Loss: 1.13
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 7/9.
INFO: Learning rate: 5e-05.
INFO: Split number: 1.
2020-08-28 03:07:47.362799: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 03:07:47.362852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:39.
Batch   150  of  4,500.    Elapsed: 0:00:55.
Batch   200  of  4,500.    Elapsed: 0:01:12.
Batch   250  of  4,500.    Elapsed: 0:01:28.
Batch   300  of  4,500.    Elapsed: 0:01:44.
Batch   350  of  4,500.    Elapsed: 0:02:01.
Batch   400  of  4,500.    Elapsed: 0:02:17.
Batch   450  of  4,500.    Elapsed: 0:02:33.
Batch   500  of  4,500.    Elapsed: 0:02:50.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:39.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:12.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:45.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:18.
Batch 1,000  of  4,500.    Elapsed: 0:05:34.
Batch 1,050  of  4,500.    Elapsed: 0:05:51.
Batch 1,100  of  4,500.    Elapsed: 0:06:07.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:40.
Batch 1,250  of  4,500.    Elapsed: 0:06:57.
Batch 1,300  of  4,500.    Elapsed: 0:07:13.
Batch 1,350  of  4,500.    Elapsed: 0:07:30.
Batch 1,400  of  4,500.    Elapsed: 0:07:46.
Batch 1,450  of  4,500.    Elapsed: 0:08:03.
Batch 1,500  of  4,500.    Elapsed: 0:08:19.
Batch 1,550  of  4,500.    Elapsed: 0:08:36.
Batch 1,600  of  4,500.    Elapsed: 0:08:52.
Batch 1,650  of  4,500.    Elapsed: 0:09:09.
Batch 1,700  of  4,500.    Elapsed: 0:09:26.
Batch 1,750  of  4,500.    Elapsed: 0:09:43.
Batch 1,800  of  4,500.    Elapsed: 0:10:00.
Batch 1,850  of  4,500.    Elapsed: 0:10:16.
Batch 1,900  of  4,500.    Elapsed: 0:10:33.
Batch 1,950  of  4,500.    Elapsed: 0:10:50.
Batch 2,000  of  4,500.    Elapsed: 0:11:07.
Batch 2,050  of  4,500.    Elapsed: 0:11:24.
Batch 2,100  of  4,500.    Elapsed: 0:11:41.
Batch 2,150  of  4,500.    Elapsed: 0:11:58.
Batch 2,200  of  4,500.    Elapsed: 0:12:15.
Batch 2,250  of  4,500.    Elapsed: 0:12:31.
Batch 2,300  of  4,500.    Elapsed: 0:12:48.
Batch 2,350  of  4,500.    Elapsed: 0:13:05.
Batch 2,400  of  4,500.    Elapsed: 0:13:22.
Batch 2,450  of  4,500.    Elapsed: 0:13:39.
Batch 2,500  of  4,500.    Elapsed: 0:13:56.
Batch 2,550  of  4,500.    Elapsed: 0:14:13.
Batch 2,600  of  4,500.    Elapsed: 0:14:30.
Batch 2,650  of  4,500.    Elapsed: 0:14:47.
Batch 2,700  of  4,500.    Elapsed: 0:15:04.
Batch 2,750  of  4,500.    Elapsed: 0:15:21.
Batch 2,800  of  4,500.    Elapsed: 0:15:38.
Batch 2,850  of  4,500.    Elapsed: 0:15:55.
Batch 2,900  of  4,500.    Elapsed: 0:16:12.
Batch 2,950  of  4,500.    Elapsed: 0:16:28.
Batch 3,000  of  4,500.    Elapsed: 0:16:45.
Batch 3,050  of  4,500.    Elapsed: 0:17:02.
Batch 3,100  of  4,500.    Elapsed: 0:17:18.
Batch 3,150  of  4,500.    Elapsed: 0:17:35.
Batch 3,200  of  4,500.    Elapsed: 0:17:51.
Batch 3,250  of  4,500.    Elapsed: 0:18:07.
Batch 3,300  of  4,500.    Elapsed: 0:18:24.
Batch 3,350  of  4,500.    Elapsed: 0:18:40.
Batch 3,400  of  4,500.    Elapsed: 0:18:57.
Batch 3,450  of  4,500.    Elapsed: 0:19:13.
Batch 3,500  of  4,500.    Elapsed: 0:19:30.
Batch 3,550  of  4,500.    Elapsed: 0:19:47.
Batch 3,600  of  4,500.    Elapsed: 0:20:03.
Batch 3,650  of  4,500.    Elapsed: 0:20:20.
Batch 3,700  of  4,500.    Elapsed: 0:20:36.
Batch 3,750  of  4,500.    Elapsed: 0:20:53.
Batch 3,800  of  4,500.    Elapsed: 0:21:09.
Batch 3,850  of  4,500.    Elapsed: 0:21:26.
Batch 3,900  of  4,500.    Elapsed: 0:21:42.
Batch 3,950  of  4,500.    Elapsed: 0:21:59.
Batch 4,000  of  4,500.    Elapsed: 0:22:15.
Batch 4,050  of  4,500.    Elapsed: 0:22:32.
Batch 4,100  of  4,500.    Elapsed: 0:22:48.
Batch 4,150  of  4,500.    Elapsed: 0:23:05.
Batch 4,200  of  4,500.    Elapsed: 0:23:21.
Batch 4,250  of  4,500.    Elapsed: 0:23:38.
Batch 4,300  of  4,500.    Elapsed: 0:23:54.
Batch 4,350  of  4,500.    Elapsed: 0:24:11.
Batch 4,400  of  4,500.    Elapsed: 0:24:28.
Batch 4,450  of  4,500.    Elapsed: 0:24:45.

  Average training loss: 0.66
  Training epoch took: 0:25:02

Now Validating.
  Validation Accuracy: 0.74
  Validation Loss: 0.58
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:34.
Batch   150  of  4,500.    Elapsed: 0:00:51.
Batch   200  of  4,500.    Elapsed: 0:01:08.
Batch   250  of  4,500.    Elapsed: 0:01:25.
Batch   300  of  4,500.    Elapsed: 0:01:42.
Batch   350  of  4,500.    Elapsed: 0:01:59.
Batch   400  of  4,500.    Elapsed: 0:02:16.
Batch   450  of  4,500.    Elapsed: 0:02:33.
Batch   500  of  4,500.    Elapsed: 0:02:49.
Batch   550  of  4,500.    Elapsed: 0:03:06.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:40.
Batch   700  of  4,500.    Elapsed: 0:03:57.
Batch   750  of  4,500.    Elapsed: 0:04:14.
Batch   800  of  4,500.    Elapsed: 0:04:31.
Batch   850  of  4,500.    Elapsed: 0:04:48.
Batch   900  of  4,500.    Elapsed: 0:05:05.
Batch   950  of  4,500.    Elapsed: 0:05:22.
Batch 1,000  of  4,500.    Elapsed: 0:05:39.
Batch 1,050  of  4,500.    Elapsed: 0:05:56.
Batch 1,100  of  4,500.    Elapsed: 0:06:13.
Batch 1,150  of  4,500.    Elapsed: 0:06:30.
Batch 1,200  of  4,500.    Elapsed: 0:06:47.
Batch 1,250  of  4,500.    Elapsed: 0:07:04.
Batch 1,300  of  4,500.    Elapsed: 0:07:21.
Batch 1,350  of  4,500.    Elapsed: 0:07:38.
Batch 1,400  of  4,500.    Elapsed: 0:07:54.
Batch 1,450  of  4,500.    Elapsed: 0:08:11.
Batch 1,500  of  4,500.    Elapsed: 0:08:28.
Batch 1,550  of  4,500.    Elapsed: 0:08:45.
Batch 1,600  of  4,500.    Elapsed: 0:09:02.
Batch 1,650  of  4,500.    Elapsed: 0:09:19.
Batch 1,700  of  4,500.    Elapsed: 0:09:36.
Batch 1,750  of  4,500.    Elapsed: 0:09:53.
Batch 1,800  of  4,500.    Elapsed: 0:10:10.
Batch 1,850  of  4,500.    Elapsed: 0:10:27.
Batch 1,900  of  4,500.    Elapsed: 0:10:44.
Batch 1,950  of  4,500.    Elapsed: 0:11:01.
Batch 2,000  of  4,500.    Elapsed: 0:11:18.
Batch 2,050  of  4,500.    Elapsed: 0:11:35.
Batch 2,100  of  4,500.    Elapsed: 0:11:52.
Batch 2,150  of  4,500.    Elapsed: 0:12:09.
Batch 2,200  of  4,500.    Elapsed: 0:12:26.
Batch 2,250  of  4,500.    Elapsed: 0:12:43.
Batch 2,300  of  4,500.    Elapsed: 0:13:00.
Batch 2,350  of  4,500.    Elapsed: 0:13:17.
Batch 2,400  of  4,500.    Elapsed: 0:13:34.
Batch 2,450  of  4,500.    Elapsed: 0:13:50.
Batch 2,500  of  4,500.    Elapsed: 0:14:07.
Batch 2,550  of  4,500.    Elapsed: 0:14:24.
Batch 2,600  of  4,500.    Elapsed: 0:14:41.
Batch 2,650  of  4,500.    Elapsed: 0:14:58.
Batch 2,700  of  4,500.    Elapsed: 0:15:15.
Batch 2,750  of  4,500.    Elapsed: 0:15:32.
Batch 2,800  of  4,500.    Elapsed: 0:15:49.
Batch 2,850  of  4,500.    Elapsed: 0:16:06.
Batch 2,900  of  4,500.    Elapsed: 0:16:23.
Batch 2,950  of  4,500.    Elapsed: 0:16:40.
Batch 3,000  of  4,500.    Elapsed: 0:16:56.
Batch 3,050  of  4,500.    Elapsed: 0:17:13.
Batch 3,100  of  4,500.    Elapsed: 0:17:29.
Batch 3,150  of  4,500.    Elapsed: 0:17:46.
Batch 3,200  of  4,500.    Elapsed: 0:18:02.
Batch 3,250  of  4,500.    Elapsed: 0:18:19.
Batch 3,300  of  4,500.    Elapsed: 0:18:35.
Batch 3,350  of  4,500.    Elapsed: 0:18:52.
Batch 3,400  of  4,500.    Elapsed: 0:19:08.
Batch 3,450  of  4,500.    Elapsed: 0:19:25.
Batch 3,500  of  4,500.    Elapsed: 0:19:41.
Batch 3,550  of  4,500.    Elapsed: 0:19:58.
Batch 3,600  of  4,500.    Elapsed: 0:20:14.
Batch 3,650  of  4,500.    Elapsed: 0:20:31.
Batch 3,700  of  4,500.    Elapsed: 0:20:47.
Batch 3,750  of  4,500.    Elapsed: 0:21:04.
Batch 3,800  of  4,500.    Elapsed: 0:21:20.
Batch 3,850  of  4,500.    Elapsed: 0:21:37.
Batch 3,900  of  4,500.    Elapsed: 0:21:53.
Batch 3,950  of  4,500.    Elapsed: 0:22:10.
Batch 4,000  of  4,500.    Elapsed: 0:22:27.
Batch 4,050  of  4,500.    Elapsed: 0:22:43.
Batch 4,100  of  4,500.    Elapsed: 0:23:00.
Batch 4,150  of  4,500.    Elapsed: 0:23:16.
Batch 4,200  of  4,500.    Elapsed: 0:23:33.
Batch 4,250  of  4,500.    Elapsed: 0:23:49.
Batch 4,300  of  4,500.    Elapsed: 0:24:06.
Batch 4,350  of  4,500.    Elapsed: 0:24:22.
Batch 4,400  of  4,500.    Elapsed: 0:24:39.
Batch 4,450  of  4,500.    Elapsed: 0:24:55.

  Average training loss: 0.52
  Training epoch took: 0:25:11

Now Validating.
  Validation Accuracy: 0.74
  Validation Loss: 0.66
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:41.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:14.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:09.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:42.
Batch 2,000  of  4,500.    Elapsed: 0:10:59.
Batch 2,050  of  4,500.    Elapsed: 0:11:15.
Batch 2,100  of  4,500.    Elapsed: 0:11:32.
Batch 2,150  of  4,500.    Elapsed: 0:11:48.
Batch 2,200  of  4,500.    Elapsed: 0:12:05.
Batch 2,250  of  4,500.    Elapsed: 0:12:21.
Batch 2,300  of  4,500.    Elapsed: 0:12:38.
Batch 2,350  of  4,500.    Elapsed: 0:12:54.
Batch 2,400  of  4,500.    Elapsed: 0:13:10.
Batch 2,450  of  4,500.    Elapsed: 0:13:27.
Batch 2,500  of  4,500.    Elapsed: 0:13:43.
Batch 2,550  of  4,500.    Elapsed: 0:14:00.
Batch 2,600  of  4,500.    Elapsed: 0:14:16.
Batch 2,650  of  4,500.    Elapsed: 0:14:33.
Batch 2,700  of  4,500.    Elapsed: 0:14:49.
Batch 2,750  of  4,500.    Elapsed: 0:15:06.
Batch 2,800  of  4,500.    Elapsed: 0:15:22.
Batch 2,850  of  4,500.    Elapsed: 0:15:38.
Batch 2,900  of  4,500.    Elapsed: 0:15:55.
Batch 2,950  of  4,500.    Elapsed: 0:16:11.
Batch 3,000  of  4,500.    Elapsed: 0:16:28.
Batch 3,050  of  4,500.    Elapsed: 0:16:44.
Batch 3,100  of  4,500.    Elapsed: 0:17:00.
Batch 3,150  of  4,500.    Elapsed: 0:17:17.
Batch 3,200  of  4,500.    Elapsed: 0:17:33.
Batch 3,250  of  4,500.    Elapsed: 0:17:50.
Batch 3,300  of  4,500.    Elapsed: 0:18:06.
Batch 3,350  of  4,500.    Elapsed: 0:18:23.
Batch 3,400  of  4,500.    Elapsed: 0:18:39.
Batch 3,450  of  4,500.    Elapsed: 0:18:55.
Batch 3,500  of  4,500.    Elapsed: 0:19:12.
Batch 3,550  of  4,500.    Elapsed: 0:19:28.
Batch 3,600  of  4,500.    Elapsed: 0:19:45.
Batch 3,650  of  4,500.    Elapsed: 0:20:01.
Batch 3,700  of  4,500.    Elapsed: 0:20:18.
Batch 3,750  of  4,500.    Elapsed: 0:20:34.
Batch 3,800  of  4,500.    Elapsed: 0:20:50.
Batch 3,850  of  4,500.    Elapsed: 0:21:07.
Batch 3,900  of  4,500.    Elapsed: 0:21:23.
Batch 3,950  of  4,500.    Elapsed: 0:21:40.
Batch 4,000  of  4,500.    Elapsed: 0:21:56.
Batch 4,050  of  4,500.    Elapsed: 0:22:12.
Batch 4,100  of  4,500.    Elapsed: 0:22:29.
Batch 4,150  of  4,500.    Elapsed: 0:22:45.
Batch 4,200  of  4,500.    Elapsed: 0:23:02.
Batch 4,250  of  4,500.    Elapsed: 0:23:18.
Batch 4,300  of  4,500.    Elapsed: 0:23:35.
Batch 4,350  of  4,500.    Elapsed: 0:23:51.
Batch 4,400  of  4,500.    Elapsed: 0:24:08.
Batch 4,450  of  4,500.    Elapsed: 0:24:24.

  Average training loss: 0.43
  Training epoch took: 0:24:41

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.69
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:49.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:44.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:17.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:50.
Batch   750  of  4,500.    Elapsed: 0:04:06.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:39.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:12.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:45.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:18.
Batch 1,200  of  4,500.    Elapsed: 0:06:34.
Batch 1,250  of  4,500.    Elapsed: 0:06:51.
Batch 1,300  of  4,500.    Elapsed: 0:07:07.
Batch 1,350  of  4,500.    Elapsed: 0:07:24.
Batch 1,400  of  4,500.    Elapsed: 0:07:40.
Batch 1,450  of  4,500.    Elapsed: 0:07:57.
Batch 1,500  of  4,500.    Elapsed: 0:08:13.
Batch 1,550  of  4,500.    Elapsed: 0:08:30.
Batch 1,600  of  4,500.    Elapsed: 0:08:46.
Batch 1,650  of  4,500.    Elapsed: 0:09:02.
Batch 1,700  of  4,500.    Elapsed: 0:09:19.
Batch 1,750  of  4,500.    Elapsed: 0:09:35.
Batch 1,800  of  4,500.    Elapsed: 0:09:52.
Batch 1,850  of  4,500.    Elapsed: 0:10:08.
Batch 1,900  of  4,500.    Elapsed: 0:10:25.
Batch 1,950  of  4,500.    Elapsed: 0:10:41.
Batch 2,000  of  4,500.    Elapsed: 0:10:57.
Batch 2,050  of  4,500.    Elapsed: 0:11:14.
Batch 2,100  of  4,500.    Elapsed: 0:11:30.
Batch 2,150  of  4,500.    Elapsed: 0:11:47.
Batch 2,200  of  4,500.    Elapsed: 0:12:03.
Batch 2,250  of  4,500.    Elapsed: 0:12:20.
Batch 2,300  of  4,500.    Elapsed: 0:12:36.
Batch 2,350  of  4,500.    Elapsed: 0:12:53.
Batch 2,400  of  4,500.    Elapsed: 0:13:09.
Batch 2,450  of  4,500.    Elapsed: 0:13:26.
Batch 2,500  of  4,500.    Elapsed: 0:13:42.
Batch 2,550  of  4,500.    Elapsed: 0:13:59.
Batch 2,600  of  4,500.    Elapsed: 0:14:15.
Batch 2,650  of  4,500.    Elapsed: 0:14:32.
Batch 2,700  of  4,500.    Elapsed: 0:14:48.
Batch 2,750  of  4,500.    Elapsed: 0:15:04.
Batch 2,800  of  4,500.    Elapsed: 0:15:21.
Batch 2,850  of  4,500.    Elapsed: 0:15:37.
Batch 2,900  of  4,500.    Elapsed: 0:15:54.
Batch 2,950  of  4,500.    Elapsed: 0:16:10.
Batch 3,000  of  4,500.    Elapsed: 0:16:27.
Batch 3,050  of  4,500.    Elapsed: 0:16:43.
Batch 3,100  of  4,500.    Elapsed: 0:17:00.
Batch 3,150  of  4,500.    Elapsed: 0:17:16.
Batch 3,200  of  4,500.    Elapsed: 0:17:32.
Batch 3,250  of  4,500.    Elapsed: 0:17:49.
Batch 3,300  of  4,500.    Elapsed: 0:18:05.
Batch 3,350  of  4,500.    Elapsed: 0:18:22.
Batch 3,400  of  4,500.    Elapsed: 0:18:38.
Batch 3,450  of  4,500.    Elapsed: 0:18:55.
Batch 3,500  of  4,500.    Elapsed: 0:19:11.
Batch 3,550  of  4,500.    Elapsed: 0:19:28.
Batch 3,600  of  4,500.    Elapsed: 0:19:44.
Batch 3,650  of  4,500.    Elapsed: 0:20:01.
Batch 3,700  of  4,500.    Elapsed: 0:20:17.
Batch 3,750  of  4,500.    Elapsed: 0:20:34.
Batch 3,800  of  4,500.    Elapsed: 0:20:50.
Batch 3,850  of  4,500.    Elapsed: 0:21:06.
Batch 3,900  of  4,500.    Elapsed: 0:21:23.
Batch 3,950  of  4,500.    Elapsed: 0:21:40.
Batch 4,000  of  4,500.    Elapsed: 0:21:56.
Batch 4,050  of  4,500.    Elapsed: 0:22:13.
Batch 4,100  of  4,500.    Elapsed: 0:22:29.
Batch 4,150  of  4,500.    Elapsed: 0:22:46.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:43:28 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7571
INFO: Training took 1:44:30 (h:mm:ss)
INFO: Total duration: 106.45 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:02.
Batch 4,250  of  4,500.    Elapsed: 0:23:19.
Batch 4,300  of  4,500.    Elapsed: 0:23:35.
Batch 4,350  of  4,500.    Elapsed: 0:23:52.
Batch 4,400  of  4,500.    Elapsed: 0:24:08.
Batch 4,450  of  4,500.    Elapsed: 0:24:25.

  Average training loss: 0.36
  Training epoch took: 0:24:41

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.98
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 8/9.
INFO: Learning rate: 5e-05.
INFO: Split number: 2.
2020-08-28 04:54:21.339970: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 04:54:21.340008: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:25.
Batch   100  of  4,500.    Elapsed: 0:00:41.
Batch   150  of  4,500.    Elapsed: 0:00:57.
Batch   200  of  4,500.    Elapsed: 0:01:13.
Batch   250  of  4,500.    Elapsed: 0:01:30.
Batch   300  of  4,500.    Elapsed: 0:01:46.
Batch   350  of  4,500.    Elapsed: 0:02:03.
Batch   400  of  4,500.    Elapsed: 0:02:19.
Batch   450  of  4,500.    Elapsed: 0:02:35.
Batch   500  of  4,500.    Elapsed: 0:02:52.
Batch   550  of  4,500.    Elapsed: 0:03:08.
Batch   600  of  4,500.    Elapsed: 0:03:25.
Batch   650  of  4,500.    Elapsed: 0:03:41.
Batch   700  of  4,500.    Elapsed: 0:03:58.
Batch   750  of  4,500.    Elapsed: 0:04:14.
Batch   800  of  4,500.    Elapsed: 0:04:31.
Batch   850  of  4,500.    Elapsed: 0:04:47.
Batch   900  of  4,500.    Elapsed: 0:05:04.
Batch   950  of  4,500.    Elapsed: 0:05:20.
Batch 1,000  of  4,500.    Elapsed: 0:05:37.
Batch 1,050  of  4,500.    Elapsed: 0:05:53.
Batch 1,100  of  4,500.    Elapsed: 0:06:10.
Batch 1,150  of  4,500.    Elapsed: 0:06:26.
Batch 1,200  of  4,500.    Elapsed: 0:06:43.
Batch 1,250  of  4,500.    Elapsed: 0:06:59.
Batch 1,300  of  4,500.    Elapsed: 0:07:16.
Batch 1,350  of  4,500.    Elapsed: 0:07:32.
Batch 1,400  of  4,500.    Elapsed: 0:07:49.
Batch 1,450  of  4,500.    Elapsed: 0:08:05.
Batch 1,500  of  4,500.    Elapsed: 0:08:22.
Batch 1,550  of  4,500.    Elapsed: 0:08:38.
Batch 1,600  of  4,500.    Elapsed: 0:08:55.
Batch 1,650  of  4,500.    Elapsed: 0:09:11.
Batch 1,700  of  4,500.    Elapsed: 0:09:28.
Batch 1,750  of  4,500.    Elapsed: 0:09:44.
Batch 1,800  of  4,500.    Elapsed: 0:10:00.
Batch 1,850  of  4,500.    Elapsed: 0:10:17.
Batch 1,900  of  4,500.    Elapsed: 0:10:33.
Batch 1,950  of  4,500.    Elapsed: 0:10:50.
Batch 2,000  of  4,500.    Elapsed: 0:11:06.
Batch 2,050  of  4,500.    Elapsed: 0:11:22.
Batch 2,100  of  4,500.    Elapsed: 0:11:39.
Batch 2,150  of  4,500.    Elapsed: 0:11:55.
Batch 2,200  of  4,500.    Elapsed: 0:12:12.
Batch 2,250  of  4,500.    Elapsed: 0:12:28.
Batch 2,300  of  4,500.    Elapsed: 0:12:45.
Batch 2,350  of  4,500.    Elapsed: 0:13:02.
Batch 2,400  of  4,500.    Elapsed: 0:13:19.
Batch 2,450  of  4,500.    Elapsed: 0:13:36.
Batch 2,500  of  4,500.    Elapsed: 0:13:53.
Batch 2,550  of  4,500.    Elapsed: 0:14:09.
Batch 2,600  of  4,500.    Elapsed: 0:14:26.
Batch 2,650  of  4,500.    Elapsed: 0:14:43.
Batch 2,700  of  4,500.    Elapsed: 0:15:00.
Batch 2,750  of  4,500.    Elapsed: 0:15:17.
Batch 2,800  of  4,500.    Elapsed: 0:15:34.
Batch 2,850  of  4,500.    Elapsed: 0:15:51.
Batch 2,900  of  4,500.    Elapsed: 0:16:07.
Batch 2,950  of  4,500.    Elapsed: 0:16:24.
Batch 3,000  of  4,500.    Elapsed: 0:16:41.
Batch 3,050  of  4,500.    Elapsed: 0:16:58.
Batch 3,100  of  4,500.    Elapsed: 0:17:15.
Batch 3,150  of  4,500.    Elapsed: 0:17:32.
Batch 3,200  of  4,500.    Elapsed: 0:17:48.
Batch 3,250  of  4,500.    Elapsed: 0:18:05.
Batch 3,300  of  4,500.    Elapsed: 0:18:22.
Batch 3,350  of  4,500.    Elapsed: 0:18:39.
Batch 3,400  of  4,500.    Elapsed: 0:18:56.
Batch 3,450  of  4,500.    Elapsed: 0:19:13.
Batch 3,500  of  4,500.    Elapsed: 0:19:30.
Batch 3,550  of  4,500.    Elapsed: 0:19:46.
Batch 3,600  of  4,500.    Elapsed: 0:20:03.
Batch 3,650  of  4,500.    Elapsed: 0:20:20.
Batch 3,700  of  4,500.    Elapsed: 0:20:37.
Batch 3,750  of  4,500.    Elapsed: 0:20:54.
Batch 3,800  of  4,500.    Elapsed: 0:21:11.
Batch 3,850  of  4,500.    Elapsed: 0:21:27.
Batch 3,900  of  4,500.    Elapsed: 0:21:44.
Batch 3,950  of  4,500.    Elapsed: 0:22:01.
Batch 4,000  of  4,500.    Elapsed: 0:22:18.
Batch 4,050  of  4,500.    Elapsed: 0:22:34.
Batch 4,100  of  4,500.    Elapsed: 0:22:51.
Batch 4,150  of  4,500.    Elapsed: 0:23:07.
Batch 4,200  of  4,500.    Elapsed: 0:23:24.
Batch 4,250  of  4,500.    Elapsed: 0:23:40.
Batch 4,300  of  4,500.    Elapsed: 0:23:56.
Batch 4,350  of  4,500.    Elapsed: 0:24:13.
Batch 4,400  of  4,500.    Elapsed: 0:24:29.
Batch 4,450  of  4,500.    Elapsed: 0:24:46.

  Average training loss: 0.67
  Training epoch took: 0:25:02

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.59
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:17.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:50.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:35.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:26.
Batch 1,400  of  4,500.    Elapsed: 0:07:43.
Batch 1,450  of  4,500.    Elapsed: 0:08:00.
Batch 1,500  of  4,500.    Elapsed: 0:08:17.
Batch 1,550  of  4,500.    Elapsed: 0:08:34.
Batch 1,600  of  4,500.    Elapsed: 0:08:51.
Batch 1,650  of  4,500.    Elapsed: 0:09:07.
Batch 1,700  of  4,500.    Elapsed: 0:09:24.
Batch 1,750  of  4,500.    Elapsed: 0:09:41.
Batch 1,800  of  4,500.    Elapsed: 0:09:58.
Batch 1,850  of  4,500.    Elapsed: 0:10:15.
Batch 1,900  of  4,500.    Elapsed: 0:10:32.
Batch 1,950  of  4,500.    Elapsed: 0:10:49.
Batch 2,000  of  4,500.    Elapsed: 0:11:05.
Batch 2,050  of  4,500.    Elapsed: 0:11:22.
Batch 2,100  of  4,500.    Elapsed: 0:11:39.
Batch 2,150  of  4,500.    Elapsed: 0:11:56.
Batch 2,200  of  4,500.    Elapsed: 0:12:13.
Batch 2,250  of  4,500.    Elapsed: 0:12:30.
Batch 2,300  of  4,500.    Elapsed: 0:12:47.
Batch 2,350  of  4,500.    Elapsed: 0:13:03.
Batch 2,400  of  4,500.    Elapsed: 0:13:20.
Batch 2,450  of  4,500.    Elapsed: 0:13:37.
Batch 2,500  of  4,500.    Elapsed: 0:13:54.
Batch 2,550  of  4,500.    Elapsed: 0:14:11.
Batch 2,600  of  4,500.    Elapsed: 0:14:28.
Batch 2,650  of  4,500.    Elapsed: 0:14:45.
Batch 2,700  of  4,500.    Elapsed: 0:15:01.
Batch 2,750  of  4,500.    Elapsed: 0:15:18.
Batch 2,800  of  4,500.    Elapsed: 0:15:35.
Batch 2,850  of  4,500.    Elapsed: 0:15:52.
Batch 2,900  of  4,500.    Elapsed: 0:16:09.
Batch 2,950  of  4,500.    Elapsed: 0:16:26.
Batch 3,000  of  4,500.    Elapsed: 0:16:42.
Batch 3,050  of  4,500.    Elapsed: 0:16:59.
Batch 3,100  of  4,500.    Elapsed: 0:17:15.
Batch 3,150  of  4,500.    Elapsed: 0:17:32.
Batch 3,200  of  4,500.    Elapsed: 0:17:48.
Batch 3,250  of  4,500.    Elapsed: 0:18:05.
Batch 3,300  of  4,500.    Elapsed: 0:18:21.
Batch 3,350  of  4,500.    Elapsed: 0:18:38.
Batch 3,400  of  4,500.    Elapsed: 0:18:54.
Batch 3,450  of  4,500.    Elapsed: 0:19:11.
Batch 3,500  of  4,500.    Elapsed: 0:19:27.
Batch 3,550  of  4,500.    Elapsed: 0:19:44.
Batch 3,600  of  4,500.    Elapsed: 0:20:00.
Batch 3,650  of  4,500.    Elapsed: 0:20:17.
Batch 3,700  of  4,500.    Elapsed: 0:20:33.
Batch 3,750  of  4,500.    Elapsed: 0:20:50.
Batch 3,800  of  4,500.    Elapsed: 0:21:06.
Batch 3,850  of  4,500.    Elapsed: 0:21:23.
Batch 3,900  of  4,500.    Elapsed: 0:21:39.
Batch 3,950  of  4,500.    Elapsed: 0:21:56.
Batch 4,000  of  4,500.    Elapsed: 0:22:12.
Batch 4,050  of  4,500.    Elapsed: 0:22:29.
Batch 4,100  of  4,500.    Elapsed: 0:22:45.
Batch 4,150  of  4,500.    Elapsed: 0:23:02.
Batch 4,200  of  4,500.    Elapsed: 0:23:18.
Batch 4,250  of  4,500.    Elapsed: 0:23:35.
Batch 4,300  of  4,500.    Elapsed: 0:23:51.
Batch 4,350  of  4,500.    Elapsed: 0:24:08.
Batch 4,400  of  4,500.    Elapsed: 0:24:24.
Batch 4,450  of  4,500.    Elapsed: 0:24:41.

  Average training loss: 0.54
  Training epoch took: 0:24:57

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.64
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:04.
Batch 1,150  of  4,500.    Elapsed: 0:06:21.
Batch 1,200  of  4,500.    Elapsed: 0:06:38.
Batch 1,250  of  4,500.    Elapsed: 0:06:55.
Batch 1,300  of  4,500.    Elapsed: 0:07:12.
Batch 1,350  of  4,500.    Elapsed: 0:07:29.
Batch 1,400  of  4,500.    Elapsed: 0:07:46.
Batch 1,450  of  4,500.    Elapsed: 0:08:02.
Batch 1,500  of  4,500.    Elapsed: 0:08:19.
Batch 1,550  of  4,500.    Elapsed: 0:08:35.
Batch 1,600  of  4,500.    Elapsed: 0:08:52.
Batch 1,650  of  4,500.    Elapsed: 0:09:08.
Batch 1,700  of  4,500.    Elapsed: 0:09:25.
Batch 1,750  of  4,500.    Elapsed: 0:09:41.
Batch 1,800  of  4,500.    Elapsed: 0:09:58.
Batch 1,850  of  4,500.    Elapsed: 0:10:14.
Batch 1,900  of  4,500.    Elapsed: 0:10:31.
Batch 1,950  of  4,500.    Elapsed: 0:10:48.
Batch 2,000  of  4,500.    Elapsed: 0:11:05.
Batch 2,050  of  4,500.    Elapsed: 0:11:22.
Batch 2,100  of  4,500.    Elapsed: 0:11:38.
Batch 2,150  of  4,500.    Elapsed: 0:11:55.
Batch 2,200  of  4,500.    Elapsed: 0:12:12.
Batch 2,250  of  4,500.    Elapsed: 0:12:29.
Batch 2,300  of  4,500.    Elapsed: 0:12:46.
Batch 2,350  of  4,500.    Elapsed: 0:13:03.
Batch 2,400  of  4,500.    Elapsed: 0:13:20.
Batch 2,450  of  4,500.    Elapsed: 0:13:37.
Batch 2,500  of  4,500.    Elapsed: 0:13:54.
Batch 2,550  of  4,500.    Elapsed: 0:14:10.
Batch 2,600  of  4,500.    Elapsed: 0:14:27.
Batch 2,650  of  4,500.    Elapsed: 0:14:44.
Batch 2,700  of  4,500.    Elapsed: 0:15:01.
Batch 2,750  of  4,500.    Elapsed: 0:15:18.
Batch 2,800  of  4,500.    Elapsed: 0:15:35.
Batch 2,850  of  4,500.    Elapsed: 0:15:52.
Batch 2,900  of  4,500.    Elapsed: 0:16:09.
Batch 2,950  of  4,500.    Elapsed: 0:16:26.
Batch 3,000  of  4,500.    Elapsed: 0:16:43.
Batch 3,050  of  4,500.    Elapsed: 0:17:00.
Batch 3,100  of  4,500.    Elapsed: 0:17:16.
Batch 3,150  of  4,500.    Elapsed: 0:17:32.
Batch 3,200  of  4,500.    Elapsed: 0:17:49.
Batch 3,250  of  4,500.    Elapsed: 0:18:05.
Batch 3,300  of  4,500.    Elapsed: 0:18:22.
Batch 3,350  of  4,500.    Elapsed: 0:18:38.
Batch 3,400  of  4,500.    Elapsed: 0:18:55.
Batch 3,450  of  4,500.    Elapsed: 0:19:11.
Batch 3,500  of  4,500.    Elapsed: 0:19:27.
Batch 3,550  of  4,500.    Elapsed: 0:19:44.
Batch 3,600  of  4,500.    Elapsed: 0:20:00.
Batch 3,650  of  4,500.    Elapsed: 0:20:17.
Batch 3,700  of  4,500.    Elapsed: 0:20:33.
Batch 3,750  of  4,500.    Elapsed: 0:20:49.
Batch 3,800  of  4,500.    Elapsed: 0:21:06.
Batch 3,850  of  4,500.    Elapsed: 0:21:22.
Batch 3,900  of  4,500.    Elapsed: 0:21:39.
Batch 3,950  of  4,500.    Elapsed: 0:21:55.
Batch 4,000  of  4,500.    Elapsed: 0:22:12.
Batch 4,050  of  4,500.    Elapsed: 0:22:28.
Batch 4,100  of  4,500.    Elapsed: 0:22:45.
Batch 4,150  of  4,500.    Elapsed: 0:23:01.
Batch 4,200  of  4,500.    Elapsed: 0:23:18.
Batch 4,250  of  4,500.    Elapsed: 0:23:34.
Batch 4,300  of  4,500.    Elapsed: 0:23:51.
Batch 4,350  of  4,500.    Elapsed: 0:24:07.
Batch 4,400  of  4,500.    Elapsed: 0:24:24.
Batch 4,450  of  4,500.    Elapsed: 0:24:40.

  Average training loss: 0.46
  Training epoch took: 0:24:57

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.77
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:35.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:08.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:41.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:14.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:10:59.
Batch 2,050  of  4,500.    Elapsed: 0:11:16.
Batch 2,100  of  4,500.    Elapsed: 0:11:32.
Batch 2,150  of  4,500.    Elapsed: 0:11:49.
Batch 2,200  of  4,500.    Elapsed: 0:12:05.
Batch 2,250  of  4,500.    Elapsed: 0:12:22.
Batch 2,300  of  4,500.    Elapsed: 0:12:38.
Batch 2,350  of  4,500.    Elapsed: 0:12:55.
Batch 2,400  of  4,500.    Elapsed: 0:13:11.
Batch 2,450  of  4,500.    Elapsed: 0:13:28.
Batch 2,500  of  4,500.    Elapsed: 0:13:45.
Batch 2,550  of  4,500.    Elapsed: 0:14:01.
Batch 2,600  of  4,500.    Elapsed: 0:14:18.
Batch 2,650  of  4,500.    Elapsed: 0:14:35.
Batch 2,700  of  4,500.    Elapsed: 0:14:51.
Batch 2,750  of  4,500.    Elapsed: 0:15:07.
Batch 2,800  of  4,500.    Elapsed: 0:15:24.
Batch 2,850  of  4,500.    Elapsed: 0:15:40.
Batch 2,900  of  4,500.    Elapsed: 0:15:57.
Batch 2,950  of  4,500.    Elapsed: 0:16:13.
Batch 3,000  of  4,500.    Elapsed: 0:16:29.
Batch 3,050  of  4,500.    Elapsed: 0:16:46.
Batch 3,100  of  4,500.    Elapsed: 0:17:02.
Batch 3,150  of  4,500.    Elapsed: 0:17:19.
Batch 3,200  of  4,500.    Elapsed: 0:17:35.
Batch 3,250  of  4,500.    Elapsed: 0:17:52.
Batch 3,300  of  4,500.    Elapsed: 0:18:08.
Batch 3,350  of  4,500.    Elapsed: 0:18:24.
Batch 3,400  of  4,500.    Elapsed: 0:18:41.
Batch 3,450  of  4,500.    Elapsed: 0:18:57.
Batch 3,500  of  4,500.    Elapsed: 0:19:14.
Batch 3,550  of  4,500.    Elapsed: 0:19:30.
Batch 3,600  of  4,500.    Elapsed: 0:19:47.
Batch 3,650  of  4,500.    Elapsed: 0:20:03.
Batch 3,700  of  4,500.    Elapsed: 0:20:20.
Batch 3,750  of  4,500.    Elapsed: 0:20:36.
Batch 3,800  of  4,500.    Elapsed: 0:20:53.
Batch 3,850  of  4,500.    Elapsed: 0:21:09.
Batch 3,900  of  4,500.    Elapsed: 0:21:25.
Batch 3,950  of  4,500.    Elapsed: 0:21:42.
Batch 4,000  of  4,500.    Elapsed: 0:21:58.
Batch 4,050  of  4,500.    Elapsed: 0:22:15.
Batch 4,100  of  4,500.    Elapsed: 0:22:31.
Batch 4,150  of  4,500.    Elapsed: 0:22:48.
Batch 4,200  of  4,500.    Elapsed: 0:23:04.
Batch 4,250  of  4,500.    Elapsed: 0:23:21.
Batch 4,300  of  4,500.    Elapsed: 0:23:37.
Batch 4,350  of  4,500.    Elapsed: 0:23:54.
Batch 4,400  of  4,500.    Elapsed: 0:24:10.
Batch 4,450  of  4,500.    Elapsed: 0:24:27.

  Average training loss: 0.39
  Training epoch took: 0:24:43

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 0.76
  Validation took: 0:00:58

======== Epoch 5 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:49.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:35.
Batch 1,250  of  4,500.    Elapsed: 0:06:51.
Batch 1,300  of  4,500.    Elapsed: 0:07:08.
Batch 1,350  of  4,500.    Elapsed: 0:07:24.
Batch 1,400  of  4,500.    Elapsed: 0:07:41.
Batch 1,450  of  4,500.    Elapsed: 0:07:57.
Batch 1,500  of  4,500.    Elapsed: 0:08:14.
Batch 1,550  of  4,500.    Elapsed: 0:08:30.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:03.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:36.
Batch 1,800  of  4,500.    Elapsed: 0:09:52.
Batch 1,850  of  4,500.    Elapsed: 0:10:09.
Batch 1,900  of  4,500.    Elapsed: 0:10:25.
Batch 1,950  of  4,500.    Elapsed: 0:10:41.
Batch 2,000  of  4,500.    Elapsed: 0:10:58.
Batch 2,050  of  4,500.    Elapsed: 0:11:14.
Batch 2,100  of  4,500.    Elapsed: 0:11:30.
Batch 2,150  of  4,500.    Elapsed: 0:11:47.
Batch 2,200  of  4,500.    Elapsed: 0:12:03.
Batch 2,250  of  4,500.    Elapsed: 0:12:19.
Batch 2,300  of  4,500.    Elapsed: 0:12:36.
Batch 2,350  of  4,500.    Elapsed: 0:12:52.
Batch 2,400  of  4,500.    Elapsed: 0:13:09.
Batch 2,450  of  4,500.    Elapsed: 0:13:25.
Batch 2,500  of  4,500.    Elapsed: 0:13:41.
Batch 2,550  of  4,500.    Elapsed: 0:13:57.
Batch 2,600  of  4,500.    Elapsed: 0:14:13.
Batch 2,650  of  4,500.    Elapsed: 0:14:29.
Batch 2,700  of  4,500.    Elapsed: 0:14:44.
Batch 2,750  of  4,500.    Elapsed: 0:15:00.
Batch 2,800  of  4,500.    Elapsed: 0:15:16.
Batch 2,850  of  4,500.    Elapsed: 0:15:31.
Batch 2,900  of  4,500.    Elapsed: 0:15:47.
Batch 2,950  of  4,500.    Elapsed: 0:16:03.
Batch 3,000  of  4,500.    Elapsed: 0:16:18.
Batch 3,050  of  4,500.    Elapsed: 0:16:34.
Batch 3,100  of  4,500.    Elapsed: 0:16:50.
Batch 3,150  of  4,500.    Elapsed: 0:17:06.
Batch 3,200  of  4,500.    Elapsed: 0:17:21.
Batch 3,250  of  4,500.    Elapsed: 0:17:37.
Batch 3,300  of  4,500.    Elapsed: 0:17:53.
Batch 3,350  of  4,500.    Elapsed: 0:18:08.
Batch 3,400  of  4,500.    Elapsed: 0:18:24.
Batch 3,450  of  4,500.    Elapsed: 0:18:40.
Batch 3,500  of  4,500.    Elapsed: 0:18:56.
Batch 3,550  of  4,500.    Elapsed: 0:19:12.
Batch 3,600  of  4,500.    Elapsed: 0:19:29.
Batch 3,650  of  4,500.    Elapsed: 0:19:45.
Batch 3,700  of  4,500.    Elapsed: 0:20:01.
Batch 3,750  of  4,500.    Elapsed: 0:20:18.
Batch 3,800  of  4,500.    Elapsed: 0:20:34.
Batch 3,850  of  4,500.    Elapsed: 0:20:51.
Batch 3,900  of  4,500.    Elapsed: 0:21:07.
Batch 3,950  of  4,500.    Elapsed: 0:21:23.
Batch 4,000  of  4,500.    Elapsed: 0:21:40.
Batch 4,050  of  4,500.    Elapsed: 0:21:56.
Batch 4,100  of  4,500.    Elapsed: 0:22:12.
Batch 4,150  of  4,500.    Elapsed: 0:22:29.
Batch 4,200  of  4,500.    Elapsed: 0:22:45.
Batch 4,250  of  4,500.    Elapsed: 0:23:02.
Batch 4,300  of  4,500.    Elapsed: 0:23:18.
Batch 4,350  of  4,500.    Elapsed: 0:23:34.
Batch 4,400  of  4,500.    Elapsed: 0:23:51.
Batch 4,450  of  4,500.    Elapsed: 0:24:07.

  Average training loss: 0.32
  Training epoch took: 0:24:23

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 1.08
  Validation took: 0:00:58

======== Epoch 6 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:49.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:38.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:11.
Batch   450  of  4,500.    Elapsed: 0:02:27.
Batch   500  of  4,500.    Elapsed: 0:02:44.
Batch   550  of  4,500.    Elapsed: 0:03:00.
Batch   600  of  4,500.    Elapsed: 0:03:17.
Batch   650  of  4,500.    Elapsed: 0:03:33.
Batch   700  of  4,500.    Elapsed: 0:03:50.
Batch   750  of  4,500.    Elapsed: 0:04:06.
Batch   800  of  4,500.    Elapsed: 0:04:22.
Batch   850  of  4,500.    Elapsed: 0:04:39.
Batch   900  of  4,500.    Elapsed: 0:04:55.
Batch   950  of  4,500.    Elapsed: 0:05:12.
Batch 1,000  of  4,500.    Elapsed: 0:05:28.
Batch 1,050  of  4,500.    Elapsed: 0:05:45.
Batch 1,100  of  4,500.    Elapsed: 0:06:01.
Batch 1,150  of  4,500.    Elapsed: 0:06:18.
Batch 1,200  of  4,500.    Elapsed: 0:06:34.
Batch 1,250  of  4,500.    Elapsed: 0:06:50.
Batch 1,300  of  4,500.    Elapsed: 0:07:07.
Batch 1,350  of  4,500.    Elapsed: 0:07:23.
Batch 1,400  of  4,500.    Elapsed: 0:07:40.
Batch 1,450  of  4,500.    Elapsed: 0:07:56.
Batch 1,500  of  4,500.    Elapsed: 0:08:12.
Batch 1,550  of  4,500.    Elapsed: 0:08:29.
Batch 1,600  of  4,500.    Elapsed: 0:08:46.
Batch 1,650  of  4,500.    Elapsed: 0:09:02.
Batch 1,700  of  4,500.    Elapsed: 0:09:19.
Batch 1,750  of  4,500.    Elapsed: 0:09:36.
Batch 1,800  of  4,500.    Elapsed: 0:09:53.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:26.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:11:00.
Batch 2,050  of  4,500.    Elapsed: 0:11:17.
Batch 2,100  of  4,500.    Elapsed: 0:11:34.
Batch 2,150  of  4,500.    Elapsed: 0:11:51.
Batch 2,200  of  4,500.    Elapsed: 0:12:07.
Batch 2,250  of  4,500.    Elapsed: 0:12:24.
Batch 2,300  of  4,500.    Elapsed: 0:12:41.
Batch 2,350  of  4,500.    Elapsed: 0:12:58.
Batch 2,400  of  4,500.    Elapsed: 0:13:15.
Batch 2,450  of  4,500.    Elapsed: 0:13:31.
Batch 2,500  of  4,500.    Elapsed: 0:13:48.
Batch 2,550  of  4,500.    Elapsed: 0:14:05.
Batch 2,600  of  4,500.    Elapsed: 0:14:22.
Batch 2,650  of  4,500.    Elapsed: 0:14:39.
Batch 2,700  of  4,500.    Elapsed: 0:14:55.
Batch 2,750  of  4,500.    Elapsed: 0:15:12.
Batch 2,800  of  4,500.    Elapsed: 0:15:29.
Batch 2,850  of  4,500.    Elapsed: 0:15:46.
Batch 2,900  of  4,500.    Elapsed: 0:16:02.
Batch 2,950  of  4,500.    Elapsed: 0:16:19.
Batch 3,000  of  4,500.    Elapsed: 0:16:36.
Batch 3,050  of  4,500.    Elapsed: 0:16:53.
Batch 3,100  of  4,500.    Elapsed: 0:17:10.
Batch 3,150  of  4,500.    Elapsed: 0:17:27.
Batch 3,200  of  4,500.    Elapsed: 0:17:43.
Batch 3,250  of  4,500.    Elapsed: 0:18:00.
Batch 3,300  of  4,500.    Elapsed: 0:18:17.
Batch 3,350  of  4,500.    Elapsed: 0:18:34.
Batch 3,400  of  4,500.    Elapsed: 0:18:50.
Batch 3,450  of  4,500.    Elapsed: 0:19:06.
Batch 3,500  of  4,500.    Elapsed: 0:19:23.
Batch 3,550  of  4,500.    Elapsed: 0:19:39.
Batch 3,600  of  4,500.    Elapsed: 0:19:55.
Batch 3,650  of  4,500.    Elapsed: 0:20:12.
Batch 3,700  of  4,500.    Elapsed: 0:20:28.
Batch 3,750  of  4,500.    Elapsed: 0:20:45.
Batch 3,800  of  4,500.    Elapsed: 0:21:01.
Batch 3,850  of  4,500.    Elapsed: 0:21:17.
Batch 3,900  of  4,500.    Elapsed: 0:21:34.INFO: 
Stopping epoch run early (Epoch 5).
INFO: Training took 2:34:42 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7504
INFO: Training took 2:35:44 (h:mm:ss)
INFO: Total duration: 157.9 minute(s).

Batch 3,950  of  4,500.    Elapsed: 0:21:50.
Batch 4,000  of  4,500.    Elapsed: 0:22:07.
Batch 4,050  of  4,500.    Elapsed: 0:22:23.
Batch 4,100  of  4,500.    Elapsed: 0:22:40.
Batch 4,150  of  4,500.    Elapsed: 0:22:56.
Batch 4,200  of  4,500.    Elapsed: 0:23:12.
Batch 4,250  of  4,500.    Elapsed: 0:23:29.
Batch 4,300  of  4,500.    Elapsed: 0:23:45.
Batch 4,350  of  4,500.    Elapsed: 0:24:01.
Batch 4,400  of  4,500.    Elapsed: 0:24:18.
Batch 4,450  of  4,500.    Elapsed: 0:24:34.

  Average training loss: 0.25
  Training epoch took: 0:24:50

Now Validating.
  Validation Accuracy: 0.76
  Validation Loss: 1.21
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Argument combination 9/9.
INFO: Learning rate: 5e-05.
INFO: Split number: 3.
2020-08-28 07:32:22.130647: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-28 07:32:22.130703: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
INFO: There are 1 GPU(s) available.
INFO: Used GPU: GeForce RTX 2080 Ti
INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/paulus/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/paulus/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
INFO: Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO: loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/paulus/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
WARNING: Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING: Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

======== Epoch 1 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:23.
Batch   100  of  4,500.    Elapsed: 0:00:39.
Batch   150  of  4,500.    Elapsed: 0:00:55.
Batch   200  of  4,500.    Elapsed: 0:01:12.
Batch   250  of  4,500.    Elapsed: 0:01:28.
Batch   300  of  4,500.    Elapsed: 0:01:44.
Batch   350  of  4,500.    Elapsed: 0:02:01.
Batch   400  of  4,500.    Elapsed: 0:02:17.
Batch   450  of  4,500.    Elapsed: 0:02:34.
Batch   500  of  4,500.    Elapsed: 0:02:50.
Batch   550  of  4,500.    Elapsed: 0:03:07.
Batch   600  of  4,500.    Elapsed: 0:03:23.
Batch   650  of  4,500.    Elapsed: 0:03:40.
Batch   700  of  4,500.    Elapsed: 0:03:56.
Batch   750  of  4,500.    Elapsed: 0:04:13.
Batch   800  of  4,500.    Elapsed: 0:04:29.
Batch   850  of  4,500.    Elapsed: 0:04:46.
Batch   900  of  4,500.    Elapsed: 0:05:02.
Batch   950  of  4,500.    Elapsed: 0:05:19.
Batch 1,000  of  4,500.    Elapsed: 0:05:35.
Batch 1,050  of  4,500.    Elapsed: 0:05:52.
Batch 1,100  of  4,500.    Elapsed: 0:06:08.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:57.
Batch 1,300  of  4,500.    Elapsed: 0:07:14.
Batch 1,350  of  4,500.    Elapsed: 0:07:30.
Batch 1,400  of  4,500.    Elapsed: 0:07:47.
Batch 1,450  of  4,500.    Elapsed: 0:08:03.
Batch 1,500  of  4,500.    Elapsed: 0:08:20.
Batch 1,550  of  4,500.    Elapsed: 0:08:36.
Batch 1,600  of  4,500.    Elapsed: 0:08:53.
Batch 1,650  of  4,500.    Elapsed: 0:09:09.
Batch 1,700  of  4,500.    Elapsed: 0:09:25.
Batch 1,750  of  4,500.    Elapsed: 0:09:42.
Batch 1,800  of  4,500.    Elapsed: 0:09:58.
Batch 1,850  of  4,500.    Elapsed: 0:10:15.
Batch 1,900  of  4,500.    Elapsed: 0:10:31.
Batch 1,950  of  4,500.    Elapsed: 0:10:48.
Batch 2,000  of  4,500.    Elapsed: 0:11:04.
Batch 2,050  of  4,500.    Elapsed: 0:11:21.
Batch 2,100  of  4,500.    Elapsed: 0:11:37.
Batch 2,150  of  4,500.    Elapsed: 0:11:54.
Batch 2,200  of  4,500.    Elapsed: 0:12:10.
Batch 2,250  of  4,500.    Elapsed: 0:12:27.
Batch 2,300  of  4,500.    Elapsed: 0:12:43.
Batch 2,350  of  4,500.    Elapsed: 0:13:00.
Batch 2,400  of  4,500.    Elapsed: 0:13:16.
Batch 2,450  of  4,500.    Elapsed: 0:13:33.
Batch 2,500  of  4,500.    Elapsed: 0:13:49.
Batch 2,550  of  4,500.    Elapsed: 0:14:06.
Batch 2,600  of  4,500.    Elapsed: 0:14:23.
Batch 2,650  of  4,500.    Elapsed: 0:14:39.
Batch 2,700  of  4,500.    Elapsed: 0:14:56.
Batch 2,750  of  4,500.    Elapsed: 0:15:12.
Batch 2,800  of  4,500.    Elapsed: 0:15:29.
Batch 2,850  of  4,500.    Elapsed: 0:15:45.
Batch 2,900  of  4,500.    Elapsed: 0:16:02.
Batch 2,950  of  4,500.    Elapsed: 0:16:18.
Batch 3,000  of  4,500.    Elapsed: 0:16:35.
Batch 3,050  of  4,500.    Elapsed: 0:16:51.
Batch 3,100  of  4,500.    Elapsed: 0:17:08.
Batch 3,150  of  4,500.    Elapsed: 0:17:24.
Batch 3,200  of  4,500.    Elapsed: 0:17:41.
Batch 3,250  of  4,500.    Elapsed: 0:17:57.
Batch 3,300  of  4,500.    Elapsed: 0:18:14.
Batch 3,350  of  4,500.    Elapsed: 0:18:30.
Batch 3,400  of  4,500.    Elapsed: 0:18:47.
Batch 3,450  of  4,500.    Elapsed: 0:19:03.
Batch 3,500  of  4,500.    Elapsed: 0:19:20.
Batch 3,550  of  4,500.    Elapsed: 0:19:36.
Batch 3,600  of  4,500.    Elapsed: 0:19:53.
Batch 3,650  of  4,500.    Elapsed: 0:20:09.
Batch 3,700  of  4,500.    Elapsed: 0:20:26.
Batch 3,750  of  4,500.    Elapsed: 0:20:42.
Batch 3,800  of  4,500.    Elapsed: 0:20:59.
Batch 3,850  of  4,500.    Elapsed: 0:21:15.
Batch 3,900  of  4,500.    Elapsed: 0:21:32.
Batch 3,950  of  4,500.    Elapsed: 0:21:48.
Batch 4,000  of  4,500.    Elapsed: 0:22:05.
Batch 4,050  of  4,500.    Elapsed: 0:22:21.
Batch 4,100  of  4,500.    Elapsed: 0:22:38.
Batch 4,150  of  4,500.    Elapsed: 0:22:54.
Batch 4,200  of  4,500.    Elapsed: 0:23:11.
Batch 4,250  of  4,500.    Elapsed: 0:23:27.
Batch 4,300  of  4,500.    Elapsed: 0:23:44.
Batch 4,350  of  4,500.    Elapsed: 0:24:00.
Batch 4,400  of  4,500.    Elapsed: 0:24:17.
Batch 4,450  of  4,500.    Elapsed: 0:24:33.

  Average training loss: 0.66
  Training epoch took: 0:24:50

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.62
  Validation took: 0:00:58

======== Epoch 2 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:08.
Batch   800  of  4,500.    Elapsed: 0:04:24.
Batch   850  of  4,500.    Elapsed: 0:04:41.
Batch   900  of  4,500.    Elapsed: 0:04:57.
Batch   950  of  4,500.    Elapsed: 0:05:14.
Batch 1,000  of  4,500.    Elapsed: 0:05:30.
Batch 1,050  of  4,500.    Elapsed: 0:05:47.
Batch 1,100  of  4,500.    Elapsed: 0:06:03.
Batch 1,150  of  4,500.    Elapsed: 0:06:20.
Batch 1,200  of  4,500.    Elapsed: 0:06:36.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:09.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:42.
Batch 1,450  of  4,500.    Elapsed: 0:07:58.
Batch 1,500  of  4,500.    Elapsed: 0:08:15.
Batch 1,550  of  4,500.    Elapsed: 0:08:31.
Batch 1,600  of  4,500.    Elapsed: 0:08:48.
Batch 1,650  of  4,500.    Elapsed: 0:09:04.
Batch 1,700  of  4,500.    Elapsed: 0:09:21.
Batch 1,750  of  4,500.    Elapsed: 0:09:37.
Batch 1,800  of  4,500.    Elapsed: 0:09:54.
Batch 1,850  of  4,500.    Elapsed: 0:10:10.
Batch 1,900  of  4,500.    Elapsed: 0:10:27.
Batch 1,950  of  4,500.    Elapsed: 0:10:43.
Batch 2,000  of  4,500.    Elapsed: 0:11:00.
Batch 2,050  of  4,500.    Elapsed: 0:11:16.
Batch 2,100  of  4,500.    Elapsed: 0:11:33.
Batch 2,150  of  4,500.    Elapsed: 0:11:49.
Batch 2,200  of  4,500.    Elapsed: 0:12:06.
Batch 2,250  of  4,500.    Elapsed: 0:12:22.
Batch 2,300  of  4,500.    Elapsed: 0:12:39.
Batch 2,350  of  4,500.    Elapsed: 0:12:55.
Batch 2,400  of  4,500.    Elapsed: 0:13:12.
Batch 2,450  of  4,500.    Elapsed: 0:13:28.
Batch 2,500  of  4,500.    Elapsed: 0:13:45.
Batch 2,550  of  4,500.    Elapsed: 0:14:02.
Batch 2,600  of  4,500.    Elapsed: 0:14:18.
Batch 2,650  of  4,500.    Elapsed: 0:14:35.
Batch 2,700  of  4,500.    Elapsed: 0:14:51.
Batch 2,750  of  4,500.    Elapsed: 0:15:08.
Batch 2,800  of  4,500.    Elapsed: 0:15:24.
Batch 2,850  of  4,500.    Elapsed: 0:15:41.
Batch 2,900  of  4,500.    Elapsed: 0:15:57.
Batch 2,950  of  4,500.    Elapsed: 0:16:14.
Batch 3,000  of  4,500.    Elapsed: 0:16:30.
Batch 3,050  of  4,500.    Elapsed: 0:16:47.
Batch 3,100  of  4,500.    Elapsed: 0:17:03.
Batch 3,150  of  4,500.    Elapsed: 0:17:20.
Batch 3,200  of  4,500.    Elapsed: 0:17:37.
Batch 3,250  of  4,500.    Elapsed: 0:17:53.
Batch 3,300  of  4,500.    Elapsed: 0:18:10.
Batch 3,350  of  4,500.    Elapsed: 0:18:26.
Batch 3,400  of  4,500.    Elapsed: 0:18:43.
Batch 3,450  of  4,500.    Elapsed: 0:18:59.
Batch 3,500  of  4,500.    Elapsed: 0:19:16.
Batch 3,550  of  4,500.    Elapsed: 0:19:32.
Batch 3,600  of  4,500.    Elapsed: 0:19:48.
Batch 3,650  of  4,500.    Elapsed: 0:20:05.
Batch 3,700  of  4,500.    Elapsed: 0:20:21.
Batch 3,750  of  4,500.    Elapsed: 0:20:38.
Batch 3,800  of  4,500.    Elapsed: 0:20:54.
Batch 3,850  of  4,500.    Elapsed: 0:21:11.
Batch 3,900  of  4,500.    Elapsed: 0:21:27.
Batch 3,950  of  4,500.    Elapsed: 0:21:44.
Batch 4,000  of  4,500.    Elapsed: 0:22:00.
Batch 4,050  of  4,500.    Elapsed: 0:22:17.
Batch 4,100  of  4,500.    Elapsed: 0:22:33.
Batch 4,150  of  4,500.    Elapsed: 0:22:50.
Batch 4,200  of  4,500.    Elapsed: 0:23:06.
Batch 4,250  of  4,500.    Elapsed: 0:23:23.
Batch 4,300  of  4,500.    Elapsed: 0:23:39.
Batch 4,350  of  4,500.    Elapsed: 0:23:56.
Batch 4,400  of  4,500.    Elapsed: 0:24:12.
Batch 4,450  of  4,500.    Elapsed: 0:24:29.

  Average training loss: 0.53
  Training epoch took: 0:24:45

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.62
  Validation took: 0:00:58

======== Epoch 3 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:23.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:56.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:29.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:02.
Batch   600  of  4,500.    Elapsed: 0:03:19.
Batch   650  of  4,500.    Elapsed: 0:03:35.
Batch   700  of  4,500.    Elapsed: 0:03:52.
Batch   750  of  4,500.    Elapsed: 0:04:09.
Batch   800  of  4,500.    Elapsed: 0:04:26.
Batch   850  of  4,500.    Elapsed: 0:04:43.
Batch   900  of  4,500.    Elapsed: 0:05:00.
Batch   950  of  4,500.    Elapsed: 0:05:17.
Batch 1,000  of  4,500.    Elapsed: 0:05:33.
Batch 1,050  of  4,500.    Elapsed: 0:05:50.
Batch 1,100  of  4,500.    Elapsed: 0:06:07.
Batch 1,150  of  4,500.    Elapsed: 0:06:24.
Batch 1,200  of  4,500.    Elapsed: 0:06:41.
Batch 1,250  of  4,500.    Elapsed: 0:06:58.
Batch 1,300  of  4,500.    Elapsed: 0:07:15.
Batch 1,350  of  4,500.    Elapsed: 0:07:31.
Batch 1,400  of  4,500.    Elapsed: 0:07:48.
Batch 1,450  of  4,500.    Elapsed: 0:08:05.
Batch 1,500  of  4,500.    Elapsed: 0:08:22.
Batch 1,550  of  4,500.    Elapsed: 0:08:39.
Batch 1,600  of  4,500.    Elapsed: 0:08:56.
Batch 1,650  of  4,500.    Elapsed: 0:09:12.
Batch 1,700  of  4,500.    Elapsed: 0:09:29.
Batch 1,750  of  4,500.    Elapsed: 0:09:45.
Batch 1,800  of  4,500.    Elapsed: 0:10:02.
Batch 1,850  of  4,500.    Elapsed: 0:10:18.
Batch 1,900  of  4,500.    Elapsed: 0:10:35.
Batch 1,950  of  4,500.    Elapsed: 0:10:51.
Batch 2,000  of  4,500.    Elapsed: 0:11:08.
Batch 2,050  of  4,500.    Elapsed: 0:11:24.
Batch 2,100  of  4,500.    Elapsed: 0:11:41.
Batch 2,150  of  4,500.    Elapsed: 0:11:57.
Batch 2,200  of  4,500.    Elapsed: 0:12:14.
Batch 2,250  of  4,500.    Elapsed: 0:12:30.
Batch 2,300  of  4,500.    Elapsed: 0:12:47.
Batch 2,350  of  4,500.    Elapsed: 0:13:03.
Batch 2,400  of  4,500.    Elapsed: 0:13:20.
Batch 2,450  of  4,500.    Elapsed: 0:13:36.
Batch 2,500  of  4,500.    Elapsed: 0:13:53.
Batch 2,550  of  4,500.    Elapsed: 0:14:09.
Batch 2,600  of  4,500.    Elapsed: 0:14:25.
Batch 2,650  of  4,500.    Elapsed: 0:14:42.
Batch 2,700  of  4,500.    Elapsed: 0:14:58.
Batch 2,750  of  4,500.    Elapsed: 0:15:15.
Batch 2,800  of  4,500.    Elapsed: 0:15:31.
Batch 2,850  of  4,500.    Elapsed: 0:15:48.
Batch 2,900  of  4,500.    Elapsed: 0:16:04.
Batch 2,950  of  4,500.    Elapsed: 0:16:21.
Batch 3,000  of  4,500.    Elapsed: 0:16:38.
Batch 3,050  of  4,500.    Elapsed: 0:16:55.
Batch 3,100  of  4,500.    Elapsed: 0:17:12.
Batch 3,150  of  4,500.    Elapsed: 0:17:29.
Batch 3,200  of  4,500.    Elapsed: 0:17:45.
Batch 3,250  of  4,500.    Elapsed: 0:18:02.
Batch 3,300  of  4,500.    Elapsed: 0:18:19.
Batch 3,350  of  4,500.    Elapsed: 0:18:35.
Batch 3,400  of  4,500.    Elapsed: 0:18:52.
Batch 3,450  of  4,500.    Elapsed: 0:19:08.
Batch 3,500  of  4,500.    Elapsed: 0:19:25.
Batch 3,550  of  4,500.    Elapsed: 0:19:41.
Batch 3,600  of  4,500.    Elapsed: 0:19:58.
Batch 3,650  of  4,500.    Elapsed: 0:20:14.
Batch 3,700  of  4,500.    Elapsed: 0:20:31.
Batch 3,750  of  4,500.    Elapsed: 0:20:47.
Batch 3,800  of  4,500.    Elapsed: 0:21:04.
Batch 3,850  of  4,500.    Elapsed: 0:21:20.
Batch 3,900  of  4,500.    Elapsed: 0:21:37.
Batch 3,950  of  4,500.    Elapsed: 0:21:53.
Batch 4,000  of  4,500.    Elapsed: 0:22:09.
Batch 4,050  of  4,500.    Elapsed: 0:22:26.
Batch 4,100  of  4,500.    Elapsed: 0:22:42.
Batch 4,150  of  4,500.    Elapsed: 0:22:59.
Batch 4,200  of  4,500.    Elapsed: 0:23:15.
Batch 4,250  of  4,500.    Elapsed: 0:23:32.
Batch 4,300  of  4,500.    Elapsed: 0:23:48.
Batch 4,350  of  4,500.    Elapsed: 0:24:05.
Batch 4,400  of  4,500.    Elapsed: 0:24:21.
Batch 4,450  of  4,500.    Elapsed: 0:24:38.

  Average training loss: 0.45
  Training epoch took: 0:24:54

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.71
  Validation took: 0:00:58

======== Epoch 4 / 10 ========
Now Training.
Batch    50  of  4,500.    Elapsed: 0:00:17.
Batch   100  of  4,500.    Elapsed: 0:00:33.
Batch   150  of  4,500.    Elapsed: 0:00:50.
Batch   200  of  4,500.    Elapsed: 0:01:06.
Batch   250  of  4,500.    Elapsed: 0:01:22.
Batch   300  of  4,500.    Elapsed: 0:01:39.
Batch   350  of  4,500.    Elapsed: 0:01:55.
Batch   400  of  4,500.    Elapsed: 0:02:12.
Batch   450  of  4,500.    Elapsed: 0:02:28.
Batch   500  of  4,500.    Elapsed: 0:02:45.
Batch   550  of  4,500.    Elapsed: 0:03:01.
Batch   600  of  4,500.    Elapsed: 0:03:18.
Batch   650  of  4,500.    Elapsed: 0:03:34.
Batch   700  of  4,500.    Elapsed: 0:03:51.
Batch   750  of  4,500.    Elapsed: 0:04:07.
Batch   800  of  4,500.    Elapsed: 0:04:23.
Batch   850  of  4,500.    Elapsed: 0:04:40.
Batch   900  of  4,500.    Elapsed: 0:04:56.
Batch   950  of  4,500.    Elapsed: 0:05:13.
Batch 1,000  of  4,500.    Elapsed: 0:05:29.
Batch 1,050  of  4,500.    Elapsed: 0:05:46.
Batch 1,100  of  4,500.    Elapsed: 0:06:02.
Batch 1,150  of  4,500.    Elapsed: 0:06:19.
Batch 1,200  of  4,500.    Elapsed: 0:06:35.
Batch 1,250  of  4,500.    Elapsed: 0:06:52.
Batch 1,300  of  4,500.    Elapsed: 0:07:08.
Batch 1,350  of  4,500.    Elapsed: 0:07:25.
Batch 1,400  of  4,500.    Elapsed: 0:07:41.
Batch 1,450  of  4,500.    Elapsed: 0:07:57.
Batch 1,500  of  4,500.    Elapsed: 0:08:14.
Batch 1,550  of  4,500.    Elapsed: 0:08:30.
Batch 1,600  of  4,500.    Elapsed: 0:08:47.
Batch 1,650  of  4,500.    Elapsed: 0:09:03.
Batch 1,700  of  4,500.    Elapsed: 0:09:20.
Batch 1,750  of  4,500.    Elapsed: 0:09:36.
Batch 1,800  of  4,500.    Elapsed: 0:09:52.
Batch 1,850  of  4,500.    Elapsed: 0:10:09.
Batch 1,900  of  4,500.    Elapsed: 0:10:25.
Batch 1,950  of  4,500.    Elapsed: 0:10:42.
Batch 2,000  of  4,500.    Elapsed: 0:10:58.
Batch 2,050  of  4,500.    Elapsed: 0:11:14.
Batch 2,100  of  4,500.    Elapsed: 0:11:31.
Batch 2,150  of  4,500.    Elapsed: 0:11:47.
Batch 2,200  of  4,500.    Elapsed: 0:12:04.
Batch 2,250  of  4,500.    Elapsed: 0:12:20.
Batch 2,300  of  4,500.    Elapsed: 0:12:37.
Batch 2,350  of  4,500.    Elapsed: 0:12:53.
Batch 2,400  of  4,500.    Elapsed: 0:13:10.
Batch 2,450  of  4,500.    Elapsed: 0:13:26.
Batch 2,500  of  4,500.    Elapsed: 0:13:42.
Batch 2,550  of  4,500.    Elapsed: 0:13:59.
Batch 2,600  of  4,500.    Elapsed: 0:14:15.
Batch 2,650  of  4,500.    Elapsed: 0:14:32.
Batch 2,700  of  4,500.    Elapsed: 0:14:48.
Batch 2,750  of  4,500.    Elapsed: 0:15:04.
Batch 2,800  of  4,500.    Elapsed: 0:15:21.
Batch 2,850  of  4,500.    Elapsed: 0:15:37.
Batch 2,900  of  4,500.    Elapsed: 0:15:54.
Batch 2,950  of  4,500.    Elapsed: 0:16:10.
Batch 3,000  of  4,500.    Elapsed: 0:16:26.
Batch 3,050  of  4,500.    Elapsed: 0:16:43.
Batch 3,100  of  4,500.    Elapsed: 0:16:59.
Batch 3,150  of  4,500.    Elapsed: 0:17:16.
Batch 3,200  of  4,500.    Elapsed: 0:17:32.
Batch 3,250  of  4,500.    Elapsed: 0:17:48.
Batch 3,300  of  4,500.    Elapsed: 0:18:05.
Batch 3,350  of  4,500.    Elapsed: 0:18:21.
Batch 3,400  of  4,500.    Elapsed: 0:18:38.
Batch 3,450  of  4,500.    Elapsed: 0:18:54.
Batch 3,500  of  4,500.    Elapsed: 0:19:10.
Batch 3,550  of  4,500.    Elapsed: 0:19:27.
Batch 3,600  of  4,500.    Elapsed: 0:19:43.
Batch 3,650  of  4,500.    Elapsed: 0:20:00.
Batch 3,700  of  4,500.    Elapsed: 0:20:16.
Batch 3,750  of  4,500.    Elapsed: 0:20:33.
Batch 3,800  of  4,500.    Elapsed: 0:20:49.
Batch 3,850  of  4,500.    Elapsed: 0:21:05.
Batch 3,900  of  4,500.    Elapsed: 0:21:22.
Batch 3,950  of  4,500.    Elapsed: 0:21:38.
Batch 4,000  of  4,500.    Elapsed: 0:21:55.
Batch 4,050  of  4,500.    Elapsed: 0:22:11.
Batch 4,100  of  4,500.    Elapsed: 0:22:28.
Batch 4,150  of  4,500.    Elapsed: 0:22:44.INFO: 
Stopping epoch run early (Epoch 3).
INFO: Training took 1:43:01 (h:mm:ss) 

INFO: Saving confusion matrices.
INFO: Test score: 0.7444
INFO: Training took 1:44:02 (h:mm:ss)
INFO: Total duration: 106.06666666666666 minute(s).

Batch 4,200  of  4,500.    Elapsed: 0:23:01.
Batch 4,250  of  4,500.    Elapsed: 0:23:17.
Batch 4,300  of  4,500.    Elapsed: 0:23:33.
Batch 4,350  of  4,500.    Elapsed: 0:23:50.
Batch 4,400  of  4,500.    Elapsed: 0:24:06.
Batch 4,450  of  4,500.    Elapsed: 0:24:23.

  Average training loss: 0.37
  Training epoch took: 0:24:39

Now Validating.
  Validation Accuracy: 0.75
  Validation Loss: 0.96
  Validation took: 0:00:58
--------------------------------

________________________________
________________________________

INFO: Overall run-time: 1008.8166666666667 minute(s).
--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


--------------------------------------------
--------------------------------------------


