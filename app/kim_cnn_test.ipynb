{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KimCNN\n",
    "https://towardsdatascience.com/identifying-hate-speech-with-bert-and-cnn-b7aa2cddd60d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from platform import python_version\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.7.7\n",
      "pandas==1.0.3\n",
      "numpy==1.19.1\n",
      "torch==1.6.0\n",
      "sklearn==0.23.1\n",
      "transformers==3.0.2\n",
      "matplotlib==3.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"transformers==%s\" % transformers.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparams & corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 140\n",
    "LABEL_COL = \"rating\"\n",
    "MAX_SEQ = 100\n",
    "\n",
    "TRAIN_SIZE = 0.6\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../corpora/small_amazon_reviews_electronic.csv')\n",
    "df = df.sample(SAMPLE_SIZE)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56116</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Matthew Throne</td>\n",
       "      <td>Being able to weigh it down is a nice addition...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.01.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51262</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Johnboy7701</td>\n",
       "      <td>Works well could be a little stronger</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.06.2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating            name  \\\n",
       "56116     4.0  Matthew Throne   \n",
       "51262     4.0     Johnboy7701   \n",
       "\n",
       "                                                  review  verified  vote  \\\n",
       "56116  Being able to weigh it down is a nice addition...      True   0.0   \n",
       "51262              Works well could be a little stronger      True   0.0   \n",
       "\n",
       "             date  \n",
       "56116  27.01.2018  \n",
       "51262  25.06.2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IDX = int(df.shape[0] * TRAIN_SIZE)\n",
    "VAL_IDX = int(TRAIN_IDX) + int((df.shape[0] * (1-TRAIN_SIZE))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:TRAIN_IDX].reset_index(drop=True)\n",
    "df_val = df[TRAIN_IDX:VAL_IDX].reset_index(drop=True)\n",
    "df_test = df[VAL_IDX:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 6) (28, 6) (28, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights='bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 s, sys: 1.04 s, total: 4.43 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(df, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.review.values\n",
    "    ]\n",
    "\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "\n",
    "\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text, dtype=torch.long)\n",
    "\n",
    "\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = tokenize_and_pad_text(df_train, MAX_SEQ)\n",
    "val_indices = tokenize_and_pad_text(df_val, MAX_SEQ)\n",
    "test_indices = tokenize_and_pad_text(df_test, MAX_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2108, 2583,  ...,    0,    0,    0],\n",
       "        [ 101, 2573, 2092,  ...,    0,    0,    0],\n",
       "        [ 101, 2023, 2003,  ..., 2000, 2031, 2330],\n",
       "        ...,\n",
       "        [ 101, 7929, 3737,  ...,    0,    0,    0],\n",
       "        [ 101, 2049, 1037,  ..., 4057, 2068, 2000],\n",
       "        [ 101, 1996, 2132,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 2.62 s, total: 1min 14s\n",
      "Wall time: 44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    x_train = bert_model(train_indices)[0]  # Models outputs are tuples\n",
    "    x_val = bert_model(val_indices)[0]\n",
    "    x_test = bert_model(test_indices)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = targets_to_tensor(df_train, LABEL_COL)\n",
    "y_val = targets_to_tensor(df_val, LABEL_COL)\n",
    "y_test = targets_to_tensor(df_test, LABEL_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 768]) tensor([[-0.2582, -0.0506,  0.2093,  ...,  0.0064,  0.7348, -0.2861],\n",
      "        [-0.2798, -0.0714, -0.8908,  ...,  0.3321,  0.9854,  0.3146],\n",
      "        [-0.2897, -0.0796,  0.1219,  ...,  0.1095,  0.4294, -0.1900],\n",
      "        ...,\n",
      "        [ 0.3450, -0.2605,  0.9711,  ..., -0.7647,  0.3504, -1.2968],\n",
      "        [ 0.1684, -0.2694,  0.9803,  ..., -0.7790,  0.2555, -1.2936],\n",
      "        [ 0.2664, -0.1511,  0.7620,  ..., -0.8262,  0.2276, -1.4162]])\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape, x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    \"\"\" Conv2d(in_channel = 1, \n",
    "           out_channel = 3,\n",
    "           kernel_size = (2,768) oder (3,768) oder (4,768))\n",
    "    \"\"\" \n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        super(KimCNN, self).__init__()\n",
    "\n",
    "        V = embed_num # maximum number of words in review\n",
    "        D = embed_dim # 768\n",
    "        C = class_num # 5\n",
    "        Co = kernel_num # number of filters for each convolution operation\n",
    "        Ks = kernel_sizes # e.g. combinations of 2, 3, 4, ... words\n",
    "        \n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            nn.Conv2d(1, Co, (K, D)) for K in Ks\n",
    "          ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        \n",
    "        # OLD: self.sigmoid = nn.Sigmoid()\n",
    "        # TODO\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.static:\n",
    "            x = Variable(x)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        # OLD: output = self.sigmoid(logit)\n",
    "        # TODO\n",
    "        # output = self.softmax(logit)\n",
    "        return logit\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **embed_num** represents the maximum number of words in a comment (100 in this example).\n",
    "- **embed_dim** represents the size of BERT embedding (768).\n",
    "- **class_num** is the number of toxicity threats to predict (6).\n",
    "- **kernel_num** is the number of filters for each convolution operation (eg. 3 filters for [2 x m] convolution).\n",
    "- **kernel_sizes** of convolutions. Eg. look at combinations 2 words, 3 words, etc.\n",
    "- **dropout** is the percentage of randomly set hidden units to 0 at each update of the training phase. Tip: Make sure you disable dropout during test/validation phase to get deterministic output.\n",
    "- **static** parameter True means that we don’t calculate gradients of embeddings and they stay static. If we set it to False, it would increase the number of parameters the model needs to learn and it could overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = x_train.shape[1]\n",
    "embed_dim = x_train.shape[2]\n",
    "class_num = 6\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "\n",
    "\n",
    "model = KimCNN(\n",
    "    embed_num=embed_num,\n",
    "    embed_dim=embed_dim,\n",
    "    class_num=class_num,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    static=static,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KimCNN(\n",
       "  (embed): Embedding(100, 768)\n",
       "  (convs1): ModuleList(\n",
       "    (0): Conv2d(1, 3, kernel_size=(2, 768), stride=(1, 1))\n",
       "    (1): Conv2d(1, 3, kernel_size=(3, 768), stride=(1, 1))\n",
       "    (2): Conv2d(1, 3, kernel_size=(4, 768), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    i, batch = 0, 0\n",
    "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
    "        x_batch = x[i : i + batch_size]\n",
    "        y_batch = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch\n",
    "    if i + batch_size < len(x):\n",
    "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
    "    if batch == 0:\n",
    "        yield x, y, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (1.119s)\n",
      "Train loss: 0.339 | Val Loss: 2.005\n",
      "Train acc: 85.417% | Val acc: 23.958%\n",
      "----------------------------------------\n",
      "Epoch 2 (0.898s)\n",
      "Train loss: 0.474 | Val Loss: 1.963\n",
      "Train acc: 78.125% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 3 (0.889s)\n",
      "Train loss: 0.526 | Val Loss: 1.944\n",
      "Train acc: 70.833% | Val acc: 35.417%\n",
      "----------------------------------------\n",
      "Epoch 4 (0.893s)\n",
      "Train loss: 0.372 | Val Loss: 1.979\n",
      "Train acc: 81.25% | Val acc: 36.458%\n",
      "----------------------------------------\n",
      "Epoch 5 (0.984s)\n",
      "Train loss: 0.441 | Val Loss: 1.986\n",
      "Train acc: 79.167% | Val acc: 39.583%\n",
      "----------------------------------------\n",
      "Epoch 6 (1.012s)\n",
      "Train loss: 0.408 | Val Loss: 1.983\n",
      "Train acc: 80.208% | Val acc: 35.417%\n",
      "----------------------------------------\n",
      "Epoch 7 (1.646s)\n",
      "Train loss: 0.469 | Val Loss: 2.04\n",
      "Train acc: 76.042% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 8 (2.592s)\n",
      "Train loss: 0.484 | Val Loss: 2.06\n",
      "Train acc: 78.125% | Val acc: 31.25%\n",
      "----------------------------------------\n",
      "Epoch 9 (3.402s)\n",
      "Train loss: 0.657 | Val Loss: 2.003\n",
      "Train acc: 63.542% | Val acc: 35.417%\n",
      "----------------------------------------\n",
      "Epoch 10 (2.951s)\n",
      "Train loss: 0.463 | Val Loss: 2.0\n",
      "Train acc: 78.125% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 11 (2.542s)\n",
      "Train loss: 0.383 | Val Loss: 1.997\n",
      "Train acc: 78.125% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 12 (3.141s)\n",
      "Train loss: 0.447 | Val Loss: 2.005\n",
      "Train acc: 80.208% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 13 (2.063s)\n",
      "Train loss: 0.513 | Val Loss: 2.029\n",
      "Train acc: 73.958% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 14 (1.804s)\n",
      "Train loss: 0.485 | Val Loss: 1.992\n",
      "Train acc: 73.958% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 15 (1.26s)\n",
      "Train loss: 0.509 | Val Loss: 1.934\n",
      "Train acc: 73.958% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 16 (4.132s)\n",
      "Train loss: 0.439 | Val Loss: 1.983\n",
      "Train acc: 82.292% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 17 (3.477s)\n",
      "Train loss: 0.422 | Val Loss: 1.983\n",
      "Train acc: 80.208% | Val acc: 36.458%\n",
      "----------------------------------------\n",
      "Epoch 18 (4.573s)\n",
      "Train loss: 0.382 | Val Loss: 1.999\n",
      "Train acc: 81.25% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 19 (4.624s)\n",
      "Train loss: 0.384 | Val Loss: 2.015\n",
      "Train acc: 81.25% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 20 (4.712s)\n",
      "Train loss: 0.482 | Val Loss: 2.055\n",
      "Train acc: 76.042% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 21 (2.821s)\n",
      "Train loss: 0.484 | Val Loss: 2.078\n",
      "Train acc: 76.042% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 22 (1.947s)\n",
      "Train loss: 0.446 | Val Loss: 2.062\n",
      "Train acc: 79.167% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 23 (1.863s)\n",
      "Train loss: 0.431 | Val Loss: 2.037\n",
      "Train acc: 78.125% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 24 (2.674s)\n",
      "Train loss: 0.495 | Val Loss: 1.997\n",
      "Train acc: 77.083% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 25 (1.88s)\n",
      "Train loss: 0.433 | Val Loss: 1.973\n",
      "Train acc: 79.167% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 26 (2.017s)\n",
      "Train loss: 0.512 | Val Loss: 1.967\n",
      "Train acc: 76.042% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 27 (1.591s)\n",
      "Train loss: 0.339 | Val Loss: 1.957\n",
      "Train acc: 85.417% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 28 (1.853s)\n",
      "Train loss: 0.476 | Val Loss: 2.023\n",
      "Train acc: 75.0% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 29 (2.589s)\n",
      "Train loss: 0.418 | Val Loss: 2.07\n",
      "Train acc: 79.167% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 30 (1.387s)\n",
      "Train loss: 0.409 | Val Loss: 2.059\n",
      "Train acc: 82.292% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 31 (1.914s)\n",
      "Train loss: 0.472 | Val Loss: 2.09\n",
      "Train acc: 73.958% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 32 (1.952s)\n",
      "Train loss: 0.457 | Val Loss: 2.106\n",
      "Train acc: 75.0% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 33 (1.701s)\n",
      "Train loss: 0.579 | Val Loss: 1.979\n",
      "Train acc: 70.833% | Val acc: 26.042%\n",
      "----------------------------------------\n",
      "Epoch 34 (1.71s)\n",
      "Train loss: 0.62 | Val Loss: 1.936\n",
      "Train acc: 69.792% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 35 (2.004s)\n",
      "Train loss: 0.552 | Val Loss: 1.999\n",
      "Train acc: 68.75% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 36 (1.583s)\n",
      "Train loss: 0.436 | Val Loss: 2.102\n",
      "Train acc: 79.167% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 37 (2.222s)\n",
      "Train loss: 0.558 | Val Loss: 2.163\n",
      "Train acc: 69.792% | Val acc: 20.833%\n",
      "----------------------------------------\n",
      "Epoch 38 (1.399s)\n",
      "Train loss: 0.485 | Val Loss: 2.195\n",
      "Train acc: 72.917% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 39 (1.489s)\n",
      "Train loss: 0.527 | Val Loss: 2.146\n",
      "Train acc: 75.0% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 40 (2.063s)\n",
      "Train loss: 0.492 | Val Loss: 2.092\n",
      "Train acc: 73.958% | Val acc: 20.833%\n",
      "----------------------------------------\n",
      "Epoch 41 (1.428s)\n",
      "Train loss: 0.496 | Val Loss: 2.042\n",
      "Train acc: 75.0% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 42 (1.454s)\n",
      "Train loss: 0.494 | Val Loss: 2.09\n",
      "Train acc: 79.167% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 43 (2.081s)\n",
      "Train loss: 0.462 | Val Loss: 2.152\n",
      "Train acc: 75.0% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 44 (1.555s)\n",
      "Train loss: 0.502 | Val Loss: 2.12\n",
      "Train acc: 76.042% | Val acc: 28.125%\n",
      "----------------------------------------\n",
      "Epoch 45 (1.838s)\n",
      "Train loss: 0.42 | Val Loss: 2.149\n",
      "Train acc: 82.292% | Val acc: 20.833%\n",
      "----------------------------------------\n",
      "Epoch 46 (1.674s)\n",
      "Train loss: 0.559 | Val Loss: 2.133\n",
      "Train acc: 73.958% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 47 (1.619s)\n",
      "Train loss: 0.508 | Val Loss: 2.122\n",
      "Train acc: 70.833% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 48 (2.036s)\n",
      "Train loss: 0.521 | Val Loss: 2.094\n",
      "Train acc: 71.875% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 49 (1.402s)\n",
      "Train loss: 0.444 | Val Loss: 2.133\n",
      "Train acc: 79.167% | Val acc: 32.292%\n",
      "----------------------------------------\n",
      "Epoch 50 (1.475s)\n",
      "Train loss: 0.543 | Val Loss: 2.207\n",
      "Train acc: 76.042% | Val acc: 32.292%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "#x_train = x_train.long()\n",
    "#y_train = y_train.long()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    model.train(True)\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, BATCH_SIZE):\n",
    "        #x_batch = x_batch.long()\n",
    "        #y_batch = y_batch.long()\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        acc = categorical_accuracy(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc.item()\n",
    "\n",
    "    train_loss /= batch\n",
    "    train_acc /= batch\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "\n",
    "    model.eval() # disable dropout for deterministic output\n",
    "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        val_loss, batch = 0, 1\n",
    "        val_acc = 0\n",
    "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, BATCH_SIZE):\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            acc = categorical_accuracy(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc.item()\n",
    "        val_loss /= batch\n",
    "        val_acc /= batch\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "    def rnd(n):\n",
    "        return np.around(n, decimals=3)\n",
    "    \n",
    "    print(f\"Epoch {epoch} ({rnd(elapsed)}s)\")\n",
    "    print(f\"Train loss: {rnd(train_losses[-1])} | Val Loss: {rnd(val_losses[-1])}\")\n",
    "    print(f\"Train acc: {rnd(train_accuracies[-1]*100)}% | Val acc: {rnd(val_accuracies[-1]*100)}%\") \n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # disable dropout for deterministic output\n",
    "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "    y_preds = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, BATCH_SIZE):\n",
    "        y_pred = model(x_batch)\n",
    "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
    "    y_preds_np = np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25008011,  0.15140831,  0.75387979,  0.77974641,  0.3716363 ,\n",
       "         0.9738462 ],\n",
       "       [-0.94829065,  0.23531982,  0.83165634,  1.54329777,  1.14960456,\n",
       "         1.16471028],\n",
       "       [-0.48482552,  0.39177954,  0.78040463,  1.23994446,  0.87735057,\n",
       "         1.00564682],\n",
       "       [-0.9384107 ,  1.64808559,  0.4806627 ,  1.81574142,  1.49107528,\n",
       "         1.08294749],\n",
       "       [-0.67829269,  0.0891971 ,  0.43799555,  0.86421561,  0.57455552,\n",
       "         0.78969955],\n",
       "       [-0.73730791,  1.43386567,  0.73605382,  1.66408563,  1.28786242,\n",
       "         1.10473347],\n",
       "       [-0.37489676,  0.54627359,  0.94118488,  1.16473258,  0.71518099,\n",
       "         1.30123246],\n",
       "       [-1.17724597,  0.08536696,  0.71791536,  1.86519945,  1.67288768,\n",
       "         0.7148447 ],\n",
       "       [-0.20030463,  0.68846339,  0.80267853,  1.0018332 ,  0.61734319,\n",
       "         1.03747559],\n",
       "       [-0.71334618,  1.32633471,  0.78794098,  1.67961109,  1.22302091,\n",
       "         1.29960382],\n",
       "       [-0.7080245 ,  0.97795302,  0.74817371,  1.62543619,  1.39047766,\n",
       "         1.1338824 ],\n",
       "       [-0.45176068,  1.58237851,  0.5507887 ,  1.48749936,  1.20019913,\n",
       "         1.06881547],\n",
       "       [-0.07945838,  1.49149811,  1.06222081,  1.3858794 ,  1.1164887 ,\n",
       "         1.34092438],\n",
       "       [-0.57420242,  0.73795152,  0.86539638,  1.52761161,  1.35037684,\n",
       "         1.23716652],\n",
       "       [-0.38546851,  1.10578012,  0.88856745,  1.36903727,  0.94045067,\n",
       "         1.22046053],\n",
       "       [-0.47446558,  0.88689929,  0.96221566,  1.39940298,  0.9683218 ,\n",
       "         1.39680493],\n",
       "       [-0.87087822, -0.07627943,  0.61200559,  1.31365681,  1.1801523 ,\n",
       "         0.7847352 ],\n",
       "       [-0.33224502,  0.98274404,  1.05664742,  1.3759197 ,  1.36025238,\n",
       "         1.49198627],\n",
       "       [-0.6734699 , -0.28016797,  0.56955576,  0.78290367,  0.45150539,\n",
       "         0.93980777],\n",
       "       [-0.31795534,  0.38988939,  0.63460541,  0.86327159,  0.7223711 ,\n",
       "         1.04742813],\n",
       "       [-0.34647289,  1.15198874,  1.09290147,  1.48613679,  0.98118007,\n",
       "         1.43872082],\n",
       "       [-0.48241797,  1.19417417,  0.76042861,  1.41047275,  1.16255474,\n",
       "         1.24947834],\n",
       "       [-0.09450268,  0.91212809,  0.81601822,  1.11095738,  0.82614231,\n",
       "         0.89943141],\n",
       "       [-0.32526591,  0.97879666,  0.81237543,  1.25243187,  0.91431999,\n",
       "         1.01893032],\n",
       "       [-0.62309712,  1.55271852,  0.52267706,  1.58355641,  1.40635121,\n",
       "         1.13247061],\n",
       "       [-0.71952027,  0.41216502,  0.65273166,  1.34854531,  1.06149161,\n",
       "         0.91945481],\n",
       "       [ 0.04634138,  1.351331  ,  1.19127512,  1.30458879,  1.54901946,\n",
       "         1.43478251],\n",
       "       [-0.15591463,  1.58617365,  0.63387775,  1.26401448,  1.30817389,\n",
       "         1.09262288]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = df_test[target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-68b3641e81d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    396\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    397\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 120\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    224\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
    "df_accuracy.sort_values('auc')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels = df_train[target_columns].sum().sum()\n",
    "positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df_train[target_columns].count().sum()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03666666666666667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels/all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test[target_columns]\n",
    "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
    "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_pred</th>\n",
       "      <th>severe_toxic_pred</th>\n",
       "      <th>obscene_pred</th>\n",
       "      <th>threat_pred</th>\n",
       "      <th>insult_pred</th>\n",
       "      <th>identity_hate_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  toxic_pred  \\\n",
       "0       0             0        0       0       0              0           0   \n",
       "1       0             0        0       0       0              0           0   \n",
       "2       0             0        0       0       0              0           0   \n",
       "3       0             0        0       0       0              0           0   \n",
       "4       0             0        0       0       0              0           0   \n",
       "5       0             0        0       0       0              0           0   \n",
       "6       0             0        0       0       0              0           0   \n",
       "7       1             0        1       0       1              0           0   \n",
       "8       0             0        0       0       0              0           0   \n",
       "9       0             0        0       0       0              0           0   \n",
       "10      0             0        0       0       0              0           0   \n",
       "11      0             0        0       0       0              0           0   \n",
       "12      0             0        0       0       0              0           0   \n",
       "13      0             0        0       0       0              0           0   \n",
       "14      0             0        0       0       0              0           0   \n",
       "15      0             0        0       0       0              0           0   \n",
       "16      0             0        0       0       0              0           0   \n",
       "17      1             0        1       0       0              0           0   \n",
       "18      0             0        0       0       0              0           0   \n",
       "19      0             0        0       0       0              0           0   \n",
       "\n",
       "    severe_toxic_pred  obscene_pred  threat_pred  insult_pred  \\\n",
       "0                   0             0            0            0   \n",
       "1                   0             0            0            0   \n",
       "2                   0             0            0            0   \n",
       "3                   0             0            0            0   \n",
       "4                   0             0            0            0   \n",
       "5                   0             0            0            0   \n",
       "6                   0             0            0            0   \n",
       "7                   0             0            0            0   \n",
       "8                   0             0            0            0   \n",
       "9                   0             0            0            0   \n",
       "10                  0             0            0            0   \n",
       "11                  0             0            0            0   \n",
       "12                  0             0            0            0   \n",
       "13                  0             0            0            0   \n",
       "14                  0             0            0            0   \n",
       "15                  0             0            0            0   \n",
       "16                  0             0            0            0   \n",
       "17                  0             0            0            0   \n",
       "18                  0             0            0            0   \n",
       "19                  0             0            0            0   \n",
       "\n",
       "    identity_hate_pred  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  \n",
       "15                   0  \n",
       "16                   0  \n",
       "17                   0  \n",
       "18                   0  \n",
       "19                   0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            2\n",
       "severe_toxic     0\n",
       "obscene          2\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  toxic_pred\n",
       "7       1           0\n",
       "17      1           0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity[df_sanity.toxic > 0][['toxic', 'toxic_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE\n",
    "class KimCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        super(KimCNN, self).__init__()\n",
    "\n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        Ci = 1\n",
    "\n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "\n",
    "        if self.static:\n",
    "            self.embed.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ALTERNATIVE 2\n",
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim,\n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The in_channels argument is the number of \"channels\" in your image going into the convolutional layer.\n",
    "        # In actual images this is usually 3 (one channel for each of the red, blue and green channels),\n",
    "        # however when using text we only have a single channel, t\n",
    "        # he text itself. The out_channels is the number of filters and the kernel_size is the size of the filters.\n",
    "        # Each of our kernel_sizes is going to be [n x emb_dim] where $n$ is the size of the n-grams.\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # embedded = [batch size, sent len, emb dim]\n",
    "\n",
    "        # In PyTorch, RNNs want the input with the batch dimension second, whereas CNNs want the batch dimension first\n",
    "        # - we do not have to permute the data here as we have already set batch_first = True in our TEXT field.\n",
    "        # We then pass the sentence through an embedding layer to get our embeddings.\n",
    "        # The second dimension of the input into a nn. Conv2d layer must be the channel dimension.\n",
    "        # As text technically does not have a channel dimension,\n",
    "        # we unsqueeze our tensor to create one.\n",
    "        # This matches with our in_channels=1 in the initialization of our convolutional layers.\n",
    "\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "\n",
    "        # embedded = [batch size, 1, sent len, emb dim]\n",
    "\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "\n",
    "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "\n",
    "        # pooled_n = [batch size, n_filters]\n",
    "\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "\n",
    "        return self.fc(cat)\n",
    "\n",
    "    def predict_class(self, sentence, nlp, dataset, device, min_len=4):\n",
    "        self.eval()\n",
    "        tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "        if len(tokenized) < min_len:\n",
    "            tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "        indexed = [dataset.TEXT.vocab.stoi[t] for t in tokenized]\n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        tensor = tensor.permute(1, 0)\n",
    "        preds = self(tensor)\n",
    "        max_preds = preds.argmax(dim=1)\n",
    "\n",
    "        return max_preds.item()\n",
    "\n",
    "    @staticmethod\n",
    "    def __count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
