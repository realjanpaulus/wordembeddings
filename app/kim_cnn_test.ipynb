{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KimCNN\n",
    "https://towardsdatascience.com/identifying-hate-speech-with-bert-and-cnn-b7aa2cddd60d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from platform import python_version\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.7.7\n",
      "pandas==1.0.3\n",
      "numpy==1.19.1\n",
      "torch==1.6.0\n",
      "sklearn==0.23.1\n",
      "transformers==3.0.2\n",
      "matplotlib==3.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"transformers==%s\" % transformers.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparams & corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 140\n",
    "LABEL_COL = \"rating\"\n",
    "MAX_SEQ = 100\n",
    "\n",
    "TRAIN_SIZE = 0.6\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../corpora/small_amazon_reviews_electronic.csv')\n",
    "df = df.sample(SAMPLE_SIZE)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58868</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Instructions are not great</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.03.2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24571</th>\n",
       "      <td>2.0</td>\n",
       "      <td>BC</td>\n",
       "      <td>Be cautious with buying Product cake with scra...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>05.07.2018</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating   name                                             review  \\\n",
       "58868     4.0  Brian                         Instructions are not great   \n",
       "24571     2.0     BC  Be cautious with buying Product cake with scra...   \n",
       "\n",
       "       verified  vote        date  length  \n",
       "58868      True   0.0  26.03.2018       4  \n",
       "24571      True   0.0  05.07.2018      50  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IDX = int(df.shape[0] * TRAIN_SIZE)\n",
    "VAL_IDX = int(TRAIN_IDX) + int((df.shape[0] * (1-TRAIN_SIZE))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:TRAIN_IDX].reset_index(drop=True)\n",
    "df_val = df[TRAIN_IDX:VAL_IDX].reset_index(drop=True)\n",
    "df_test = df[VAL_IDX:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 7) (28, 7) (28, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights='bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 1.28 s, total: 4.58 s\n",
      "Wall time: 8.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(df, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.review.values\n",
    "    ]\n",
    "\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "\n",
    "\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text, dtype=torch.long)\n",
    "\n",
    "\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_indices = tokenize_and_pad_text(df_train, MAX_SEQ)\n",
    "val_indices = tokenize_and_pad_text(df_val, MAX_SEQ)\n",
    "test_indices = tokenize_and_pad_text(df_test, MAX_SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  8128,  2024,  ...,     0,     0,     0],\n",
       "        [  101,  2022, 17145,  ...,     0,     0,     0],\n",
       "        [  101, 24665,  6305,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  3321,  2003,  ...,     0,     0,     0],\n",
       "        [  101,  2028,  2757,  ...,  3791,  3637,  1045],\n",
       "        [  101,  3277,  2007,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 3.5 s, total: 1min 20s\n",
      "Wall time: 48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    x_train = bert_model(train_indices)[0]  # Models outputs are tuples\n",
    "    x_val = bert_model(val_indices)[0]\n",
    "    x_test = bert_model(test_indices)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = targets_to_tensor(df_train, LABEL_COL)\n",
    "y_val = targets_to_tensor(df_val, LABEL_COL)\n",
    "y_test = targets_to_tensor(df_test, LABEL_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 768]) tensor([[-0.4320,  0.3098,  0.4746,  ..., -0.3138,  0.5364, -0.5687],\n",
      "        [-0.1051,  0.0361,  0.5194,  ..., -0.0588, -0.0292, -0.6363],\n",
      "        [ 0.2319,  0.6842,  0.7212,  ...,  0.1204,  0.2186, -0.1933],\n",
      "        ...,\n",
      "        [ 0.1164, -0.1399,  0.9884,  ..., -0.5276,  0.1733, -0.9118],\n",
      "        [ 0.0642, -0.1584,  0.9645,  ..., -0.5232,  0.0913, -0.8546],\n",
      "        [ 0.0881,  0.0216,  0.8947,  ..., -0.5156,  0.0755, -0.9127]])\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape, x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    i, batch = 0, 0\n",
    "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
    "        x_batch = x[i : i + batch_size]\n",
    "        y_batch = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch\n",
    "    if i + batch_size < len(x):\n",
    "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
    "    if batch == 0:\n",
    "        yield x, y, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "\n",
    "EMBEDDING_TYPE = \"glove.6B.100d\"\n",
    "MAX_VOCAB_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "REVIEW = data.Field(tokenize = \"toktok\",\n",
    "                    lower = True)\n",
    "\n",
    "RATING = data.LabelField()\n",
    "assigned_fields = {\"review\": ('text', REVIEW), \n",
    "                   \"rating\": ('label', RATING)}\n",
    "\n",
    "train_data, val_data, test_data = data.TabularDataset.splits(path=\"../corpora/splits/\", \n",
    "                                                              train='train.json',\n",
    "                                                              validation='val.json', \n",
    "                                                              test='test.json', \n",
    "                                                              format='json',\n",
    "                                                              fields=assigned_fields,\n",
    "                                                              skip_header = True)\n",
    "\n",
    "\n",
    "\n",
    "REVIEW.build_vocab(train_data, \n",
    "                   vectors = EMBEDDING_TYPE, \n",
    "                   unk_init = torch.Tensor.normal_,\n",
    "                   max_size = MAX_VOCAB_SIZE)\n",
    "RATING.build_vocab(train_data)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits((train_data, val_data, test_data), \n",
    "                                                                         batch_size = BATCH_SIZE,\n",
    "                                                                         device = device,\n",
    "                                                                         sort_key = lambda x: len(x.text),\n",
    "                                                                         sort = False,\n",
    "                                                                         sort_within_batch=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KimCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    \"\"\" Conv2d(in_channel = 1, \n",
    "           out_channel = 3,\n",
    "           kernel_size = (2,768) oder (3,768) oder (4,768))\n",
    "    \"\"\" \n",
    "    def __init__(self, embed_num, embed_dim, class_num, \n",
    "                 kernel_num, kernel_sizes, dropout, static, in_channel):\n",
    "        super(KimCNN, self).__init__()\n",
    "\n",
    "        V = embed_num # maximum number of words in review\n",
    "        D = embed_dim # 768\n",
    "        C = class_num # 5\n",
    "        Co = kernel_num # number of filters for each convolution operation\n",
    "        Ks = kernel_sizes # e.g. combinations of 2, 3, 4, ... words\n",
    "        \n",
    "        \n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            nn.Conv1d(in_channel, Co, (K, D)) for K in Ks\n",
    "          ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        \n",
    "        # OLD: self.sigmoid = nn.Sigmoid()\n",
    "        # TODO\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.static:\n",
    "            x = Variable(x)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        output = self.fc1(x)  # (N, C)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **embed_num** represents the maximum number of words in a comment (100 in this example).\n",
    "- **embed_dim** represents the size of BERT embedding (768).\n",
    "- **class_num** is the number of toxicity threats to predict (6).\n",
    "- **kernel_num** is the number of filters for each convolution operation (eg. 3 filters for [2 x m] convolution).\n",
    "- **kernel_sizes** of convolutions. Eg. look at combinations 2 words, 3 words, etc.\n",
    "- **dropout** is the percentage of randomly set hidden units to 0 at each update of the training phase. Tip: Make sure you disable dropout during test/validation phase to get deterministic output.\n",
    "- **static** parameter True means that we don’t calculate gradients of embeddings and they stay static. If we set it to False, it would increase the number of parameters the model needs to learn and it could overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = x_train.shape[1]\n",
    "embed_dim = x_train.shape[2]\n",
    "class_num = 6\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True\n",
    "in_channel = 1\n",
    "\n",
    "\n",
    "model = KimCNN(\n",
    "    embed_num=embed_num,\n",
    "    embed_dim=embed_dim,\n",
    "    class_num=class_num,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    static=static,\n",
    "    in_channel = in_channel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KimCNN(\n",
       "  (embed): Embedding(100, 768)\n",
       "  (convs1): ModuleList(\n",
       "    (0): Conv1d(1, 3, kernel_size=(2, 768), stride=(1,))\n",
       "    (1): Conv1d(1, 3, kernel_size=(3, 768), stride=(1,))\n",
       "    (2): Conv1d(1, 3, kernel_size=(4, 768), stride=(1,))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_TYPE = \"bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.iterator.BucketIterator object at 0x7ff2a13569d0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-c27bba8879eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# copy field names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             self.input_fields = [k for k, v in dataset.fields.items() if\n\u001b[1;32m     27\u001b[0m                                  v is not None and not v.is_target]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'fields'"
     ]
    }
   ],
   "source": [
    "train_iterator2, val_iterator2, test_iterator2 = data.BucketIterator.splits((x_train, x_val, x_test), \n",
    "                                                                         batch_size = BATCH_SIZE,\n",
    "                                                                         device = device,\n",
    "                                                                         sort_key = lambda x: len(x.text),\n",
    "                                                                         sort = False,\n",
    "                                                                         sort_within_batch=False)\n",
    "\n",
    "print(train_iterator2)\n",
    "for i in train_iterator2:\n",
    "    print(i.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train() \n",
    "    \n",
    "    \n",
    "    if EMBEDDING_TYPE == \"bert\":\n",
    "        for batch_text, batch_label, batch in iterator:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_text)\n",
    "            \n",
    "            loss = criterion(predictions, batch_label)\n",
    "            acc = categorical_accuracy(predictions, batch_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item()\n",
    "    \n",
    "    for batch in iterator:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        #acc = categorical_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        #epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "for epoch in range(2):\n",
    "    train_loss, train_acc = train(model, train_iterator2, \n",
    "                                  optimizer, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (1.118s)\n",
      "Train loss: 1.124 | Val Loss: 2.425\n",
      "Train acc: 46.875% | Val acc: 22.917%\n",
      "----------------------------------------\n",
      "Epoch 2 (1.066s)\n",
      "Train loss: 0.941 | Val Loss: 2.071\n",
      "Train acc: 57.292% | Val acc: 21.875%\n",
      "----------------------------------------\n",
      "Epoch 3 (1.045s)\n",
      "Train loss: 0.93 | Val Loss: 2.067\n",
      "Train acc: 60.417% | Val acc: 18.75%\n",
      "----------------------------------------\n",
      "Epoch 4 (0.941s)\n",
      "Train loss: 1.185 | Val Loss: 1.868\n",
      "Train acc: 45.833% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 5 (0.881s)\n",
      "Train loss: 1.111 | Val Loss: 1.866\n",
      "Train acc: 45.833% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 6 (0.884s)\n",
      "Train loss: 0.996 | Val Loss: 1.949\n",
      "Train acc: 53.125% | Val acc: 29.167%\n",
      "----------------------------------------\n",
      "Epoch 7 (0.887s)\n",
      "Train loss: 1.016 | Val Loss: 1.905\n",
      "Train acc: 51.042% | Val acc: 25.0%\n",
      "----------------------------------------\n",
      "Epoch 8 (0.889s)\n",
      "Train loss: 0.99 | Val Loss: 2.079\n",
      "Train acc: 56.25% | Val acc: 21.875%\n",
      "----------------------------------------\n",
      "Epoch 9 (0.944s)\n",
      "Train loss: 1.056 | Val Loss: 2.34\n",
      "Train acc: 52.083% | Val acc: 11.458%\n",
      "----------------------------------------\n",
      "Epoch 10 (2.107s)\n",
      "Train loss: 1.101 | Val Loss: 2.051\n",
      "Train acc: 50.0% | Val acc: 19.792%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "#x_train = x_train.long()\n",
    "#y_train = y_train.long()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    model.train(True)\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, BATCH_SIZE):\n",
    "        #x_batch = x_batch.long()\n",
    "        #y_batch = y_batch.long()\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        acc = categorical_accuracy(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc.item()\n",
    "\n",
    "    train_loss /= batch\n",
    "    train_acc /= batch\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "\n",
    "    model.eval() # disable dropout for deterministic output\n",
    "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        val_loss, batch = 0, 1\n",
    "        val_acc = 0\n",
    "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, BATCH_SIZE):\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            acc = categorical_accuracy(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc.item()\n",
    "        val_loss /= batch\n",
    "        val_acc /= batch\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "    def rnd(n):\n",
    "        return np.around(n, decimals=3)\n",
    "    \n",
    "    print(f\"Epoch {epoch} ({rnd(elapsed)}s)\")\n",
    "    print(f\"Train loss: {rnd(train_losses[-1])} | Val Loss: {rnd(val_losses[-1])}\")\n",
    "    print(f\"Train acc: {rnd(train_accuracies[-1]*100)}% | Val acc: {rnd(val_accuracies[-1]*100)}%\") \n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # disable dropout for deterministic output\n",
    "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "    y_preds = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, BATCH_SIZE):\n",
    "        y_pred = model(x_batch)\n",
    "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
    "    y_preds_np = np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25008011,  0.15140831,  0.75387979,  0.77974641,  0.3716363 ,\n",
       "         0.9738462 ],\n",
       "       [-0.94829065,  0.23531982,  0.83165634,  1.54329777,  1.14960456,\n",
       "         1.16471028],\n",
       "       [-0.48482552,  0.39177954,  0.78040463,  1.23994446,  0.87735057,\n",
       "         1.00564682],\n",
       "       [-0.9384107 ,  1.64808559,  0.4806627 ,  1.81574142,  1.49107528,\n",
       "         1.08294749],\n",
       "       [-0.67829269,  0.0891971 ,  0.43799555,  0.86421561,  0.57455552,\n",
       "         0.78969955],\n",
       "       [-0.73730791,  1.43386567,  0.73605382,  1.66408563,  1.28786242,\n",
       "         1.10473347],\n",
       "       [-0.37489676,  0.54627359,  0.94118488,  1.16473258,  0.71518099,\n",
       "         1.30123246],\n",
       "       [-1.17724597,  0.08536696,  0.71791536,  1.86519945,  1.67288768,\n",
       "         0.7148447 ],\n",
       "       [-0.20030463,  0.68846339,  0.80267853,  1.0018332 ,  0.61734319,\n",
       "         1.03747559],\n",
       "       [-0.71334618,  1.32633471,  0.78794098,  1.67961109,  1.22302091,\n",
       "         1.29960382],\n",
       "       [-0.7080245 ,  0.97795302,  0.74817371,  1.62543619,  1.39047766,\n",
       "         1.1338824 ],\n",
       "       [-0.45176068,  1.58237851,  0.5507887 ,  1.48749936,  1.20019913,\n",
       "         1.06881547],\n",
       "       [-0.07945838,  1.49149811,  1.06222081,  1.3858794 ,  1.1164887 ,\n",
       "         1.34092438],\n",
       "       [-0.57420242,  0.73795152,  0.86539638,  1.52761161,  1.35037684,\n",
       "         1.23716652],\n",
       "       [-0.38546851,  1.10578012,  0.88856745,  1.36903727,  0.94045067,\n",
       "         1.22046053],\n",
       "       [-0.47446558,  0.88689929,  0.96221566,  1.39940298,  0.9683218 ,\n",
       "         1.39680493],\n",
       "       [-0.87087822, -0.07627943,  0.61200559,  1.31365681,  1.1801523 ,\n",
       "         0.7847352 ],\n",
       "       [-0.33224502,  0.98274404,  1.05664742,  1.3759197 ,  1.36025238,\n",
       "         1.49198627],\n",
       "       [-0.6734699 , -0.28016797,  0.56955576,  0.78290367,  0.45150539,\n",
       "         0.93980777],\n",
       "       [-0.31795534,  0.38988939,  0.63460541,  0.86327159,  0.7223711 ,\n",
       "         1.04742813],\n",
       "       [-0.34647289,  1.15198874,  1.09290147,  1.48613679,  0.98118007,\n",
       "         1.43872082],\n",
       "       [-0.48241797,  1.19417417,  0.76042861,  1.41047275,  1.16255474,\n",
       "         1.24947834],\n",
       "       [-0.09450268,  0.91212809,  0.81601822,  1.11095738,  0.82614231,\n",
       "         0.89943141],\n",
       "       [-0.32526591,  0.97879666,  0.81237543,  1.25243187,  0.91431999,\n",
       "         1.01893032],\n",
       "       [-0.62309712,  1.55271852,  0.52267706,  1.58355641,  1.40635121,\n",
       "         1.13247061],\n",
       "       [-0.71952027,  0.41216502,  0.65273166,  1.34854531,  1.06149161,\n",
       "         0.91945481],\n",
       "       [ 0.04634138,  1.351331  ,  1.19127512,  1.30458879,  1.54901946,\n",
       "         1.43478251],\n",
       "       [-0.15591463,  1.58617365,  0.63387775,  1.26401448,  1.30817389,\n",
       "         1.09262288]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = df_test[target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-68b3641e81d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    396\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    397\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 120\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    224\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
    "df_accuracy.sort_values('auc')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels = df_train[target_columns].sum().sum()\n",
    "positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df_train[target_columns].count().sum()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03666666666666667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels/all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test[target_columns]\n",
    "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
    "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_pred</th>\n",
       "      <th>severe_toxic_pred</th>\n",
       "      <th>obscene_pred</th>\n",
       "      <th>threat_pred</th>\n",
       "      <th>insult_pred</th>\n",
       "      <th>identity_hate_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  toxic_pred  \\\n",
       "0       0             0        0       0       0              0           0   \n",
       "1       0             0        0       0       0              0           0   \n",
       "2       0             0        0       0       0              0           0   \n",
       "3       0             0        0       0       0              0           0   \n",
       "4       0             0        0       0       0              0           0   \n",
       "5       0             0        0       0       0              0           0   \n",
       "6       0             0        0       0       0              0           0   \n",
       "7       1             0        1       0       1              0           0   \n",
       "8       0             0        0       0       0              0           0   \n",
       "9       0             0        0       0       0              0           0   \n",
       "10      0             0        0       0       0              0           0   \n",
       "11      0             0        0       0       0              0           0   \n",
       "12      0             0        0       0       0              0           0   \n",
       "13      0             0        0       0       0              0           0   \n",
       "14      0             0        0       0       0              0           0   \n",
       "15      0             0        0       0       0              0           0   \n",
       "16      0             0        0       0       0              0           0   \n",
       "17      1             0        1       0       0              0           0   \n",
       "18      0             0        0       0       0              0           0   \n",
       "19      0             0        0       0       0              0           0   \n",
       "\n",
       "    severe_toxic_pred  obscene_pred  threat_pred  insult_pred  \\\n",
       "0                   0             0            0            0   \n",
       "1                   0             0            0            0   \n",
       "2                   0             0            0            0   \n",
       "3                   0             0            0            0   \n",
       "4                   0             0            0            0   \n",
       "5                   0             0            0            0   \n",
       "6                   0             0            0            0   \n",
       "7                   0             0            0            0   \n",
       "8                   0             0            0            0   \n",
       "9                   0             0            0            0   \n",
       "10                  0             0            0            0   \n",
       "11                  0             0            0            0   \n",
       "12                  0             0            0            0   \n",
       "13                  0             0            0            0   \n",
       "14                  0             0            0            0   \n",
       "15                  0             0            0            0   \n",
       "16                  0             0            0            0   \n",
       "17                  0             0            0            0   \n",
       "18                  0             0            0            0   \n",
       "19                  0             0            0            0   \n",
       "\n",
       "    identity_hate_pred  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  \n",
       "15                   0  \n",
       "16                   0  \n",
       "17                   0  \n",
       "18                   0  \n",
       "19                   0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            2\n",
       "severe_toxic     0\n",
       "obscene          2\n",
       "threat           0\n",
       "insult           1\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  toxic_pred\n",
       "7       1           0\n",
       "17      1           0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity[df_sanity.toxic > 0][['toxic', 'toxic_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE\n",
    "class KimCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        super(KimCNN, self).__init__()\n",
    "\n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        Ci = 1\n",
    "\n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "\n",
    "        if self.static:\n",
    "            self.embed.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]  # [(N, Co, W), ...]*len(Ks)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ALTERNATIVE 2\n",
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim,\n",
    "                 dropout, pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The in_channels argument is the number of \"channels\" in your image going into the convolutional layer.\n",
    "        # In actual images this is usually 3 (one channel for each of the red, blue and green channels),\n",
    "        # however when using text we only have a single channel, t\n",
    "        # he text itself. The out_channels is the number of filters and the kernel_size is the size of the filters.\n",
    "        # Each of our kernel_sizes is going to be [n x emb_dim] where $n$ is the size of the n-grams.\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # embedded = [batch size, sent len, emb dim]\n",
    "\n",
    "        # In PyTorch, RNNs want the input with the batch dimension second, whereas CNNs want the batch dimension first\n",
    "        # - we do not have to permute the data here as we have already set batch_first = True in our TEXT field.\n",
    "        # We then pass the sentence through an embedding layer to get our embeddings.\n",
    "        # The second dimension of the input into a nn. Conv2d layer must be the channel dimension.\n",
    "        # As text technically does not have a channel dimension,\n",
    "        # we unsqueeze our tensor to create one.\n",
    "        # This matches with our in_channels=1 in the initialization of our convolutional layers.\n",
    "\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "\n",
    "        # embedded = [batch size, 1, sent len, emb dim]\n",
    "\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "\n",
    "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "\n",
    "        # pooled_n = [batch size, n_filters]\n",
    "\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "\n",
    "        return self.fc(cat)\n",
    "\n",
    "    def predict_class(self, sentence, nlp, dataset, device, min_len=4):\n",
    "        self.eval()\n",
    "        tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "        if len(tokenized) < min_len:\n",
    "            tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "        indexed = [dataset.TEXT.vocab.stoi[t] for t in tokenized]\n",
    "        tensor = torch.LongTensor(indexed).to(device)\n",
    "        tensor = tensor.unsqueeze(1)\n",
    "        tensor = tensor.permute(1, 0)\n",
    "        preds = self(tensor)\n",
    "        max_preds = preds.argmax(dim=1)\n",
    "\n",
    "        return max_preds.item()\n",
    "\n",
    "    @staticmethod\n",
    "    def __count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 102 0 100\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.cls_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.sep_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [SEP] [PAD] [UNK]\n"
     ]
    }
   ],
   "source": [
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
